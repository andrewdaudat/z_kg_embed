<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.43">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>16&nbsp; Appendix B: Resources and Tools â€“ Knowledge Graph Embeddings for Link Prediction and Reasoning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../content/appendix-a.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-d4d76bf8491c20bad77d141916dc28e1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-bdec3157979715d7154bb60f5aa24e58.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../content/appendix-b.html"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Appendix B: Resources and Tools</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Knowledge Graph Embeddings for Link Prediction and Reasoning</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/outline.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Outline</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Introduction to Knowledge Graphs and Representations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/embedding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Fundamentals of Vector Space Representations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/translation-based.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Translation-Based Embedding Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/semantic-matching.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Semantic Matching Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/rotation-nn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Advanced Models: Rotations and Neural Networks</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/training.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Training and Optimization Techniques</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/evaluation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Evaluation Methodologies and Benchmarks</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/additional-knowledge.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Incorporating Additional Information</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/reasoning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Reasoning with Knowledge Graph Embeddings</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/applications.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Practical Applications and Case Studies</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/implementation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Implementing Knowledge Graph Embedding Systems</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/frontier.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Advanced Topics and Research Frontiers</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/appendix-a.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Appendix A: Mathematical Foundations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/appendix-b.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Appendix B: Resources and Tools</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="-1">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction-to-knowledge-graph-embedding-resources" id="toc-introduction-to-knowledge-graph-embedding-resources" class="nav-link active" data-scroll-target="#introduction-to-knowledge-graph-embedding-resources"><span class="header-section-number">16.1</span> Introduction to Knowledge Graph Embedding Resources</a></li>
  <li><a href="#open-source-libraries-for-knowledge-graph-embeddings" id="toc-open-source-libraries-for-knowledge-graph-embeddings" class="nav-link" data-scroll-target="#open-source-libraries-for-knowledge-graph-embeddings"><span class="header-section-number">16.2</span> Open-Source Libraries for Knowledge Graph Embeddings</a>
  <ul class="collapse">
  <li><a href="#pykeen" id="toc-pykeen" class="nav-link" data-scroll-target="#pykeen"><span class="header-section-number">16.2.1</span> PyKEEN</a></li>
  <li><a href="#dgl-ke" id="toc-dgl-ke" class="nav-link" data-scroll-target="#dgl-ke"><span class="header-section-number">16.2.2</span> DGL-KE</a></li>
  <li><a href="#libkge" id="toc-libkge" class="nav-link" data-scroll-target="#libkge"><span class="header-section-number">16.2.3</span> LibKGE</a></li>
  <li><a href="#ampligraph" id="toc-ampligraph" class="nav-link" data-scroll-target="#ampligraph"><span class="header-section-number">16.2.4</span> AmpliGraph</a></li>
  <li><a href="#torchkge" id="toc-torchkge" class="nav-link" data-scroll-target="#torchkge"><span class="header-section-number">16.2.5</span> TorchKGE</a></li>
  <li><a href="#graphvite" id="toc-graphvite" class="nav-link" data-scroll-target="#graphvite"><span class="header-section-number">16.2.6</span> GraphVite</a></li>
  <li><a href="#openke" id="toc-openke" class="nav-link" data-scroll-target="#openke"><span class="header-section-number">16.2.7</span> OpenKE</a></li>
  </ul></li>
  <li><a href="#benchmark-datasets-and-access-instructions" id="toc-benchmark-datasets-and-access-instructions" class="nav-link" data-scroll-target="#benchmark-datasets-and-access-instructions"><span class="header-section-number">16.3</span> Benchmark Datasets and Access Instructions</a>
  <ul class="collapse">
  <li><a href="#fb15k-and-fb15k-237" id="toc-fb15k-and-fb15k-237" class="nav-link" data-scroll-target="#fb15k-and-fb15k-237"><span class="header-section-number">16.3.1</span> FB15k and FB15k-237</a></li>
  <li><a href="#wn18-and-wn18rr" id="toc-wn18-and-wn18rr" class="nav-link" data-scroll-target="#wn18-and-wn18rr"><span class="header-section-number">16.3.2</span> WN18 and WN18RR</a></li>
  <li><a href="#yago3-10" id="toc-yago3-10" class="nav-link" data-scroll-target="#yago3-10"><span class="header-section-number">16.3.3</span> YAGO3-10</a></li>
  <li><a href="#dbpedia-and-nell" id="toc-dbpedia-and-nell" class="nav-link" data-scroll-target="#dbpedia-and-nell"><span class="header-section-number">16.3.4</span> DBpedia and NELL</a></li>
  <li><a href="#countries" id="toc-countries" class="nav-link" data-scroll-target="#countries"><span class="header-section-number">16.3.5</span> Countries</a></li>
  <li><a href="#newer-benchmark-datasets" id="toc-newer-benchmark-datasets" class="nav-link" data-scroll-target="#newer-benchmark-datasets"><span class="header-section-number">16.3.6</span> Newer Benchmark Datasets</a></li>
  <li><a href="#domain-specific-datasets" id="toc-domain-specific-datasets" class="nav-link" data-scroll-target="#domain-specific-datasets"><span class="header-section-number">16.3.7</span> Domain-Specific Datasets</a></li>
  </ul></li>
  <li><a href="#public-knowledge-graphs-for-experimentation" id="toc-public-knowledge-graphs-for-experimentation" class="nav-link" data-scroll-target="#public-knowledge-graphs-for-experimentation"><span class="header-section-number">16.4</span> Public Knowledge Graphs for Experimentation</a></li>
  <li><a href="#visualization-tools-for-embeddings" id="toc-visualization-tools-for-embeddings" class="nav-link" data-scroll-target="#visualization-tools-for-embeddings"><span class="header-section-number">16.5</span> Visualization Tools for Embeddings</a></li>
  <li><a href="#evaluation-frameworks-and-tools" id="toc-evaluation-frameworks-and-tools" class="nav-link" data-scroll-target="#evaluation-frameworks-and-tools"><span class="header-section-number">16.6</span> Evaluation Frameworks and Tools</a></li>
  <li><a href="#online-courses-and-tutorials" id="toc-online-courses-and-tutorials" class="nav-link" data-scroll-target="#online-courses-and-tutorials"><span class="header-section-number">16.7</span> Online Courses and Tutorials</a></li>
  <li><a href="#research-paper-collections" id="toc-research-paper-collections" class="nav-link" data-scroll-target="#research-paper-collections"><span class="header-section-number">16.8</span> Research Paper Collections</a></li>
  <li><a href="#community-forums-and-discussion-groups" id="toc-community-forums-and-discussion-groups" class="nav-link" data-scroll-target="#community-forums-and-discussion-groups"><span class="header-section-number">16.9</span> Community Forums and Discussion Groups</a></li>
  <li><a href="#competitions-and-challenges" id="toc-competitions-and-challenges" class="nav-link" data-scroll-target="#competitions-and-challenges"><span class="header-section-number">16.10</span> Competitions and Challenges</a></li>
  <li><a href="#industry-applications-and-case-studies" id="toc-industry-applications-and-case-studies" class="nav-link" data-scroll-target="#industry-applications-and-case-studies"><span class="header-section-number">16.11</span> Industry Applications and Case Studies</a></li>
  <li><a href="#additional-tools-for-knowledge-graph-construction" id="toc-additional-tools-for-knowledge-graph-construction" class="nav-link" data-scroll-target="#additional-tools-for-knowledge-graph-construction"><span class="header-section-number">16.12</span> Additional Tools for Knowledge Graph Construction</a></li>
  <li><a href="#performance-benchmarking-resources" id="toc-performance-benchmarking-resources" class="nav-link" data-scroll-target="#performance-benchmarking-resources"><span class="header-section-number">16.13</span> Performance Benchmarking Resources</a></li>
  <li><a href="#api-and-web-services" id="toc-api-and-web-services" class="nav-link" data-scroll-target="#api-and-web-services"><span class="header-section-number">16.14</span> API and Web Services</a></li>
  <li><a href="#pre-trained-knowledge-graph-embeddings" id="toc-pre-trained-knowledge-graph-embeddings" class="nav-link" data-scroll-target="#pre-trained-knowledge-graph-embeddings"><span class="header-section-number">16.15</span> Pre-trained Knowledge Graph Embeddings</a></li>
  <li><a href="#knowledge-graph-reasoning-tools" id="toc-knowledge-graph-reasoning-tools" class="nav-link" data-scroll-target="#knowledge-graph-reasoning-tools"><span class="header-section-number">16.16</span> Knowledge Graph Reasoning Tools</a></li>
  <li><a href="#documentation-and-style-guides" id="toc-documentation-and-style-guides" class="nav-link" data-scroll-target="#documentation-and-style-guides"><span class="header-section-number">16.17</span> Documentation and Style Guides</a></li>
  <li><a href="#integrating-with-deep-learning-frameworks" id="toc-integrating-with-deep-learning-frameworks" class="nav-link" data-scroll-target="#integrating-with-deep-learning-frameworks"><span class="header-section-number">16.18</span> Integrating with Deep Learning Frameworks</a></li>
  <li><a href="#industry-standards-and-formats" id="toc-industry-standards-and-formats" class="nav-link" data-scroll-target="#industry-standards-and-formats"><span class="header-section-number">16.19</span> Industry Standards and Formats</a></li>
  <li><a href="#experimental-and-research-frontiers" id="toc-experimental-and-research-frontiers" class="nav-link" data-scroll-target="#experimental-and-research-frontiers"><span class="header-section-number">16.20</span> Experimental and Research Frontiers</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">16.21</span> Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Appendix B: Resources and Tools</span></h1>
</div>



<div class="quarto-title-meta column-body">

    
  
    
  </div>
  


</header>


<section id="introduction-to-knowledge-graph-embedding-resources" class="level2" data-number="16.1">
<h2 data-number="16.1" class="anchored" data-anchor-id="introduction-to-knowledge-graph-embedding-resources"><span class="header-section-number">16.1</span> Introduction to Knowledge Graph Embedding Resources</h2>
<p>This appendix provides a comprehensive collection of resources, tools, datasets, and libraries for knowledge graph embeddings. The field has seen rapid growth in recent years, resulting in a wealth of resources for both researchers and practitioners. This appendix aims to organize these resources in a structured manner, making it easier for readers to find and utilize the tools they need for their specific knowledge graph embedding tasks.</p>
<p>We begin by listing popular open-source libraries for implementing knowledge graph embedding models, followed by benchmark datasets commonly used for evaluation. We then provide resources for visualizing embeddings, evaluation frameworks, educational resources, and community forums. Finally, we highlight industrial applications and practical case studies that demonstrate the real-world impact of knowledge graph embeddings.</p>
<p>This appendix serves as a practical guide that complements the theoretical knowledge presented in the main chapters, helping readers to apply knowledge graph embedding techniques in their own work.</p>
</section>
<section id="open-source-libraries-for-knowledge-graph-embeddings" class="level2" data-number="16.2">
<h2 data-number="16.2" class="anchored" data-anchor-id="open-source-libraries-for-knowledge-graph-embeddings"><span class="header-section-number">16.2</span> Open-Source Libraries for Knowledge Graph Embeddings</h2>
<p>Several high-quality open-source libraries have been developed for implementing and experimenting with knowledge graph embedding models.</p>
<section id="pykeen" class="level3" data-number="16.2.1">
<h3 data-number="16.2.1" class="anchored" data-anchor-id="pykeen"><span class="header-section-number">16.2.1</span> PyKEEN</h3>
<p>PyKEEN (Python KnowledgE EmbeddiNgs) is one of the most comprehensive libraries for knowledge graph embeddings.</p>
<div id="def-pykeen" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.1 (PyKEEN)</strong></span> <strong>PyKEEN (Python KnowledgE EmbeddiNgs)</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/pykeen/pykeen">https://github.com/pykeen/pykeen</a></li>
<li><strong>Documentation</strong>: <a href="https://pykeen.readthedocs.io">https://pykeen.readthedocs.io</a></li>
<li><strong>Paper</strong>: Ali, M., et al.&nbsp;(2021). PyKEEN 1.0: A Python Library for Training and Evaluating Knowledge Graph Embeddings. Journal of Machine Learning Research, 22(82), 1-6.</li>
</ul>
<p><strong>Key Features</strong>:</p>
<ol type="1">
<li>Implements over 25 knowledge graph embedding models</li>
<li>Provides automated hyper-parameter optimization</li>
<li>Supports multiple training approaches (LCWA, sLCWA)</li>
<li>Includes comprehensive evaluation metrics and protocols</li>
<li>Offers visualization capabilities for embeddings</li>
<li>Provides reproducible benchmarking results</li>
<li>Integrates with popular deep learning frameworks like PyTorch</li>
</ol>
<p><strong>Supported Models</strong>: TransE, TransR, TransD, TransH, DistMult, ComplEx, RESCAL, ConvE, RotatE, QuatE, TuckER, and many more.</p>
</div>
<p>PyKEEN is particularly suitable for researchers due to its comprehensive model selection and strong focus on reproducibility.</p>
</section>
<section id="dgl-ke" class="level3" data-number="16.2.2">
<h3 data-number="16.2.2" class="anchored" data-anchor-id="dgl-ke"><span class="header-section-number">16.2.2</span> DGL-KE</h3>
<p>DGL-KE is a high-performance library built on the Deep Graph Library for scalable knowledge graph embedding.</p>
<div id="def-dgl-ke" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.2 (DGL-KE)</strong></span> <strong>DGL-KE (Deep Graph Library - Knowledge Embedding)</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/awslabs/dgl-ke">https://github.com/awslabs/dgl-ke</a></li>
<li><strong>Documentation</strong>: <a href="https://dglke.dgl.ai">https://dglke.dgl.ai</a></li>
<li><strong>Paper</strong>: Zheng, D., et al.&nbsp;(2020). DGL-KE: Training Knowledge Graph Embeddings at Scale. SIGIR 2020.</li>
</ul>
<p><strong>Key Features</strong>:</p>
<ol type="1">
<li>Optimized for large-scale knowledge graphs</li>
<li>Supports distributed training on multiple GPUs and machines</li>
<li>Implements efficient negative sampling techniques</li>
<li>Provides high-performance evaluation for link prediction</li>
<li>Includes both command-line interface and Python API</li>
<li>Achieves significant speedups compared to other frameworks</li>
</ol>
<p><strong>Supported Models</strong>: TransE, TransR, RESCAL, DistMult, ComplEx, RotatE.</p>
</div>
<p>DGL-KE is particularly suitable for applications involving large-scale knowledge graphs that require distributed training.</p>
</section>
<section id="libkge" class="level3" data-number="16.2.3">
<h3 data-number="16.2.3" class="anchored" data-anchor-id="libkge"><span class="header-section-number">16.2.3</span> LibKGE</h3>
<p>LibKGE is a library focused on reproducible research and hyperparameter optimization for knowledge graph embeddings.</p>
<div id="def-libkge" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.3 (LibKGE)</strong></span> <strong>LibKGE</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/uma-pi1/kge">https://github.com/uma-pi1/kge</a></li>
<li><strong>Documentation</strong>: Available in GitHub repository</li>
<li><strong>Paper</strong>: Ruffinelli, D., Broscheit, S., &amp; Gemulla, R. (2020). You CAN Teach an Old Dog New Tricks! On Training Knowledge Graph Embeddings. ICLR 2020.</li>
</ul>
<p><strong>Key Features</strong>:</p>
<ol type="1">
<li>Focuses on reproducible research</li>
<li>Provides comprehensive hyperparameter optimization</li>
<li>Supports various training strategies</li>
<li>Implements different loss functions and negative sampling techniques</li>
<li>Offers detailed experimental logging and tracking</li>
<li>Enables fair comparison between different models</li>
</ol>
<p><strong>Supported Models</strong>: TransE, DistMult, ComplEx, RESCAL, ConvE, and more.</p>
</div>
<p>LibKGE is particularly valuable for researchers interested in fair and reproducible comparisons between different knowledge graph embedding models.</p>
</section>
<section id="ampligraph" class="level3" data-number="16.2.4">
<h3 data-number="16.2.4" class="anchored" data-anchor-id="ampligraph"><span class="header-section-number">16.2.4</span> AmpliGraph</h3>
<p>AmpliGraph is a library designed for knowledge graph embedding with a focus on accessibility and ease of use.</p>
<div id="def-ampligraph" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.4 (AmpliGraph)</strong></span> <strong>AmpliGraph</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/Accenture/AmpliGraph">https://github.com/Accenture/AmpliGraph</a></li>
<li><strong>Documentation</strong>: <a href="https://docs.ampligraph.org">https://docs.ampligraph.org</a></li>
<li><strong>Paper</strong>: Costabello, L., et al.&nbsp;(2019). AmpliGraph: a Library for Representation Learning on Knowledge Graphs. GitHub repository.</li>
</ul>
<p><strong>Key Features</strong>:</p>
<ol type="1">
<li>User-friendly API inspired by scikit-learn</li>
<li>Supports TensorFlow and PyTorch backends</li>
<li>Provides comprehensive documentation and examples</li>
<li>Implements model selection and hyperparameter optimization</li>
<li>Includes various evaluation metrics</li>
<li>Offers visualization capabilities</li>
</ol>
<p><strong>Supported Models</strong>: TransE, DistMult, ComplEx, HolE, ConvKB, and more.</p>
</div>
<p>AmpliGraph is particularly suitable for practitioners who prioritize ease of use and integration with existing machine learning workflows.</p>
</section>
<section id="torchkge" class="level3" data-number="16.2.5">
<h3 data-number="16.2.5" class="anchored" data-anchor-id="torchkge"><span class="header-section-number">16.2.5</span> TorchKGE</h3>
<p>TorchKGE is a PyTorch-based library for knowledge graph embedding with a focus on simplicity and flexibility.</p>
<div id="def-torchkge" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.5 (TorchKGE)</strong></span> <strong>TorchKGE</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/torchkge-team/torchkge">https://github.com/torchkge-team/torchkge</a></li>
<li><strong>Documentation</strong>: <a href="https://torchkge.readthedocs.io">https://torchkge.readthedocs.io</a></li>
<li><strong>Paper</strong>: Arm, A., et al.&nbsp;(2019). TorchKGE: A Knowledge Graph Embedding Library for PyTorch. GitHub repository.</li>
</ul>
<p><strong>Key Features</strong>:</p>
<ol type="1">
<li>Built on PyTorch for seamless integration with PyTorch workflows</li>
<li>Provides a simple and consistent API</li>
<li>Supports various training and evaluation protocols</li>
<li>Includes visualization tools</li>
<li>Implements efficient negative sampling techniques</li>
<li>Offers examples and tutorials</li>
</ol>
<p><strong>Supported Models</strong>: TransE, TransR, TransD, TransH, DistMult, ComplEx, RESCAL, ConvKB, and more.</p>
</div>
<p>TorchKGE is particularly useful for researchers and practitioners already familiar with PyTorch who want a lightweight and flexible KGE library.</p>
</section>
<section id="graphvite" class="level3" data-number="16.2.6">
<h3 data-number="16.2.6" class="anchored" data-anchor-id="graphvite"><span class="header-section-number">16.2.6</span> GraphVite</h3>
<p>GraphVite is a high-performance system for training graph embeddings with GPU acceleration.</p>
<div id="def-graphvite" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.6 (GraphVite)</strong></span> <strong>GraphVite</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/DeepGraphLearning/graphvite">https://github.com/DeepGraphLearning/graphvite</a></li>
<li><strong>Documentation</strong>: Available in GitHub repository</li>
<li><strong>Paper</strong>: Zhu, Z., et al.&nbsp;(2019). GraphVite: A High-Performance CPU-GPU Hybrid System for Node Embedding. WWW 2019.</li>
</ul>
<p><strong>Key Features</strong>:</p>
<ol type="1">
<li>Highly optimized CPU-GPU hybrid implementation</li>
<li>Supports large-scale knowledge graphs</li>
<li>Provides efficient parallel training</li>
<li>Implements various embedding algorithms</li>
<li>Includes comprehensive evaluation tools</li>
<li>Offers significant speedups compared to other implementations</li>
</ol>
<p><strong>Supported Models</strong>: TransE, DistMult, ComplEx, SimplE, RotatE, and more.</p>
</div>
<p>GraphVite is particularly suitable for applications requiring high-performance training on large-scale knowledge graphs.</p>
</section>
<section id="openke" class="level3" data-number="16.2.7">
<h3 data-number="16.2.7" class="anchored" data-anchor-id="openke"><span class="header-section-number">16.2.7</span> OpenKE</h3>
<p>OpenKE is one of the earliest comprehensive knowledge graph embedding frameworks.</p>
<div id="def-openke" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.7 (OpenKE)</strong></span> <strong>OpenKE</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/thunlp/OpenKE">https://github.com/thunlp/OpenKE</a></li>
<li><strong>Documentation</strong>: Available in GitHub repository</li>
<li><strong>Paper</strong>: Han, X., et al.&nbsp;(2018). OpenKE: An Open Toolkit for Knowledge Embedding. EMNLP 2018.</li>
</ul>
<p><strong>Key Features</strong>:</p>
<ol type="1">
<li>Implemented in C++ with Python interfaces</li>
<li>Provides efficient training with multi-threading</li>
<li>Supports various knowledge graph embedding models</li>
<li>Includes both training and evaluation tools</li>
<li>Offers TensorFlow and PyTorch interfaces</li>
<li>Provides pre-trained embeddings for common datasets</li>
</ol>
<p><strong>Supported Models</strong>: TransE, TransD, TransR, TransH, DistMult, ComplEx, RESCAL, HolE, and more.</p>
</div>
<p>OpenKE is a mature library that has been used in many research papers and practical applications.</p>
</section>
</section>
<section id="benchmark-datasets-and-access-instructions" class="level2" data-number="16.3">
<h2 data-number="16.3" class="anchored" data-anchor-id="benchmark-datasets-and-access-instructions"><span class="header-section-number">16.3</span> Benchmark Datasets and Access Instructions</h2>
<p>Standard benchmark datasets are essential for evaluating and comparing knowledge graph embedding models.</p>
<section id="fb15k-and-fb15k-237" class="level3" data-number="16.3.1">
<h3 data-number="16.3.1" class="anchored" data-anchor-id="fb15k-and-fb15k-237"><span class="header-section-number">16.3.1</span> FB15k and FB15k-237</h3>
<p>FB15k is derived from Freebase and has been a standard benchmark, while FB15k-237 is a subset that addresses certain biases.</p>
<div id="def-fb15k" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.8 (FB15k and FB15k-237)</strong></span> <strong>FB15k</strong></p>
<ul>
<li><strong>Source</strong>: Subset of Freebase</li>
<li><strong>Original Paper</strong>: Bordes, A., et al.&nbsp;(2013). Translating Embeddings for Modeling Multi-relational Data. NIPS 2013.</li>
<li><strong>Access</strong>: Available through most KGE libraries and <a href="https://github.com/thunlp/KB2E">https://github.com/thunlp/KB2E</a></li>
<li><strong>Statistics</strong>: 14,951 entities, 1,345 relations, 483,142 training triples, 50,000 validation triples, 59,071 test triples</li>
</ul>
<p><strong>FB15k-237</strong></p>
<ul>
<li><strong>Source</strong>: Modified version of FB15k with inverse relations removed</li>
<li><strong>Original Paper</strong>: Toutanova, K., &amp; Chen, D. (2015). Observed versus latent features for knowledge base and text inference. ACL Workshop on Continuous Vector Space Models and their Compositionality.</li>
<li><strong>Access</strong>: Available through most KGE libraries and <a href="https://github.com/TimDettmers/ConvE">https://github.com/TimDettmers/ConvE</a></li>
<li><strong>Statistics</strong>: 14,541 entities, 237 relations, 272,115 training triples, 17,535 validation triples, 20,466 test triples</li>
</ul>
</div>
<p>FB15k-237 is generally preferred over FB15k for evaluation due to its removal of inverse relations, which prevents models from achieving artificially high performance through simple inverse relation matching.</p>
</section>
<section id="wn18-and-wn18rr" class="level3" data-number="16.3.2">
<h3 data-number="16.3.2" class="anchored" data-anchor-id="wn18-and-wn18rr"><span class="header-section-number">16.3.2</span> WN18 and WN18RR</h3>
<p>WN18 is derived from WordNet, while WN18RR is a subset that addresses certain biases.</p>
<div id="def-wn18" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.9 (WN18 and WN18RR)</strong></span> <strong>WN18</strong></p>
<ul>
<li><strong>Source</strong>: Subset of WordNet</li>
<li><strong>Original Paper</strong>: Bordes, A., et al.&nbsp;(2013). Translating Embeddings for Modeling Multi-relational Data. NIPS 2013.</li>
<li><strong>Access</strong>: Available through most KGE libraries and <a href="https://github.com/thunlp/KB2E">https://github.com/thunlp/KB2E</a></li>
<li><strong>Statistics</strong>: 40,943 entities, 18 relations, 141,442 training triples, 5,000 validation triples, 5,000 test triples</li>
</ul>
<p><strong>WN18RR</strong></p>
<ul>
<li><strong>Source</strong>: Modified version of WN18 with inverse relations removed</li>
<li><strong>Original Paper</strong>: Dettmers, T., et al.&nbsp;(2018). Convolutional 2D Knowledge Graph Embeddings. AAAI 2018.</li>
<li><strong>Access</strong>: Available through most KGE libraries and <a href="https://github.com/TimDettmers/ConvE">https://github.com/TimDettmers/ConvE</a></li>
<li><strong>Statistics</strong>: 40,943 entities, 11 relations, 86,835 training triples, 3,034 validation triples, 3,134 test triples</li>
</ul>
</div>
<p>Similar to FB15k-237, WN18RR is generally preferred over WN18 for evaluation due to its removal of inverse relations.</p>
</section>
<section id="yago3-10" class="level3" data-number="16.3.3">
<h3 data-number="16.3.3" class="anchored" data-anchor-id="yago3-10"><span class="header-section-number">16.3.3</span> YAGO3-10</h3>
<p>YAGO3-10 is a subset of the YAGO3 knowledge base.</p>
<div id="def-yago3-10" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.10 (YAGO3-10)</strong></span> <strong>YAGO3-10</strong></p>
<ul>
<li><strong>Source</strong>: Subset of YAGO3</li>
<li><strong>Original Paper</strong>: Dettmers, T., et al.&nbsp;(2018). Convolutional 2D Knowledge Graph Embeddings. AAAI 2018.</li>
<li><strong>Access</strong>: Available through most KGE libraries and <a href="https://github.com/TimDettmers/ConvE">https://github.com/TimDettmers/ConvE</a></li>
<li><strong>Statistics</strong>: 123,182 entities, 37 relations, 1,079,040 training triples, 5,000 validation triples, 5,000 test triples</li>
</ul>
</div>
<p>YAGO3-10 is larger than FB15k-237 and WN18RR, making it useful for evaluating model scalability.</p>
</section>
<section id="dbpedia-and-nell" class="level3" data-number="16.3.4">
<h3 data-number="16.3.4" class="anchored" data-anchor-id="dbpedia-and-nell"><span class="header-section-number">16.3.4</span> DBpedia and NELL</h3>
<p>These datasets are derived from DBpedia and the Never-Ending Language Learning (NELL) project.</p>
<div id="def-dbpedia-nell" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.11 (DBpedia and NELL)</strong></span> <strong>DB100k (DBpedia Subset)</strong></p>
<ul>
<li><strong>Source</strong>: Subset of DBpedia</li>
<li><strong>Access</strong>: Available through some KGE libraries and academic repositories</li>
<li><strong>Statistics</strong>: ~100,000 entities, ~470 relations, ~600,000 triples</li>
</ul>
<p><strong>NELL-995</strong></p>
<ul>
<li><strong>Source</strong>: Subset of NELL (Never-Ending Language Learning)</li>
<li><strong>Original Paper</strong>: Xiong, W., et al.&nbsp;(2017). DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning. EMNLP 2017.</li>
<li><strong>Access</strong>: <a href="https://github.com/xwhan/DeepPath">https://github.com/xwhan/DeepPath</a></li>
<li><strong>Statistics</strong>: 75,492 entities, 200 relations, 154,213 triples</li>
</ul>
</div>
<p>These datasets provide additional diversity in terms of domain and structure for evaluating knowledge graph embedding models.</p>
</section>
<section id="countries" class="level3" data-number="16.3.5">
<h3 data-number="16.3.5" class="anchored" data-anchor-id="countries"><span class="header-section-number">16.3.5</span> Countries</h3>
<p>Countries is a small dataset specifically designed to test reasoning capabilities.</p>
<div id="def-countries" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.12 (Countries)</strong></span> <strong>Countries</strong></p>
<ul>
<li><strong>Source</strong>: Created specifically for testing multi-hop reasoning</li>
<li><strong>Original Paper</strong>: Bouchard, G., et al.&nbsp;(2015). On Approximate Reasoning Capabilities of Low-Rank Vector Spaces. AAAI Spring Symposium Series.</li>
<li><strong>Access</strong>: <a href="https://github.com/pykeen/pykeen/tree/master/src/pykeen/datasets/countries">https://github.com/pykeen/pykeen/tree/master/src/pykeen/datasets/countries</a></li>
<li><strong>Statistics</strong>: 271 entities, 2 relations, 1,158 triples, divided into increasingly difficult tasks (S1, S2, S3)</li>
</ul>
</div>
<p>The Countries dataset is particularly useful for evaluating a modelâ€™s ability to perform multi-hop reasoning.</p>
</section>
<section id="newer-benchmark-datasets" class="level3" data-number="16.3.6">
<h3 data-number="16.3.6" class="anchored" data-anchor-id="newer-benchmark-datasets"><span class="header-section-number">16.3.6</span> Newer Benchmark Datasets</h3>
<p>Several newer datasets have been introduced to address limitations of earlier benchmarks.</p>
<div id="def-newer-datasets" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.13 (Newer Benchmark Datasets)</strong></span> <strong>FB15k-237-OWE</strong></p>
<ul>
<li><strong>Source</strong>: Extension of FB15k-237 for open-world embedding</li>
<li><strong>Original Paper</strong>: Mohamed, S. K., et al.&nbsp;(2020). Loss Functions for Entity Alignments in Knowledge Graphs. Semantic Web Journal.</li>
<li><strong>Access</strong>: <a href="https://github.com/samehkamaleldin/fb15k-237-owe">https://github.com/samehkamaleldin/fb15k-237-owe</a></li>
</ul>
<p><strong>CODEX</strong></p>
<ul>
<li><strong>Source</strong>: Comprehensive Dataset Extraction from Wikidata</li>
<li><strong>Original Paper</strong>: Safavi, T., &amp; Koutra, D. (2020). CoDEx: A Comprehensive Knowledge Graph Completion Benchmark. EMNLP 2020.</li>
<li><strong>Access</strong>: <a href="https://github.com/tsafavi/codex">https://github.com/tsafavi/codex</a></li>
<li><strong>Variants</strong>: CoDEx-S (small), CoDEx-M (medium), CoDEx-L (large)</li>
</ul>
<p><strong>OGB (Open Graph Benchmark) Knowledge Graphs</strong></p>
<ul>
<li><strong>Source</strong>: Various sources for large-scale evaluation</li>
<li><strong>Original Paper</strong>: Hu, W., et al.&nbsp;(2020). Open Graph Benchmark: Datasets for Machine Learning on Graphs. NeurIPS 2020.</li>
<li><strong>Access</strong>: <a href="https://ogb.stanford.edu/docs/linkprop/">https://ogb.stanford.edu/docs/linkprop/</a></li>
<li><strong>Variants</strong>: ogbl-wikikg2, ogbl-biokg</li>
</ul>
</div>
<p>These newer datasets address various limitations of earlier benchmarks and provide additional challenges for evaluating knowledge graph embedding models.</p>
</section>
<section id="domain-specific-datasets" class="level3" data-number="16.3.7">
<h3 data-number="16.3.7" class="anchored" data-anchor-id="domain-specific-datasets"><span class="header-section-number">16.3.7</span> Domain-Specific Datasets</h3>
<p>Various domain-specific knowledge graph datasets are available for specialized applications.</p>
<div id="def-domain-datasets" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.14 (Domain-Specific Datasets)</strong></span> <strong>Biomedical Datasets</strong></p>
<ul>
<li><strong>Bio2RDF</strong>: Linked data for the life sciences <a href="http://bio2rdf.org/">http://bio2rdf.org/</a></li>
<li><strong>Hetionet</strong>: Integrative network of biomedical knowledge <a href="https://github.com/hetio/hetionet">https://github.com/hetio/hetionet</a></li>
<li><strong>UMLS</strong>: Unified Medical Language System <a href="https://www.nlm.nih.gov/research/umls/">https://www.nlm.nih.gov/research/umls/</a></li>
</ul>
<p><strong>Scientific Literature Datasets</strong></p>
<ul>
<li><strong>ORKG</strong>: Open Research Knowledge Graph <a href="https://www.orkg.org/">https://www.orkg.org/</a></li>
<li><strong>AIDA</strong>: Academic Institution Database Augmented <a href="https://github.com/allenai/aida">https://github.com/allenai/aida</a></li>
</ul>
<p><strong>E-commerce Datasets</strong></p>
<ul>
<li><strong>Amazon-Books</strong>: Knowledge graph derived from Amazon product metadata <a href="https://github.com/zhenjiezhang/KGRecsys">https://github.com/zhenjiezhang/KGRecsys</a></li>
<li><strong>Alibaba-iFashion</strong>: Fashion knowledge graph for recommendation <a href="https://github.com/xiangwang1223/KB4Rec">https://github.com/xiangwang1223/KB4Rec</a></li>
</ul>
</div>
<p>Domain-specific datasets are valuable for developing and evaluating knowledge graph embedding models for particular applications.</p>
</section>
</section>
<section id="public-knowledge-graphs-for-experimentation" class="level2" data-number="16.4">
<h2 data-number="16.4" class="anchored" data-anchor-id="public-knowledge-graphs-for-experimentation"><span class="header-section-number">16.4</span> Public Knowledge Graphs for Experimentation</h2>
<p>Several large-scale public knowledge graphs are available for experimentation beyond the standard benchmarks.</p>
<div id="def-public-kgs" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.15 (Public Knowledge Graphs)</strong></span> <strong>Wikidata</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://www.wikidata.org/">https://www.wikidata.org/</a></li>
<li><strong>Access</strong>: Various dumps available at <a href="https://dumps.wikimedia.org/wikidatawiki/entities/">https://dumps.wikimedia.org/wikidatawiki/entities/</a></li>
<li><strong>Scale</strong>: ~100 million entities, ~1 billion statements</li>
</ul>
<p><strong>DBpedia</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://www.dbpedia.org/">https://www.dbpedia.org/</a></li>
<li><strong>Access</strong>: Various downloads available at <a href="https://databus.dbpedia.org/">https://databus.dbpedia.org/</a></li>
<li><strong>Scale</strong>: ~4.5 million entities, ~500 million facts</li>
</ul>
<p><strong>YAGO</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://yago-knowledge.org/">https://yago-knowledge.org/</a></li>
<li><strong>Access</strong>: Downloads available at <a href="https://yago-knowledge.org/downloads/">https://yago-knowledge.org/downloads/</a></li>
<li><strong>Scale</strong>: ~10 million entities, ~120 million facts</li>
</ul>
<p><strong>ConceptNet</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://conceptnet.io/">https://conceptnet.io/</a></li>
<li><strong>Access</strong>: Downloads available at <a href="https://github.com/commonsense/conceptnet5/wiki/Downloads">https://github.com/commonsense/conceptnet5/wiki/Downloads</a></li>
<li><strong>Scale</strong>: ~8 million entities, ~34 million relations</li>
</ul>
<p><strong>BabelNet</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://babelnet.org/">https://babelnet.org/</a></li>
<li><strong>Access</strong>: Available through API (registration required)</li>
<li><strong>Scale</strong>: ~16 million entities, ~380 million relations</li>
</ul>
</div>
<p>These public knowledge graphs provide real-world data at scale for experimenting with knowledge graph embedding techniques.</p>
</section>
<section id="visualization-tools-for-embeddings" class="level2" data-number="16.5">
<h2 data-number="16.5" class="anchored" data-anchor-id="visualization-tools-for-embeddings"><span class="header-section-number">16.5</span> Visualization Tools for Embeddings</h2>
<p>Visualization tools help understand and interpret knowledge graph embeddings.</p>
<div id="def-visualization-tools" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.16 (Visualization Tools)</strong></span> <strong>Embedding Projector</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://projector.tensorflow.org/">https://projector.tensorflow.org/</a></li>
<li><strong>Features</strong>: Web-based visualization of high-dimensional data, supports PCA, t-SNE, and UMAP projections</li>
<li><strong>Integration</strong>: Compatible with TensorFlow and general embedding formats</li>
</ul>
<p><strong>PIXIE</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/marcalph/pixie">https://github.com/marcalph/pixie</a></li>
<li><strong>Features</strong>: Interactive visualization of word and graph embeddings, supports various dimensionality reduction techniques</li>
</ul>
<p><strong>PyKEEN Visualizations</strong></p>
<ul>
<li><strong>Documentation</strong>: <a href="https://pykeen.readthedocs.io/en/stable/tutorial/visualization.html">https://pykeen.readthedocs.io/en/stable/tutorial/visualization.html</a></li>
<li><strong>Features</strong>: Built-in visualization capabilities for knowledge graph embeddings, entity clusters, and relation patterns</li>
</ul>
<p><strong>Embedding Navigator</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/ieg-vienna/embeddingnav">https://github.com/ieg-vienna/embeddingnav</a></li>
<li><strong>Features</strong>: Interactive exploration of embeddings with multiple coordinated views</li>
</ul>
<p><strong>graph-tool Visualization</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://graph-tool.skewed.de/">https://graph-tool.skewed.de/</a></li>
<li><strong>Features</strong>: Efficient tools for graph visualization and analysis, can be used with knowledge graph embeddings</li>
</ul>
</div>
<p>Visualization tools are essential for understanding the structure and patterns captured by knowledge graph embeddings.</p>
</section>
<section id="evaluation-frameworks-and-tools" class="level2" data-number="16.6">
<h2 data-number="16.6" class="anchored" data-anchor-id="evaluation-frameworks-and-tools"><span class="header-section-number">16.6</span> Evaluation Frameworks and Tools</h2>
<p>Evaluation frameworks provide standardized methods for assessing knowledge graph embedding models.</p>
<div id="def-evaluation-frameworks" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.17 (Evaluation Frameworks and Tools)</strong></span> <strong>LPBench</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/pykeen/lpbench">https://github.com/pykeen/lpbench</a></li>
<li><strong>Features</strong>: Benchmarking for link prediction models, standardized evaluation protocols</li>
</ul>
<p><strong>KGEB (Knowledge Graph Embedding Benchmark)</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/ZhenfengLei/KGEBench">https://github.com/ZhenfengLei/KGEBench</a></li>
<li><strong>Features</strong>: Comprehensive benchmark for knowledge graph embedding models, includes various datasets and evaluation metrics</li>
</ul>
<p><strong>OpenKE Benchmarks</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/thunlp/OpenKE/tree/OpenKE-PyTorch/benchmarks">https://github.com/thunlp/OpenKE/tree/OpenKE-PyTorch/benchmarks</a></li>
<li><strong>Features</strong>: Standard benchmarks for various knowledge graph embedding models</li>
</ul>
<p><strong>PyKEEN Benchmarking</strong></p>
<ul>
<li><strong>Documentation</strong>: <a href="https://pykeen.readthedocs.io/en/stable/reference/benchmarking.html">https://pykeen.readthedocs.io/en/stable/reference/benchmarking.html</a></li>
<li><strong>Features</strong>: Built-in benchmarking capabilities, reproducibility of published results</li>
</ul>
</div>
<p>Standardized evaluation frameworks ensure fair and reproducible comparisons between different knowledge graph embedding models.</p>
</section>
<section id="online-courses-and-tutorials" class="level2" data-number="16.7">
<h2 data-number="16.7" class="anchored" data-anchor-id="online-courses-and-tutorials"><span class="header-section-number">16.7</span> Online Courses and Tutorials</h2>
<p>Several online resources provide educational content on knowledge graph embeddings.</p>
<div id="def-courses-tutorials" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.18 (Online Courses and Tutorials)</strong></span> <strong>Stanford CS224W: Machine Learning with Graphs</strong></p>
<ul>
<li><strong>Website</strong>: <a href="http://web.stanford.edu/class/cs224w/">http://web.stanford.edu/class/cs224w/</a></li>
<li><strong>Features</strong>: Comprehensive course on graph machine learning, includes lectures on knowledge graph embeddings</li>
</ul>
<p><strong>Knowledge Graph Tutorial by Azure Cognitive Services</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://learn.microsoft.com/en-us/azure/cognitive-services/qnamaker/concepts/knowledge-graph">https://learn.microsoft.com/en-us/azure/cognitive-services/qnamaker/concepts/knowledge-graph</a></li>
<li><strong>Features</strong>: Practical tutorial on building and using knowledge graphs</li>
</ul>
<p><strong>PyKEEN Tutorials</strong></p>
<ul>
<li><strong>Documentation</strong>: <a href="https://pykeen.readthedocs.io/en/stable/tutorial/">https://pykeen.readthedocs.io/en/stable/tutorial/</a></li>
<li><strong>Features</strong>: Step-by-step tutorials on implementing and evaluating knowledge graph embedding models</li>
</ul>
<p><strong>Knowledge Graph Embeddings Tutorial (EMNLP 2019)</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://kge-tutorial-emnlp19.github.io/">https://kge-tutorial-emnlp19.github.io/</a></li>
<li><strong>Features</strong>: Comprehensive tutorial on knowledge graph embeddings by leading researchers</li>
</ul>
<p><strong>Neo4j Graph Data Science Library Tutorials</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://neo4j.com/docs/graph-data-science/current/">https://neo4j.com/docs/graph-data-science/current/</a></li>
<li><strong>Features</strong>: Tutorials on applying graph embeddings to Neo4j knowledge graphs</li>
</ul>
</div>
<p>These educational resources provide structured learning paths for understanding and implementing knowledge graph embeddings.</p>
</section>
<section id="research-paper-collections" class="level2" data-number="16.8">
<h2 data-number="16.8" class="anchored" data-anchor-id="research-paper-collections"><span class="header-section-number">16.8</span> Research Paper Collections</h2>
<p>Curated collections of research papers help navigate the vast literature on knowledge graph embeddings.</p>
<div id="def-paper-collections" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.19 (Research Paper Collections)</strong></span> <strong>Knowledge Graph Embedding Papers by THUNLP</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/thunlp/KRLPapers">https://github.com/thunlp/KRLPapers</a></li>
<li><strong>Features</strong>: Comprehensive list of papers on knowledge representation learning</li>
</ul>
<p><strong>Graph Embedding Papers</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/chihming/awesome-network-embedding">https://github.com/chihming/awesome-network-embedding</a></li>
<li><strong>Features</strong>: Collection of papers on network and graph embeddings, including knowledge graphs</li>
</ul>
<p><strong>Papers with Code: Knowledge Graph Embeddings</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://paperswithcode.com/task/knowledge-graph-embeddings">https://paperswithcode.com/task/knowledge-graph-embeddings</a></li>
<li><strong>Features</strong>: Papers on knowledge graph embeddings with associated code implementations</li>
</ul>
<p><strong>Semantic Scholar: Knowledge Graph Embeddings</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://www.semanticscholar.org/topic/Knowledge-Graph-Embedding/2288">https://www.semanticscholar.org/topic/Knowledge-Graph-Embedding/2288</a></li>
<li><strong>Features</strong>: Research papers on knowledge graph embeddings with citation information and related work</li>
</ul>
</div>
<p>These collections provide convenient access to the research literature on knowledge graph embeddings.</p>
</section>
<section id="community-forums-and-discussion-groups" class="level2" data-number="16.9">
<h2 data-number="16.9" class="anchored" data-anchor-id="community-forums-and-discussion-groups"><span class="header-section-number">16.9</span> Community Forums and Discussion Groups</h2>
<p>Community forums provide platforms for discussion, questions, and sharing of knowledge about knowledge graph embeddings.</p>
<div id="def-community-forums" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.20 (Community Forums and Discussion Groups)</strong></span> <strong>Stack Overflow: Knowledge-Graph Tag</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://stackoverflow.com/questions/tagged/knowledge-graph">https://stackoverflow.com/questions/tagged/knowledge-graph</a></li>
<li><strong>Features</strong>: Q&amp;A forum for technical questions about knowledge graphs</li>
</ul>
<p><strong>PyKEEN GitHub Discussions</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://github.com/pykeen/pykeen/discussions">https://github.com/pykeen/pykeen/discussions</a></li>
<li><strong>Features</strong>: Discussion forum for PyKEEN users and developers</li>
</ul>
<p><strong>Knowledge Graph Conference Community</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://www.knowledgegraph.tech/the-knowledge-graph-community/">https://www.knowledgegraph.tech/the-knowledge-graph-community/</a></li>
<li><strong>Features</strong>: Community resources, events, and discussions related to knowledge graphs</li>
</ul>
<p><strong>Reddit: r/MachineLearning</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://www.reddit.com/r/MachineLearning/">https://www.reddit.com/r/MachineLearning/</a></li>
<li><strong>Features</strong>: Discussions on machine learning, including knowledge graph embeddings</li>
</ul>
<p><strong>Discord: Artificial Intelligence</strong></p>
<ul>
<li><strong>Website</strong>: Various AI-focused Discord servers</li>
<li><strong>Features</strong>: Real-time chat and discussion with researchers and practitioners</li>
</ul>
</div>
<p>Community forums provide opportunities to ask questions, share experiences, and connect with others working on knowledge graph embeddings.</p>
</section>
<section id="competitions-and-challenges" class="level2" data-number="16.10">
<h2 data-number="16.10" class="anchored" data-anchor-id="competitions-and-challenges"><span class="header-section-number">16.10</span> Competitions and Challenges</h2>
<p>Competitions and challenges provide opportunities to test and improve knowledge graph embedding models.</p>
<div id="def-competitions-challenges" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.21 (Competitions and Challenges)</strong></span> <strong>Open Graph Benchmark (OGB) Leaderboards</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://ogb.stanford.edu/docs/leader_linkprop/">https://ogb.stanford.edu/docs/leader_linkprop/</a></li>
<li><strong>Features</strong>: Leaderboards for link prediction on various knowledge graphs</li>
</ul>
<p><strong>Knowledge Graph Completion at WSDM Cup</strong></p>
<ul>
<li><strong>Website</strong>: Various WSDM Cup challenges</li>
<li><strong>Features</strong>: Periodic competitions on knowledge graph completion tasks</li>
</ul>
<p><strong>ICLR Graph Representation Learning Challenges</strong></p>
<ul>
<li><strong>Website</strong>: Various ICLR workshop challenges</li>
<li><strong>Features</strong>: Research challenges focused on graph representation learning</li>
</ul>
<p><strong>SemEval Tasks</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://semeval.github.io/">https://semeval.github.io/</a></li>
<li><strong>Features</strong>: Semantic evaluation tasks, occasionally including knowledge graph-related challenges</li>
</ul>
</div>
<p>Participating in competitions and challenges can provide benchmarks for evaluating knowledge graph embedding methods and opportunities for improvement.</p>
</section>
<section id="industry-applications-and-case-studies" class="level2" data-number="16.11">
<h2 data-number="16.11" class="anchored" data-anchor-id="industry-applications-and-case-studies"><span class="header-section-number">16.11</span> Industry Applications and Case Studies</h2>
<p>Real-world applications and case studies demonstrate the practical impact of knowledge graph embeddings.</p>
<div id="def-industry-applications" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.22 (Industry Applications and Case Studies)</strong></span> <strong>Google Knowledge Graph</strong></p>
<ul>
<li><strong>Article</strong>: Singhal, A. (2012). Introducing the Knowledge Graph: things, not strings. Google Blog.</li>
<li><strong>Application</strong>: Enhanced search results, question answering, and entity disambiguation</li>
</ul>
<p><strong>Amazon Product Knowledge Graph</strong></p>
<ul>
<li><strong>Paper</strong>: Dong, X. (2018). Challenges and Innovations in Building a Product Knowledge Graph. KDD 2018.</li>
<li><strong>Application</strong>: Product recommendations, search enhancement, and catalog management</li>
</ul>
<p><strong>LinkedIn Economic Graph</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://economicgraph.linkedin.com/">https://economicgraph.linkedin.com/</a></li>
<li><strong>Application</strong>: Labor market insights, skill recommendations, and career path analysis</li>
</ul>
<p><strong>Uber Knowledge Graph</strong></p>
<ul>
<li><strong>Article</strong>: Uber Engineering. (2018). Uberâ€™s Big Data Platform: 100+ Petabytes with Minute Latency. Uber Engineering Blog.</li>
<li><strong>Application</strong>: Location understanding, mapping, and operational optimization</li>
</ul>
<p><strong>Microsoft Academic Knowledge Graph</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://aka.ms/mskg">https://aka.ms/mskg</a></li>
<li><strong>Application</strong>: Academic search, researcher recommendations, and scientific trend analysis</li>
</ul>
</div>
<p>Industry applications demonstrate the practical value of knowledge graph embeddings in various domains.</p>
</section>
<section id="additional-tools-for-knowledge-graph-construction" class="level2" data-number="16.12">
<h2 data-number="16.12" class="anchored" data-anchor-id="additional-tools-for-knowledge-graph-construction"><span class="header-section-number">16.12</span> Additional Tools for Knowledge Graph Construction</h2>
<p>Tools for constructing and managing knowledge graphs complement embedding techniques.</p>
<div id="def-kg-construction-tools" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.23 (Knowledge Graph Construction Tools)</strong></span> <strong>Neo4j</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://neo4j.com/">https://neo4j.com/</a></li>
<li><strong>Features</strong>: Graph database with support for knowledge graph management and querying</li>
</ul>
<p><strong>GraphDB</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://graphdb.ontotext.com/">https://graphdb.ontotext.com/</a></li>
<li><strong>Features</strong>: Semantic graph database optimized for RDF and SPARQL</li>
</ul>
<p><strong>Stardog</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://www.stardog.com/">https://www.stardog.com/</a></li>
<li><strong>Features</strong>: Enterprise knowledge graph platform with reasoning capabilities</li>
</ul>
<p><strong>OpenRefine</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://openrefine.org/">https://openrefine.org/</a></li>
<li><strong>Features</strong>: Tool for cleaning and transforming data for knowledge graph construction</li>
</ul>
<p><strong>Stanford CoreNLP</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://stanfordnlp.github.io/CoreNLP/">https://stanfordnlp.github.io/CoreNLP/</a></li>
<li><strong>Features</strong>: Natural language processing tools for extracting knowledge from text</li>
</ul>
</div>
<p>These tools facilitate the construction and management of knowledge graphs, which can then be enhanced with embedding techniques.</p>
</section>
<section id="performance-benchmarking-resources" class="level2" data-number="16.13">
<h2 data-number="16.13" class="anchored" data-anchor-id="performance-benchmarking-resources"><span class="header-section-number">16.13</span> Performance Benchmarking Resources</h2>
<p>Resources for benchmarking the performance of knowledge graph embedding models on various hardware.</p>
<div id="def-performance-benchmarking" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.24 (Performance Benchmarking Resources)</strong></span> <strong>DGL-KE Benchmarks</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/awslabs/dgl-ke/tree/master/benchmark">https://github.com/awslabs/dgl-ke/tree/master/benchmark</a></li>
<li><strong>Features</strong>: Performance benchmarks for various knowledge graph embedding models on different hardware configurations</li>
</ul>
<p><strong>GraphVite Benchmarks</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/DeepGraphLearning/graphvite/tree/master/benchmark">https://github.com/DeepGraphLearning/graphvite/tree/master/benchmark</a></li>
<li><strong>Features</strong>: Performance comparisons between GraphVite and other frameworks</li>
</ul>
<p><strong>PyKEEN Memory and Runtime Profiling</strong></p>
<ul>
<li><strong>Documentation</strong>: <a href="https://pykeen.readthedocs.io/en/stable/reference/performance.html">https://pykeen.readthedocs.io/en/stable/reference/performance.html</a></li>
<li><strong>Features</strong>: Tools for profiling memory usage and runtime of knowledge graph embedding models</li>
</ul>
<p><strong>OGB Benchmark Results</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://ogb.stanford.edu/docs/leader_linkprop/">https://ogb.stanford.edu/docs/leader_linkprop/</a></li>
<li><strong>Features</strong>: Performance benchmarks for various models on standardized datasets</li>
</ul>
<p><strong>Hardware-Accelerated Graph Learning Benchmarks</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/DGLPyTorch">https://github.com/NVIDIA/DeepLearningExamples/tree/master/DGLPyTorch</a></li>
<li><strong>Features</strong>: Benchmarks for accelerating graph learning, including knowledge graph embeddings, with NVIDIA hardware</li>
</ul>
</div>
<p>These resources help evaluate the computational efficiency of knowledge graph embedding models, which is crucial for large-scale applications.</p>
</section>
<section id="api-and-web-services" class="level2" data-number="16.14">
<h2 data-number="16.14" class="anchored" data-anchor-id="api-and-web-services"><span class="header-section-number">16.14</span> API and Web Services</h2>
<p>Several APIs and web services provide access to knowledge graph embeddings and related functionality.</p>
<div id="def-api-services" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.25 (API and Web Services)</strong></span> <strong>Google Knowledge Graph API</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://developers.google.com/knowledge-graph">https://developers.google.com/knowledge-graph</a></li>
<li><strong>Features</strong>: Access to Googleâ€™s Knowledge Graph for entity search and information retrieval</li>
</ul>
<p><strong>Wikidata Query Service</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://query.wikidata.org/">https://query.wikidata.org/</a></li>
<li><strong>Features</strong>: SPARQL endpoint for querying Wikidata</li>
</ul>
<p><strong>DBpedia Spotlight</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://www.dbpedia-spotlight.org/">https://www.dbpedia-spotlight.org/</a></li>
<li><strong>Features</strong>: API for entity linking and knowledge graph integration</li>
</ul>
<p><strong>Microsoft Concept Graph</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://concept.research.microsoft.com/">https://concept.research.microsoft.com/</a></li>
<li><strong>Features</strong>: API for accessing concept relationships</li>
</ul>
<p><strong>SciGraph API</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://scigraph.springernature.com/">https://scigraph.springernature.com/</a></li>
<li><strong>Features</strong>: Access to scholarly knowledge graphs</li>
</ul>
</div>
<p>These services provide convenient access to knowledge graph data and functionality without requiring local infrastructure.</p>
</section>
<section id="pre-trained-knowledge-graph-embeddings" class="level2" data-number="16.15">
<h2 data-number="16.15" class="anchored" data-anchor-id="pre-trained-knowledge-graph-embeddings"><span class="header-section-number">16.15</span> Pre-trained Knowledge Graph Embeddings</h2>
<p>Pre-trained knowledge graph embeddings can be useful for transfer learning and applications.</p>
<div id="def-pretrained-embeddings" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.26 (Pre-trained Knowledge Graph Embeddings)</strong></span> <strong>PyKEEN Pre-trained Models</strong></p>
<ul>
<li><strong>Documentation</strong>: <a href="https://pykeen.readthedocs.io/en/stable/reference/pretrained.html">https://pykeen.readthedocs.io/en/stable/reference/pretrained.html</a></li>
<li><strong>Features</strong>: Pre-trained knowledge graph embedding models for various datasets</li>
</ul>
<p><strong>OpenKE Pre-trained Embeddings</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/thunlp/OpenKE/tree/OpenKE-PyTorch/checkpoint">https://github.com/thunlp/OpenKE/tree/OpenKE-PyTorch/checkpoint</a></li>
<li><strong>Features</strong>: Pre-trained embeddings for FB15K, WN18, and other datasets</li>
</ul>
<p><strong>KG-BERT Pre-trained Models</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/yao8839836/kg-bert">https://github.com/yao8839836/kg-bert</a></li>
<li><strong>Features</strong>: Pre-trained BERT-based knowledge graph embedding models</li>
</ul>
<p><strong>Wikidata Embeddings</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://github.com/Wikidata/taxlink">https://github.com/Wikidata/taxlink</a></li>
<li><strong>Features</strong>: Pre-trained embeddings for Wikidata entities</li>
</ul>
<p><strong>BioKG Embeddings</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://github.com/dsi-bdi/biokg">https://github.com/dsi-bdi/biokg</a></li>
<li><strong>Features</strong>: Pre-trained embeddings for biomedical knowledge graphs</li>
</ul>
</div>
<p>Pre-trained embeddings can save computational resources and provide a starting point for transfer learning to specific domains.</p>
</section>
<section id="knowledge-graph-reasoning-tools" class="level2" data-number="16.16">
<h2 data-number="16.16" class="anchored" data-anchor-id="knowledge-graph-reasoning-tools"><span class="header-section-number">16.16</span> Knowledge Graph Reasoning Tools</h2>
<p>Tools for reasoning with knowledge graphs complement embedding-based approaches.</p>
<div id="def-reasoning-tools" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.27 (Knowledge Graph Reasoning Tools)</strong></span> <strong>AnyBURL (Rule Learning for Knowledge Graphs)</strong></p>
<ul>
<li><strong>Website</strong>: <a href="http://web.informatik.uni-mannheim.de/AnyBURL/">http://web.informatik.uni-mannheim.de/AnyBURL/</a></li>
<li><strong>Features</strong>: Fast rule learning for knowledge graphs</li>
</ul>
<p><strong>NeuralLP</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/fanyangxyz/Neural-LP">https://github.com/fanyangxyz/Neural-LP</a></li>
<li><strong>Features</strong>: Differentiable neural logic programming for knowledge graph reasoning</li>
</ul>
<p><strong>AMIE (Association Rule Mining under Incomplete Evidence)</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/lajus/amie">https://github.com/lajus/amie</a></li>
<li><strong>Features</strong>: Rule mining system for large knowledge bases</li>
</ul>
<p><strong>kglib (Knowledge Graph Library)</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/vaticle/kglib">https://github.com/vaticle/kglib</a></li>
<li><strong>Features</strong>: Machine learning with knowledge graphs, built on Grakn</li>
</ul>
<p><strong>RLvLR (Reinforcement Learning via Logic Rule)</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/DeepGraphLearning/RLvLR">https://github.com/DeepGraphLearning/RLvLR</a></li>
<li><strong>Features</strong>: Reinforcement learning for knowledge graph reasoning</li>
</ul>
</div>
<p>These tools provide complementary approaches to reasoning with knowledge graphs, which can be combined with embedding-based methods.</p>
</section>
<section id="documentation-and-style-guides" class="level2" data-number="16.17">
<h2 data-number="16.17" class="anchored" data-anchor-id="documentation-and-style-guides"><span class="header-section-number">16.17</span> Documentation and Style Guides</h2>
<p>Guidelines for documenting knowledge graph embeddings and related resources.</p>
<div id="def-documentation-guides" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.28 (Documentation and Style Guides)</strong></span> <strong>Knowledge Graph Best Practices</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://www.w3.org/2019/09/kg-best-practices/">https://www.w3.org/2019/09/kg-best-practices/</a></li>
<li><strong>Features</strong>: Best practices for knowledge graph design and documentation</li>
</ul>
<p><strong>Schema.org</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://schema.org/">https://schema.org/</a></li>
<li><strong>Features</strong>: Vocabulary for structured data markup and knowledge graph integration</li>
</ul>
<p><strong>PyKEEN Documentation Guidelines</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/pykeen/pykeen/blob/master/CONTRIBUTING.md">https://github.com/pykeen/pykeen/blob/master/CONTRIBUTING.md</a></li>
<li><strong>Features</strong>: Guidelines for documenting knowledge graph embedding models and experiments</li>
</ul>
<p><strong>Knowledge Graph Publication Guidelines</strong></p>
<ul>
<li><strong>Paper</strong>: Hogan, A., et al.&nbsp;(2021). Knowledge Graphs. ACM Computing Surveys, 54(4), 1-37.</li>
<li><strong>Features</strong>: Guidelines for publishing and documenting knowledge graphs and related research</li>
</ul>
</div>
<p>Proper documentation is essential for the reproducibility and usability of knowledge graph embedding research and applications.</p>
</section>
<section id="integrating-with-deep-learning-frameworks" class="level2" data-number="16.18">
<h2 data-number="16.18" class="anchored" data-anchor-id="integrating-with-deep-learning-frameworks"><span class="header-section-number">16.18</span> Integrating with Deep Learning Frameworks</h2>
<p>Resources for integrating knowledge graph embeddings with popular deep learning frameworks.</p>
<div id="def-deep-learning-integration" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.29 (Integrating with Deep Learning Frameworks)</strong></span> <strong>PyTorch Geometric</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://pytorch-geometric.readthedocs.io/">https://pytorch-geometric.readthedocs.io/</a></li>
<li><strong>Features</strong>: Extension of PyTorch for graph neural networks, can be used with knowledge graph embeddings</li>
</ul>
<p><strong>DGL (Deep Graph Library)</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://www.dgl.ai/">https://www.dgl.ai/</a></li>
<li><strong>Features</strong>: Framework-agnostic library for graph neural networks, includes knowledge graph embedding support</li>
</ul>
<p><strong>TensorFlow Graph Neural Networks</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/tensorflow/gnn">https://github.com/tensorflow/gnn</a></li>
<li><strong>Features</strong>: TensorFlow library for graph neural networks, can be integrated with knowledge graph embeddings</li>
</ul>
<p><strong>Spektral</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://graphneural.network/">https://graphneural.network/</a></li>
<li><strong>Features</strong>: Graph neural network library for Keras and TensorFlow</li>
</ul>
<p><strong>Hugging Face Transformers Integration</strong></p>
<ul>
<li><strong>Documentation</strong>: <a href="https://huggingface.co/blog/knowledge-graph-completion">https://huggingface.co/blog/knowledge-graph-completion</a></li>
<li><strong>Features</strong>: Integration of transformers with knowledge graph completion tasks</li>
</ul>
</div>
<p>Integration with deep learning frameworks facilitates the development of advanced knowledge graph embedding models and applications.</p>
</section>
<section id="industry-standards-and-formats" class="level2" data-number="16.19">
<h2 data-number="16.19" class="anchored" data-anchor-id="industry-standards-and-formats"><span class="header-section-number">16.19</span> Industry Standards and Formats</h2>
<p>Standards and formats for representing knowledge graphs and their embeddings.</p>
<div id="def-standards-formats" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.30 (Industry Standards and Formats)</strong></span> <strong>RDF (Resource Description Framework)</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://www.w3.org/RDF/">https://www.w3.org/RDF/</a></li>
<li><strong>Features</strong>: Standard model for data interchange on the web, widely used for knowledge graphs</li>
</ul>
<p><strong>OWL (Web Ontology Language)</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://www.w3.org/OWL/">https://www.w3.org/OWL/</a></li>
<li><strong>Features</strong>: Knowledge representation language for defining ontologies</li>
</ul>
<p><strong>SPARQL</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://www.w3.org/TR/sparql11-query/">https://www.w3.org/TR/sparql11-query/</a></li>
<li><strong>Features</strong>: Query language for RDF data</li>
</ul>
<p><strong>JSON-LD</strong></p>
<ul>
<li><strong>Website</strong>: <a href="https://json-ld.org/">https://json-ld.org/</a></li>
<li><strong>Features</strong>: JSON-based format for linked data, compatible with knowledge graphs</li>
</ul>
<p><strong>Knowledge Graph Exchange (KGX)</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/biolink/kgx">https://github.com/biolink/kgx</a></li>
<li><strong>Features</strong>: Format for exchanging knowledge graphs across different platforms</li>
</ul>
</div>
<p>Standardized formats facilitate interoperability and exchange of knowledge graphs and their embeddings.</p>
</section>
<section id="experimental-and-research-frontiers" class="level2" data-number="16.20">
<h2 data-number="16.20" class="anchored" data-anchor-id="experimental-and-research-frontiers"><span class="header-section-number">16.20</span> Experimental and Research Frontiers</h2>
<p>Resources for exploring the cutting edge of knowledge graph embedding research.</p>
<div id="def-research-frontiers" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 16.31 (Experimental and Research Frontiers)</strong></span> <strong>Hyperbolic Knowledge Graph Embeddings</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/HazyResearch/KGEmb">https://github.com/HazyResearch/KGEmb</a></li>
<li><strong>Features</strong>: Implementation of hyperbolic knowledge graph embeddings</li>
</ul>
<p><strong>Quantum Knowledge Graph Embeddings</strong></p>
<ul>
<li><strong>GitHub</strong>: <a href="https://github.com/qiuchi/qaunt_KGE">https://github.com/qiuchi/qaunt_KGE</a></li>
<li><strong>Features</strong>: Exploration of quantum computing for knowledge graph embeddings</li>
</ul>
<p><strong>Self-Supervised Knowledge Graph Embeddings</strong></p>
<ul>
<li><strong>GitHub</strong>: Various repositories</li>
<li><strong>Features</strong>: Methods that leverage self-supervised learning for knowledge graph embeddings</li>
</ul>
<p><strong>LLM-KG Integration</strong></p>
<ul>
<li><strong>GitHub</strong>: Various repositories</li>
<li><strong>Features</strong>: Integration of large language models with knowledge graphs for enhanced reasoning</li>
</ul>
<p><strong>Cross-Modal Knowledge Graph Embeddings</strong></p>
<ul>
<li><strong>GitHub</strong>: Various repositories</li>
<li><strong>Features</strong>: Approaches that integrate multiple modalities (text, images, etc.) with knowledge graph embeddings</li>
</ul>
</div>
<p>These resources provide glimpses into emerging research directions for knowledge graph embeddings.</p>
</section>
<section id="conclusion" class="level2" data-number="16.21">
<h2 data-number="16.21" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">16.21</span> Conclusion</h2>
<p>This appendix has provided a comprehensive collection of resources and tools for knowledge graph embeddings. From open-source libraries and benchmark datasets to visualization tools, evaluation frameworks, and industry applications, we have covered the breadth of resources available to researchers and practitioners working with knowledge graph embeddings.</p>
<p>The field of knowledge graph embeddings continues to evolve rapidly, with new models, datasets, and applications emerging regularly. The resources listed in this appendix provide a solid foundation for understanding, implementing, and applying knowledge graph embedding techniques. By leveraging these resources, readers can build on the theoretical knowledge presented in the main chapters and apply it to their own knowledge graph projects.</p>
<p>For the most up-to-date information, we encourage readers to explore the links provided, participate in community forums, and follow the latest research publications. The collaborative nature of the field ensures that new resources and tools will continue to emerge, further enhancing the capabilities and applications of knowledge graph embeddings.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation column-body">
  <div class="nav-page nav-page-previous">
      <a href="../content/appendix-a.html" class="pagination-link" aria-label="Appendix A: Mathematical Foundations">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Appendix A: Mathematical Foundations</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p><a href="https://tuedsci.github.io/">Â© Tue Nguyen</a></p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>