<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.43">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>13&nbsp; Implementing Knowledge Graph Embedding Systems – Knowledge Graph Embeddings for Link Prediction and Reasoning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../content/frontier.html" rel="next">
<link href="../content/applications.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-d4d76bf8491c20bad77d141916dc28e1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-bdec3157979715d7154bb60f5aa24e58.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../content/implementation.html"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Implementing Knowledge Graph Embedding Systems</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Knowledge Graph Embeddings for Link Prediction and Reasoning</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/outline.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Outline</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Introduction to Knowledge Graphs and Representations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/embedding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Fundamentals of Vector Space Representations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/translation-based.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Translation-Based Embedding Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/semantic-matching.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Semantic Matching Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/rotation-nn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Advanced Models: Rotations and Neural Networks</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/training.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Training and Optimization Techniques</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/evaluation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Evaluation Methodologies and Benchmarks</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/additional-knowledge.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Incorporating Additional Information</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/reasoning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Reasoning with Knowledge Graph Embeddings</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/applications.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Practical Applications and Case Studies</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/implementation.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Implementing Knowledge Graph Embedding Systems</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/frontier.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Advanced Topics and Research Frontiers</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/appendix-a.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Appendix A: Mathematical Foundations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../content/appendix-b.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Appendix B: Resources and Tools</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="-1">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#the-knowledge-graph-embedding-pipeline" id="toc-the-knowledge-graph-embedding-pipeline" class="nav-link active" data-scroll-target="#the-knowledge-graph-embedding-pipeline"><span class="header-section-number">13.1</span> The knowledge graph embedding pipeline</a></li>
  <li><a href="#data-preparation-and-preprocessing" id="toc-data-preparation-and-preprocessing" class="nav-link" data-scroll-target="#data-preparation-and-preprocessing"><span class="header-section-number">13.2</span> Data preparation and preprocessing</a>
  <ul class="collapse">
  <li><a href="#data-formats-and-standards" id="toc-data-formats-and-standards" class="nav-link" data-scroll-target="#data-formats-and-standards"><span class="header-section-number">13.2.1</span> Data formats and standards</a></li>
  <li><a href="#data-cleaning-and-filtering" id="toc-data-cleaning-and-filtering" class="nav-link" data-scroll-target="#data-cleaning-and-filtering"><span class="header-section-number">13.2.2</span> Data cleaning and filtering</a></li>
  <li><a href="#graph-partitioning" id="toc-graph-partitioning" class="nav-link" data-scroll-target="#graph-partitioning"><span class="header-section-number">13.2.3</span> Graph partitioning</a></li>
  <li><a href="#dataset-splitting" id="toc-dataset-splitting" class="nav-link" data-scroll-target="#dataset-splitting"><span class="header-section-number">13.2.4</span> Dataset splitting</a></li>
  <li><a href="#negative-sampling-strategies" id="toc-negative-sampling-strategies" class="nav-link" data-scroll-target="#negative-sampling-strategies"><span class="header-section-number">13.2.5</span> Negative sampling strategies</a></li>
  </ul></li>
  <li><a href="#software-frameworks-and-tools" id="toc-software-frameworks-and-tools" class="nav-link" data-scroll-target="#software-frameworks-and-tools"><span class="header-section-number">13.3</span> Software frameworks and tools</a>
  <ul class="collapse">
  <li><a href="#open-source-libraries" id="toc-open-source-libraries" class="nav-link" data-scroll-target="#open-source-libraries"><span class="header-section-number">13.3.1</span> Open-source libraries</a></li>
  <li><a href="#custom-implementation-considerations" id="toc-custom-implementation-considerations" class="nav-link" data-scroll-target="#custom-implementation-considerations"><span class="header-section-number">13.3.2</span> Custom implementation considerations</a></li>
  <li><a href="#integration-with-graph-databases" id="toc-integration-with-graph-databases" class="nav-link" data-scroll-target="#integration-with-graph-databases"><span class="header-section-number">13.3.3</span> Integration with graph databases</a></li>
  </ul></li>
  <li><a href="#training-and-optimization" id="toc-training-and-optimization" class="nav-link" data-scroll-target="#training-and-optimization"><span class="header-section-number">13.4</span> Training and optimization</a>
  <ul class="collapse">
  <li><a href="#hardware-acceleration" id="toc-hardware-acceleration" class="nav-link" data-scroll-target="#hardware-acceleration"><span class="header-section-number">13.4.1</span> Hardware acceleration</a></li>
  <li><a href="#distributed-training" id="toc-distributed-training" class="nav-link" data-scroll-target="#distributed-training"><span class="header-section-number">13.4.2</span> Distributed training</a></li>
  <li><a href="#memory-optimization" id="toc-memory-optimization" class="nav-link" data-scroll-target="#memory-optimization"><span class="header-section-number">13.4.3</span> Memory optimization</a></li>
  <li><a href="#hyperparameter-optimization" id="toc-hyperparameter-optimization" class="nav-link" data-scroll-target="#hyperparameter-optimization"><span class="header-section-number">13.4.4</span> Hyperparameter optimization</a></li>
  <li><a href="#regularization-techniques" id="toc-regularization-techniques" class="nav-link" data-scroll-target="#regularization-techniques"><span class="header-section-number">13.4.5</span> Regularization techniques</a></li>
  </ul></li>
  <li><a href="#scaling-to-large-knowledge-graphs" id="toc-scaling-to-large-knowledge-graphs" class="nav-link" data-scroll-target="#scaling-to-large-knowledge-graphs"><span class="header-section-number">13.5</span> Scaling to large knowledge graphs</a>
  <ul class="collapse">
  <li><a href="#partitioning-and-parallel-processing" id="toc-partitioning-and-parallel-processing" class="nav-link" data-scroll-target="#partitioning-and-parallel-processing"><span class="header-section-number">13.5.1</span> Partitioning and parallel processing</a></li>
  <li><a href="#embedding-compression-techniques" id="toc-embedding-compression-techniques" class="nav-link" data-scroll-target="#embedding-compression-techniques"><span class="header-section-number">13.5.2</span> Embedding compression techniques</a></li>
  <li><a href="#out-of-core-training" id="toc-out-of-core-training" class="nav-link" data-scroll-target="#out-of-core-training"><span class="header-section-number">13.5.3</span> Out-of-core training</a></li>
  <li><a href="#entity-and-relation-filtering" id="toc-entity-and-relation-filtering" class="nav-link" data-scroll-target="#entity-and-relation-filtering"><span class="header-section-number">13.5.4</span> Entity and relation filtering</a></li>
  </ul></li>
  <li><a href="#evaluation-and-validation" id="toc-evaluation-and-validation" class="nav-link" data-scroll-target="#evaluation-and-validation"><span class="header-section-number">13.6</span> Evaluation and validation</a>
  <ul class="collapse">
  <li><a href="#evaluation-metrics" id="toc-evaluation-metrics" class="nav-link" data-scroll-target="#evaluation-metrics"><span class="header-section-number">13.6.1</span> Evaluation metrics</a></li>
  <li><a href="#validation-strategies" id="toc-validation-strategies" class="nav-link" data-scroll-target="#validation-strategies"><span class="header-section-number">13.6.2</span> Validation strategies</a></li>
  <li><a href="#reproducibility-considerations" id="toc-reproducibility-considerations" class="nav-link" data-scroll-target="#reproducibility-considerations"><span class="header-section-number">13.6.3</span> Reproducibility considerations</a></li>
  </ul></li>
  <li><a href="#deployment-architectures" id="toc-deployment-architectures" class="nav-link" data-scroll-target="#deployment-architectures"><span class="header-section-number">13.7</span> Deployment architectures</a>
  <ul class="collapse">
  <li><a href="#serving-architectures" id="toc-serving-architectures" class="nav-link" data-scroll-target="#serving-architectures"><span class="header-section-number">13.7.1</span> Serving architectures</a></li>
  <li><a href="#caching-strategies" id="toc-caching-strategies" class="nav-link" data-scroll-target="#caching-strategies"><span class="header-section-number">13.7.2</span> Caching strategies</a></li>
  <li><a href="#monitoring-and-maintenance" id="toc-monitoring-and-maintenance" class="nav-link" data-scroll-target="#monitoring-and-maintenance"><span class="header-section-number">13.7.3</span> Monitoring and maintenance</a></li>
  <li><a href="#incremental-learning" id="toc-incremental-learning" class="nav-link" data-scroll-target="#incremental-learning"><span class="header-section-number">13.7.4</span> Incremental learning</a></li>
  </ul></li>
  <li><a href="#integration-with-other-systems" id="toc-integration-with-other-systems" class="nav-link" data-scroll-target="#integration-with-other-systems"><span class="header-section-number">13.8</span> Integration with other systems</a>
  <ul class="collapse">
  <li><a href="#integration-with-recommendation-systems" id="toc-integration-with-recommendation-systems" class="nav-link" data-scroll-target="#integration-with-recommendation-systems"><span class="header-section-number">13.8.1</span> Integration with recommendation systems</a></li>
  <li><a href="#integration-with-search-systems" id="toc-integration-with-search-systems" class="nav-link" data-scroll-target="#integration-with-search-systems"><span class="header-section-number">13.8.2</span> Integration with search systems</a></li>
  <li><a href="#integration-with-natural-language-processing" id="toc-integration-with-natural-language-processing" class="nav-link" data-scroll-target="#integration-with-natural-language-processing"><span class="header-section-number">13.8.3</span> Integration with natural language processing</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">13.9</span> Summary</a></li>
  <li><a href="#further-reading" id="toc-further-reading" class="nav-link" data-scroll-target="#further-reading"><span class="header-section-number">13.10</span> Further reading</a>
  <ul class="collapse">
  <li><a href="#software-frameworks-and-implementation" id="toc-software-frameworks-and-implementation" class="nav-link" data-scroll-target="#software-frameworks-and-implementation"><span class="header-section-number">13.10.1</span> Software frameworks and implementation</a></li>
  <li><a href="#scaling-and-optimization" id="toc-scaling-and-optimization" class="nav-link" data-scroll-target="#scaling-and-optimization"><span class="header-section-number">13.10.2</span> Scaling and optimization</a></li>
  <li><a href="#deployment-and-integration" id="toc-deployment-and-integration" class="nav-link" data-scroll-target="#deployment-and-integration"><span class="header-section-number">13.10.3</span> Deployment and integration</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Implementing Knowledge Graph Embedding Systems</span></h1>
</div>



<div class="quarto-title-meta column-body">

    
  
    
  </div>
  


</header>


<p>Transitioning from theoretical understanding to practical implementation is a critical step in deploying knowledge graph embedding models for real-world applications. While previous chapters focused on the mathematical foundations and model architectures, this chapter addresses the engineering challenges and best practices for building effective knowledge graph embedding systems.</p>
<p>Implementing a knowledge graph embedding system involves numerous considerations: from data preparation and model selection to training optimization, hyperparameter tuning, and deployment strategies. These practical aspects can significantly impact the performance, efficiency, and maintainability of the system. Moreover, scaling knowledge graph embeddings to handle large graphs with millions of entities and billions of relations requires specialized techniques and infrastructure.</p>
<p>This chapter provides a comprehensive guide to implementing knowledge graph embedding systems, covering the entire pipeline from data processing to deployment. We’ll discuss software frameworks, hardware considerations, optimization techniques, and system architectures. By the end of this chapter, you’ll have a practical understanding of how to build efficient and effective knowledge graph embedding systems for various applications.</p>
<section id="the-knowledge-graph-embedding-pipeline" class="level2" data-number="13.1">
<h2 data-number="13.1" class="anchored" data-anchor-id="the-knowledge-graph-embedding-pipeline"><span class="header-section-number">13.1</span> The knowledge graph embedding pipeline</h2>
<p>Implementing a knowledge graph embedding system involves several interconnected components that form a complete pipeline:</p>
<div id="def-kge-pipeline" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.1 (Knowledge graph embedding pipeline)</strong></span> The <strong>knowledge graph embedding pipeline</strong> typically includes:</p>
<ol type="1">
<li><strong>Data acquisition</strong>: Collecting or accessing knowledge graph data</li>
<li><strong>Preprocessing</strong>: Cleaning, filtering, and transforming the data</li>
<li><strong>Model selection</strong>: Choosing appropriate embedding models</li>
<li><strong>Training</strong>: Optimizing model parameters</li>
<li><strong>Evaluation</strong>: Assessing model performance</li>
<li><strong>Deployment</strong>: Making the model available for applications</li>
<li><strong>Monitoring and maintenance</strong>: Ensuring ongoing system health and performance</li>
</ol>
<p>Each stage involves specific challenges and considerations that impact the overall system effectiveness.</p>
</div>
<div id="exm-pipeline" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.1 (Pipeline example)</strong></span> For a recommendation system based on knowledge graph embeddings:</p>
<ol type="1">
<li><strong>Data acquisition</strong>: Collect user-item interaction data, item attributes, and user profile information</li>
<li><strong>Preprocessing</strong>: Convert to a knowledge graph format, handle missing values, remove duplicates</li>
<li><strong>Model selection</strong>: Choose RotatE for its ability to model various relation patterns</li>
<li><strong>Training</strong>: Optimize embeddings using self-adversarial negative sampling and GPU acceleration</li>
<li><strong>Evaluation</strong>: Measure performance using ranking metrics on a held-out test set</li>
<li><strong>Deployment</strong>: Integrate embeddings into a recommendation API</li>
<li><strong>Monitoring</strong>: Track recommendation quality and retrain as new data becomes available</li>
</ol>
<p>Each stage requires careful implementation to ensure the final system performs effectively.</p>
</div>
</section>
<section id="data-preparation-and-preprocessing" class="level2" data-number="13.2">
<h2 data-number="13.2" class="anchored" data-anchor-id="data-preparation-and-preprocessing"><span class="header-section-number">13.2</span> Data preparation and preprocessing</h2>
<p>Effective data preparation is crucial for knowledge graph embedding systems:</p>
<section id="data-formats-and-standards" class="level3" data-number="13.2.1">
<h3 data-number="13.2.1" class="anchored" data-anchor-id="data-formats-and-standards"><span class="header-section-number">13.2.1</span> Data formats and standards</h3>
<p>Knowledge graphs can be represented in various formats:</p>
<div id="def-data-formats" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.2 (Knowledge graph data formats)</strong></span> Common formats include:</p>
<ol type="1">
<li><strong>RDF (Resource Description Framework)</strong>: Represents data as triples (subject, predicate, object)
<ul>
<li>Serializations include RDF/XML, Turtle, N-Triples, JSON-LD</li>
</ul></li>
<li><strong>Property Graph</strong>: Nodes and edges with properties (e.g., Neo4j’s format)</li>
<li><strong>Edge list</strong>: Simple representation of triples as (head, relation, tail)</li>
<li><strong>Adjacency matrix</strong>: Sparse matrix representation of the graph structure</li>
<li><strong>Specialized formats</strong>: Dataset-specific formats like FB15k or WN18</li>
</ol>
<p>Most knowledge graph embedding libraries use simple edge list formats for training.</p>
</div>
<div id="exm-data-format" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.2 (Data format example)</strong></span> The same knowledge about Paris could be represented in different formats:</p>
<p><strong>RDF (Turtle format)</strong>:</p>
<pre><code>&lt;http://example.org/Paris&gt; &lt;http://example.org/isCapitalOf&gt; &lt;http://example.org/France&gt; .
&lt;http://example.org/Paris&gt; &lt;http://example.org/hasPopulation&gt; "2161000"^^&lt;http://www.w3.org/2001/XMLSchema#integer&gt; .</code></pre>
<p><strong>Edge list format</strong>:</p>
<pre><code>Paris isCapitalOf France
Paris hasPopulation 2161000</code></pre>
<p>For knowledge graph embedding, the edge list format is typically preprocessed further into numeric IDs:</p>
<pre><code>42 7 17
42 12 2161000</code></pre>
<p>where 42 might be the ID for Paris, 7 for isCapitalOf, etc.</p>
</div>
</section>
<section id="data-cleaning-and-filtering" class="level3" data-number="13.2.2">
<h3 data-number="13.2.2" class="anchored" data-anchor-id="data-cleaning-and-filtering"><span class="header-section-number">13.2.2</span> Data cleaning and filtering</h3>
<p>Data cleaning is essential for high-quality embeddings:</p>
<div id="def-data-cleaning" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.3 (Data cleaning for knowledge graphs)</strong></span> Important data cleaning steps include:</p>
<ol type="1">
<li><strong>Entity resolution</strong>: Identifying and merging duplicate entities</li>
<li><strong>Relation normalization</strong>: Standardizing relation names and types</li>
<li><strong>Handling missing values</strong>: Deciding how to treat incomplete information</li>
<li><strong>Removing noise</strong>: Filtering out erroneous or low-confidence triples</li>
<li><strong>Handling special cases</strong>: Addressing literals, numerical values, and other non-entity objects</li>
</ol>
</div>
<div id="exm-data-cleaning" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.3 (Data cleaning example)</strong></span> Consider a knowledge graph with these issues:</p>
<ul>
<li>The entity “NYC” and “New York City” refer to the same entity</li>
<li>The relations “born_in” and “birthplace” represent the same relationship</li>
<li>Some population values are missing</li>
<li>Some triples contain obvious errors (e.g., “New York City, capital_of, United States”)</li>
</ul>
<p>Cleaning steps would include:</p>
<ol type="1">
<li>Merging “NYC” and “New York City” into a single entity</li>
<li>Standardizing “born_in” and “birthplace” to a single relation type</li>
<li>Marking missing populations for special handling</li>
<li>Removing the incorrect “capital_of” relationship</li>
</ol>
</div>
</section>
<section id="graph-partitioning" class="level3" data-number="13.2.3">
<h3 data-number="13.2.3" class="anchored" data-anchor-id="graph-partitioning"><span class="header-section-number">13.2.3</span> Graph partitioning</h3>
<p>For large knowledge graphs, partitioning can improve training efficiency:</p>
<div id="def-graph-partitioning" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.4 (Graph partitioning)</strong></span> <strong>Graph partitioning</strong> divides a large graph into smaller subgraphs:</p>
<ol type="1">
<li><strong>Random partitioning</strong>: Randomly assign nodes to partitions</li>
<li><strong>Balanced partitioning</strong>: Ensure similar sizes for each partition</li>
<li><strong>Minimum cut partitioning</strong>: Minimize edges between partitions</li>
<li><strong>Community-based partitioning</strong>: Group nodes based on community structure</li>
<li><strong>Relation-based partitioning</strong>: Separate subgraphs based on relation types</li>
</ol>
<p>Effective partitioning can enable parallel processing and reduce memory requirements.</p>
</div>
<div id="exm-partitioning" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.4 (Graph partitioning example)</strong></span> For a large e-commerce knowledge graph:</p>
<ol type="1">
<li>Partition by product category (electronics, clothing, home goods, etc.)</li>
<li>Train embeddings for each partition independently</li>
<li>Optionally, align the embedding spaces using shared entities</li>
<li>Combine the aligned embeddings for downstream tasks</li>
</ol>
<p>This approach allows training on smaller subgraphs that fit in memory while maintaining the ability to reason across categories.</p>
</div>
</section>
<section id="dataset-splitting" class="level3" data-number="13.2.4">
<h3 data-number="13.2.4" class="anchored" data-anchor-id="dataset-splitting"><span class="header-section-number">13.2.4</span> Dataset splitting</h3>
<p>Proper dataset splitting is crucial for evaluating knowledge graph embeddings:</p>
<div id="def-dataset-splitting" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.5 (Dataset splitting strategies)</strong></span> Common splitting approaches include:</p>
<ol type="1">
<li><strong>Random split</strong>: Randomly assign triples to train/validation/test sets</li>
<li><strong>Time-based split</strong>: Use temporal information to create chronological splits</li>
<li><strong>Entity-based split</strong>: Ensure certain entities appear only in specific splits (for testing inductive capabilities)</li>
<li><strong>Relation-based split</strong>: Hold out certain relation types for testing</li>
<li><strong>Transductive vs.&nbsp;inductive splits</strong>: Different splits depending on whether the goal is transductive or inductive learning</li>
</ol>
</div>
<div id="exm-splitting" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.5 (Dataset splitting example)</strong></span> Different splitting strategies for different evaluation goals:</p>
<p><strong>For standard link prediction (transductive setting)</strong>:</p>
<ul>
<li>Random 80/10/10 split of triples into train/validation/test</li>
<li>Ensure all entities appear in the training set</li>
</ul>
<p><strong>For inductive evaluation</strong>:</p>
<ul>
<li>Select 20% of entities to appear only in test set</li>
<li>Remove all triples containing these entities from train/validation</li>
<li>Use these “unseen” entities to evaluate inductive capabilities</li>
</ul>
<p><strong>For temporal prediction</strong>:</p>
<ul>
<li>Sort triples by timestamp</li>
<li>Use older triples for training, newer ones for testing</li>
</ul>
</div>
</section>
<section id="negative-sampling-strategies" class="level3" data-number="13.2.5">
<h3 data-number="13.2.5" class="anchored" data-anchor-id="negative-sampling-strategies"><span class="header-section-number">13.2.5</span> Negative sampling strategies</h3>
<p>Negative sampling is crucial for efficient training:</p>
<div id="def-negative-sampling-impl" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.6 (Implementing negative sampling)</strong></span> Key considerations for negative sampling:</p>
<ol type="1">
<li><strong>Batch preparation</strong>: Generate negative samples on-the-fly or pre-compute them</li>
<li><strong>Sampling distribution</strong>: Uniform random sampling vs.&nbsp;relation-aware strategies</li>
<li><strong>Filtering</strong>: Avoid sampling false negatives (triples that actually exist)</li>
<li><strong>Self-adversarial sampling</strong>: Implement dynamic weighting based on current model scores</li>
<li><strong>Negative sample ratio</strong>: Balance between positive and negative samples</li>
</ol>
</div>
<div id="exm-negative-sampling-impl" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.6 (Negative sampling implementation example)</strong></span> For efficient implementation of self-adversarial negative sampling:</p>
<ol type="1">
<li>For each positive triple <span class="math inline">\((h, r, t)\)</span> in a batch</li>
<li>Generate multiple corrupted triples by replacing <span class="math inline">\(h\)</span> or <span class="math inline">\(t\)</span> with random entities</li>
<li>Compute scores for all corrupted triples using the current model</li>
<li>Calculate sampling weights: <span class="math inline">\(p(h', r, t') = \frac{\exp(\alpha f_r(h', t'))}{\sum_{j} \exp(\alpha f_r(h_j', t_j'))}\)</span></li>
<li>Apply these weights when computing the loss gradient</li>
</ol>
<p>This implementation dynamically focuses training on “hard” negative examples that the model incorrectly scores highly.</p>
</div>
</section>
</section>
<section id="software-frameworks-and-tools" class="level2" data-number="13.3">
<h2 data-number="13.3" class="anchored" data-anchor-id="software-frameworks-and-tools"><span class="header-section-number">13.3</span> Software frameworks and tools</h2>
<p>Several software frameworks are available for implementing knowledge graph embeddings:</p>
<section id="open-source-libraries" class="level3" data-number="13.3.1">
<h3 data-number="13.3.1" class="anchored" data-anchor-id="open-source-libraries"><span class="header-section-number">13.3.1</span> Open-source libraries</h3>
<div id="def-kge-libraries" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.7 (Knowledge graph embedding libraries)</strong></span> Popular open-source libraries include:</p>
<ol type="1">
<li><strong>PyKEEN</strong>: Comprehensive Python library with implementations of many KGE models</li>
<li><strong>OpenKE</strong>: Open-source framework for knowledge embedding in Python/C++</li>
<li><strong>DGL-KE</strong>: Knowledge graph embedding built on Deep Graph Library</li>
<li><strong>TorchKGE</strong>: PyTorch-based library for knowledge graph embedding</li>
<li><strong>AmpliGraph</strong>: TensorFlow-based library with focus on scalability</li>
<li><strong>GraphVite</strong>: High-performance graph embedding with CPU-GPU hybrid architecture</li>
</ol>
</div>
<div id="exm-pykeen" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.7 (PyKEEN example)</strong></span> Using PyKEEN to train a TransE model:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pykeen.pipeline</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pykeen.datasets <span class="im">import</span> FB15k237</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load a benchmark dataset</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> FB15k237()</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the pipeline</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pykeen.pipeline.pipeline(</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    dataset<span class="op">=</span>dataset,</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span><span class="st">'TransE'</span>,</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    model_kwargs<span class="op">=</span><span class="bu">dict</span>(</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>        embedding_dim<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        scoring_function_norm<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    optimizer<span class="op">=</span><span class="st">'Adam'</span>,</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    optimizer_kwargs<span class="op">=</span><span class="bu">dict</span>(lr<span class="op">=</span><span class="fl">0.0005</span>),</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>    loss<span class="op">=</span><span class="st">'MarginRankingLoss'</span>,</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    loss_kwargs<span class="op">=</span><span class="bu">dict</span>(margin<span class="op">=</span><span class="fl">1.0</span>),</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    training_loop<span class="op">=</span><span class="st">'sLCWA'</span>,  <span class="co"># Self-adversarial negative sampling</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    negative_sampler<span class="op">=</span><span class="st">'basic'</span>,</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    negative_sampler_kwargs<span class="op">=</span><span class="bu">dict</span>(num_negs_per_pos<span class="op">=</span><span class="dv">5</span>),</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    random_seed<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>results.evaluate()</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the model</span></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>results.save_to_directory(<span class="st">'transe_fb15k237'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This code demonstrates how libraries like PyKEEN simplify the implementation process by providing high-level interfaces to state-of-the-art models and training procedures.</p>
</div>
</section>
<section id="custom-implementation-considerations" class="level3" data-number="13.3.2">
<h3 data-number="13.3.2" class="anchored" data-anchor-id="custom-implementation-considerations"><span class="header-section-number">13.3.2</span> Custom implementation considerations</h3>
<p>Sometimes custom implementations are necessary:</p>
<div id="def-custom-implementation" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.8 (Custom implementation considerations)</strong></span> When building custom implementations, consider:</p>
<ol type="1">
<li><strong>Framework selection</strong>: PyTorch, TensorFlow, JAX, or other deep learning frameworks</li>
<li><strong>Computational graph optimization</strong>: Static vs.&nbsp;dynamic computation graphs</li>
<li><strong>Memory management</strong>: Techniques for handling large embedding tables</li>
<li><strong>Batch processing</strong>: Efficient batch generation and processing strategies</li>
<li><strong>Data loading</strong>: Zero-copy data loading and transfer techniques</li>
<li><strong>Device utilization</strong>: CPU, GPU, TPU, or multi-device strategies</li>
</ol>
</div>
<div id="exm-custom-impl" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.8 (Custom implementation example)</strong></span> A custom PyTorch implementation of RotatE optimized for performance:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RotatE(nn.Module):</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_entities, num_relations, embedding_dim, margin<span class="op">=</span><span class="fl">1.0</span>, epsilon<span class="op">=</span><span class="fl">2.0</span>):</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(RotatE, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Complex embeddings (real and imaginary parts)</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.entity_dim <span class="op">=</span> embedding_dim <span class="op">*</span> <span class="dv">2</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.relation_dim <span class="op">=</span> embedding_dim</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize embeddings</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.entity_embedding <span class="op">=</span> nn.Embedding(num_entities, <span class="va">self</span>.entity_dim)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.relation_embedding <span class="op">=</span> nn.Embedding(num_relations, <span class="va">self</span>.relation_dim)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize with uniform distribution</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>        nn.init.uniform_(<span class="va">self</span>.entity_embedding.weight, <span class="op">-</span><span class="fl">1.0</span>, <span class="fl">1.0</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>        nn.init.uniform_(<span class="va">self</span>.relation_embedding.weight, <span class="op">-</span><span class="fl">1.0</span>, <span class="fl">1.0</span>)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.margin <span class="op">=</span> margin</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.epsilon <span class="op">=</span> epsilon</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, head, relation, tail, mode<span class="op">=</span><span class="st">'single'</span>):</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Forward function for computing score"""</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>        batch_size <span class="op">=</span> head.size(<span class="dv">0</span>)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get embeddings</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>        head_emb <span class="op">=</span> <span class="va">self</span>.entity_embedding(head)</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>        relation_emb <span class="op">=</span> <span class="va">self</span>.relation_embedding(relation)</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>        tail_emb <span class="op">=</span> <span class="va">self</span>.entity_embedding(tail)</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Split real and imaginary parts</span></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>        head_re, head_im <span class="op">=</span> torch.chunk(head_emb, <span class="dv">2</span>, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>        tail_re, tail_im <span class="op">=</span> torch.chunk(tail_emb, <span class="dv">2</span>, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Make relation phases with constrained modulus of 1</span></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>        relation_phase <span class="op">=</span> relation_emb <span class="op">/</span> (<span class="va">self</span>.relation_dim <span class="op">/</span> <span class="va">self</span>.margin) <span class="op">*</span> <span class="va">self</span>.epsilon</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>        relation_re <span class="op">=</span> torch.cos(relation_phase)</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>        relation_im <span class="op">=</span> torch.sin(relation_phase)</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Perform rotation in complex space</span></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>        re_score <span class="op">=</span> head_re <span class="op">*</span> relation_re <span class="op">-</span> head_im <span class="op">*</span> relation_im <span class="op">-</span> tail_re</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>        im_score <span class="op">=</span> head_re <span class="op">*</span> relation_im <span class="op">+</span> head_im <span class="op">*</span> relation_re <span class="op">-</span> tail_im</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute distance in complex space</span></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> torch.stack([re_score, im_score], dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> score.norm(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Return negative distance as score (higher is better)</span></span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="op">-</span>score.<span class="bu">sum</span>(dim<span class="op">=-</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This implementation includes optimizations like:</p>
<ol type="1">
<li>Efficient complex number handling with real and imaginary parts</li>
<li>Proper initialization and normalization</li>
<li>Vectorized operations for better GPU utilization</li>
</ol>
</div>
</section>
<section id="integration-with-graph-databases" class="level3" data-number="13.3.3">
<h3 data-number="13.3.3" class="anchored" data-anchor-id="integration-with-graph-databases"><span class="header-section-number">13.3.3</span> Integration with graph databases</h3>
<p>Knowledge graph embeddings can be integrated with graph databases:</p>
<div id="def-graph-db-integration" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.9 (Graph database integration)</strong></span> Approaches for integrating with graph databases:</p>
<ol type="1">
<li><strong>Real-time embedding</strong>: Computing embeddings on-demand from database content</li>
<li><strong>Periodic synchronization</strong>: Regularly updating embeddings based on database changes</li>
<li><strong>Vector storage</strong>: Storing pre-computed embeddings alongside graph data</li>
<li><strong>Hybrid querying</strong>: Combining graph queries with embedding-based similarity</li>
<li><strong>Plugin architecture</strong>: Extending graph databases with embedding capabilities</li>
</ol>
</div>
<div id="exm-neo4j-integration" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.9 (Neo4j integration example)</strong></span> Integrating knowledge graph embeddings with Neo4j:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> neo4j <span class="im">import</span> GraphDatabase</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Neo4j connection</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>driver <span class="op">=</span> GraphDatabase.driver(<span class="st">"bolt://localhost:7687"</span>, auth<span class="op">=</span>(<span class="st">"neo4j"</span>, <span class="st">"password"</span>))</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Load pre-trained embeddings</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>entity_embeddings <span class="op">=</span> np.load(<span class="st">'entity_embeddings.npy'</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>relation_embeddings <span class="op">=</span> np.load(<span class="st">'relation_embeddings.npy'</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>entity_map <span class="op">=</span> {<span class="bu">id</span>: idx <span class="cf">for</span> idx, <span class="bu">id</span> <span class="kw">in</span> <span class="bu">enumerate</span>(np.load(<span class="st">'entity_ids.npy'</span>))}</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_similar_entities(tx, entity_name, top_k<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the entity ID from Neo4j</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> tx.run(<span class="st">"MATCH (e {name: $name}) RETURN id(e) AS id"</span>, name<span class="op">=</span>entity_name)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    entity_id <span class="op">=</span> result.single()[<span class="st">"id"</span>]</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get the embedding vector</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> entity_id <span class="kw">in</span> entity_map:</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>        entity_vector <span class="op">=</span> entity_embeddings[entity_map[entity_id]]</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute similarities</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>        similarities <span class="op">=</span> np.dot(entity_embeddings, entity_vector)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>        most_similar <span class="op">=</span> np.argsort(similarities)[<span class="op">-</span>top_k<span class="op">-</span><span class="dv">1</span>:<span class="op">-</span><span class="dv">1</span>][::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Query Neo4j for the similar entities</span></span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>        similar_ids <span class="op">=</span> [<span class="bu">int</span>(<span class="bu">id</span>) <span class="cf">for</span> <span class="bu">id</span>, idx <span class="kw">in</span> entity_map.items() <span class="cf">if</span> idx <span class="kw">in</span> most_similar]</span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>        similar_entities <span class="op">=</span> tx.run(</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>            <span class="st">"MATCH (e) WHERE id(e) IN $ids RETURN e.name AS name"</span>,</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>            ids<span class="op">=</span>similar_ids</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>        ).values()</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> [name[<span class="dv">0</span>] <span class="cf">for</span> name <span class="kw">in</span> similar_entities]</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> []</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> driver.session() <span class="im">as</span> session:</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>    similar <span class="op">=</span> session.read_transaction(get_similar_entities, <span class="st">"Albert_Einstein"</span>)</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Entities similar to Albert Einstein: </span><span class="sc">{</span>similar<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This example demonstrates how pre-trained embeddings can be used with a graph database to provide similarity-based queries that go beyond explicit graph connections.</p>
</div>
</section>
</section>
<section id="training-and-optimization" class="level2" data-number="13.4">
<h2 data-number="13.4" class="anchored" data-anchor-id="training-and-optimization"><span class="header-section-number">13.4</span> Training and optimization</h2>
<p>Efficient training of knowledge graph embeddings requires careful optimization:</p>
<section id="hardware-acceleration" class="level3" data-number="13.4.1">
<h3 data-number="13.4.1" class="anchored" data-anchor-id="hardware-acceleration"><span class="header-section-number">13.4.1</span> Hardware acceleration</h3>
<p>Hardware acceleration is essential for training large models:</p>
<div id="def-hardware-acceleration" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.10 (Hardware acceleration techniques)</strong></span> Hardware acceleration approaches include:</p>
<ol type="1">
<li><strong>GPU training</strong>: Using GPUs for parallel computation of embeddings</li>
<li><strong>Multi-GPU training</strong>: Distributing training across multiple GPUs</li>
<li><strong>CPU optimizations</strong>: Leveraging SIMD instructions and multithreading</li>
<li><strong>TPU acceleration</strong>: Using Tensor Processing Units for specific models</li>
<li><strong>FPGA and ASIC solutions</strong>: Custom hardware for embedding computation</li>
<li><strong>Memory hierarchy optimization</strong>: Efficient use of CPU/GPU memory hierarchy</li>
</ol>
</div>
<div id="exm-gpu-optimization" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.10 (GPU optimization example)</strong></span> Optimizing TransE training for GPU:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Move model to GPU</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> TransE(num_entities, num_relations, embedding_dim).cuda()</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Use pinned memory for faster CPU-to-GPU transfers</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>dataloader <span class="op">=</span> DataLoader(</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    dataset,</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">1024</span>,</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    shuffle<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    pin_memory<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    num_workers<span class="op">=</span><span class="dv">4</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Mixed precision training</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> torch.cuda.amp.GradScaler()</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">0.0005</span>)</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch <span class="kw">in</span> dataloader:</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Move batch to GPU</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>        positive_triples <span class="op">=</span> batch[<span class="st">"positive"</span>].cuda(non_blocking<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>        negative_triples <span class="op">=</span> batch[<span class="st">"negative"</span>].cuda(non_blocking<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Mixed precision forward pass</span></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.cuda.amp.autocast():</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>            positive_scores <span class="op">=</span> model(positive_triples)</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>            negative_scores <span class="op">=</span> model(negative_triples)</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_function(positive_scores, negative_scores)</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Mixed precision backward pass and optimization</span></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad()</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>        scaler.scale(loss).backward()</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>        scaler.step(optimizer)</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>        scaler.update()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This example includes several GPU optimizations:</p>
<ol type="1">
<li>Pinned memory for faster data transfer</li>
<li>Non-blocking transfers for better CPU-GPU overlap</li>
<li>Mixed precision training to improve performance</li>
<li>Larger batch size to better utilize GPU parallelism</li>
</ol>
</div>
</section>
<section id="distributed-training" class="level3" data-number="13.4.2">
<h3 data-number="13.4.2" class="anchored" data-anchor-id="distributed-training"><span class="header-section-number">13.4.2</span> Distributed training</h3>
<p>Distributed training enables scaling to very large knowledge graphs:</p>
<div id="def-distributed-training" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.11 (Distributed training approaches)</strong></span> Approaches for distributed training:</p>
<ol type="1">
<li><strong>Data parallelism</strong>: Each worker processes different batches of triples</li>
<li><strong>Model parallelism</strong>: Embedding tables are sharded across multiple devices</li>
<li><strong>Parameter server architecture</strong>: Centralized embedding tables with distributed workers</li>
<li><strong>Decentralized training</strong>: Peer-to-peer communication between workers</li>
<li><strong>Mixed approaches</strong>: Combining data and model parallelism</li>
</ol>
</div>
<div id="exm-distributed" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.11 (Distributed training example)</strong></span> Using PyTorch’s DistributedDataParallel for knowledge graph embedding:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.distributed <span class="im">as</span> dist</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.multiprocessing <span class="im">as</span> mp</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.nn.parallel <span class="im">import</span> DistributedDataParallel <span class="im">as</span> DDP</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> setup(rank, world_size):</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize process group</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    dist.init_process_group(<span class="st">"nccl"</span>, rank<span class="op">=</span>rank, world_size<span class="op">=</span>world_size)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(rank, world_size):</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    setup(rank, world_size)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create model and move to GPU</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> TransE(num_entities, num_relations, embedding_dim).to(rank)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Wrap model with DDP</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> DDP(model, device_ids<span class="op">=</span>[rank])</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create dataloader with DistributedSampler</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    sampler <span class="op">=</span> DistributedSampler(dataset, num_replicas<span class="op">=</span>world_size, rank<span class="op">=</span>rank)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    dataloader <span class="op">=</span> DataLoader(dataset, batch_size<span class="op">=</span>batch_size, sampler<span class="op">=</span>sampler)</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Training loop</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>        sampler.set_epoch(epoch)  <span class="co"># Important for proper shuffling</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch <span class="kw">in</span> dataloader:</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Process batch</span></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>            <span class="co"># ...</span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Start multiple processes</span></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>world_size <span class="op">=</span> torch.cuda.device_count()</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>mp.spawn(train, args<span class="op">=</span>(world_size,), nprocs<span class="op">=</span>world_size, join<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This implementation distributes training across multiple GPUs, with each GPU processing different batches of the dataset.</p>
</div>
</section>
<section id="memory-optimization" class="level3" data-number="13.4.3">
<h3 data-number="13.4.3" class="anchored" data-anchor-id="memory-optimization"><span class="header-section-number">13.4.3</span> Memory optimization</h3>
<p>Memory optimization is crucial for handling large knowledge graphs:</p>
<div id="def-memory-optimization" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.12 (Memory optimization techniques)</strong></span> Memory optimization approaches include:</p>
<ol type="1">
<li><strong>Embedding table sharding</strong>: Distributing large embedding tables across devices</li>
<li><strong>Sparse embeddings</strong>: Using sparse representations for entities with few connections</li>
<li><strong>Quantization</strong>: Reducing precision of embedding values (e.g., FP32 to FP16 or INT8)</li>
<li><strong>Feature hashing</strong>: Using hash functions to reduce embedding table size</li>
<li><strong>On-the-fly embedding generation</strong>: Computing embeddings from smaller parameter sets</li>
<li><strong>Gradient accumulation</strong>: Processing smaller batches and accumulating gradients</li>
</ol>
</div>
<div id="exm-memory-opt" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.12 (Memory optimization example)</strong></span> Implementing quantized embeddings:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.quantization <span class="im">import</span> quantize_per_tensor</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> QuantizedEmbedding(torch.nn.Module):</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_embeddings, embedding_dim):</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize full precision embeddings</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.embedding <span class="op">=</span> torch.nn.Embedding(num_embeddings, embedding_dim)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.register_buffer(<span class="st">'scale'</span>, torch.ones(<span class="dv">1</span>))</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.register_buffer(<span class="st">'zero_point'</span>, torch.zeros(<span class="dv">1</span>, dtype<span class="op">=</span>torch.<span class="bu">long</span>))</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, indices):</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Quantize embeddings during forward pass (for inference)</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> <span class="va">self</span>.training:</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Quantize to 8-bit</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>            quantized_weight <span class="op">=</span> quantize_per_tensor(</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.embedding.weight,</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>                scale<span class="op">=</span><span class="va">self</span>.scale,</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>                zero_point<span class="op">=</span><span class="va">self</span>.zero_point,</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>                dtype<span class="op">=</span>torch.quint8</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Dequantize for computation</span></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>            dequantized_weight <span class="op">=</span> quantized_weight.dequantize()</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> torch.nn.functional.embedding(indices, dequantized_weight)</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Use full precision during training</span></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.embedding(indices)</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> quantize_for_inference(<span class="va">self</span>):</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute scale and zero point based on weight distribution</span></span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>        weight <span class="op">=</span> <span class="va">self</span>.embedding.weight.detach()</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>        min_val <span class="op">=</span> weight.<span class="bu">min</span>().item()</span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>        max_val <span class="op">=</span> weight.<span class="bu">max</span>().item()</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute scale and zero point for uniform quantization</span></span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>        scale <span class="op">=</span> (max_val <span class="op">-</span> min_val) <span class="op">/</span> <span class="fl">255.0</span></span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a>        zero_point <span class="op">=</span> <span class="bu">round</span>(<span class="dv">0</span> <span class="op">-</span> min_val <span class="op">/</span> scale)</span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.scale[<span class="dv">0</span>] <span class="op">=</span> scale</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.zero_point[<span class="dv">0</span>] <span class="op">=</span> zero_point</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This implementation uses 8-bit quantization to reduce the memory footprint of embedding tables, which is especially beneficial for inference.</p>
</div>
</section>
<section id="hyperparameter-optimization" class="level3" data-number="13.4.4">
<h3 data-number="13.4.4" class="anchored" data-anchor-id="hyperparameter-optimization"><span class="header-section-number">13.4.4</span> Hyperparameter optimization</h3>
<p>Effective hyperparameter tuning is essential for optimal performance:</p>
<div id="def-hyperparameter-optimization" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.13 (Hyperparameter optimization)</strong></span> Approaches for hyperparameter optimization:</p>
<ol type="1">
<li><strong>Grid search</strong>: Exhaustive search over a parameter grid</li>
<li><strong>Random search</strong>: Sampling random combinations of parameters</li>
<li><strong>Bayesian optimization</strong>: Sequential model-based optimization</li>
<li><strong>Population-based training</strong>: Evolutionary algorithms for parameter search</li>
<li><strong>Hyperband and ASHA</strong>: Multi-armed bandit approaches for efficient resource allocation</li>
<li><strong>Early stopping strategies</strong>: Avoiding wasted computation on poor configurations</li>
</ol>
</div>
<div id="exm-hyperopt" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.13 (Hyperparameter optimization example)</strong></span> Using Ray Tune for hyperparameter optimization:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> ray</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ray <span class="im">import</span> tune</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ray.tune.schedulers <span class="im">import</span> ASHAScheduler</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_kg_embedding(config):</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create model with hyperparameters from config</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> TransE(</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>        num_entities<span class="op">=</span>num_entities,</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>        num_relations<span class="op">=</span>num_relations,</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>        embedding_dim<span class="op">=</span>config[<span class="st">"embedding_dim"</span>],</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>        margin<span class="op">=</span>config[<span class="st">"margin"</span>],</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>        norm<span class="op">=</span>config[<span class="st">"norm"</span>]</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> torch.optim.Adam(</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>        model.parameters(),</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>        lr<span class="op">=</span>config[<span class="st">"lr"</span>],</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>        weight_decay<span class="op">=</span>config[<span class="st">"weight_decay"</span>]</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Train for several epochs</span></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(config[<span class="st">"num_epochs"</span>]):</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Training loop...</span></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Evaluate on validation set</span></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>        val_mrr <span class="op">=</span> evaluate_model(model, val_dataset)</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Report metrics to Ray Tune</span></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>        tune.report(mrr<span class="op">=</span>val_mrr)</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Define hyperparameter search space</span></span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>search_space <span class="op">=</span> {</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>    <span class="st">"embedding_dim"</span>: tune.choice([<span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">300</span>]),</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>    <span class="st">"margin"</span>: tune.uniform(<span class="fl">0.5</span>, <span class="fl">5.0</span>),</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>    <span class="st">"norm"</span>: tune.choice([<span class="dv">1</span>, <span class="dv">2</span>]),</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>    <span class="st">"lr"</span>: tune.loguniform(<span class="fl">1e-4</span>, <span class="fl">1e-2</span>),</span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>    <span class="st">"weight_decay"</span>: tune.loguniform(<span class="fl">1e-6</span>, <span class="fl">1e-3</span>),</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>    <span class="st">"num_epochs"</span>: <span class="dv">50</span></span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Use ASHA scheduler for efficient early stopping</span></span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a>scheduler <span class="op">=</span> ASHAScheduler(</span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>    max_t<span class="op">=</span><span class="dv">50</span>,  <span class="co"># Maximum number of epochs</span></span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a>    grace_period<span class="op">=</span><span class="dv">5</span>,  <span class="co"># Minimum epochs before stopping</span></span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a>    reduction_factor<span class="op">=</span><span class="dv">2</span></span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Run hyperparameter search</span></span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true" tabindex="-1"></a>analysis <span class="op">=</span> tune.run(</span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true" tabindex="-1"></a>    train_kg_embedding,</span>
<span id="cb10-51"><a href="#cb10-51" aria-hidden="true" tabindex="-1"></a>    config<span class="op">=</span>search_space,</span>
<span id="cb10-52"><a href="#cb10-52" aria-hidden="true" tabindex="-1"></a>    num_samples<span class="op">=</span><span class="dv">50</span>,  <span class="co"># Number of trials</span></span>
<span id="cb10-53"><a href="#cb10-53" aria-hidden="true" tabindex="-1"></a>    scheduler<span class="op">=</span>scheduler,</span>
<span id="cb10-54"><a href="#cb10-54" aria-hidden="true" tabindex="-1"></a>    resources_per_trial<span class="op">=</span>{<span class="st">"cpu"</span>: <span class="dv">4</span>, <span class="st">"gpu"</span>: <span class="dv">1</span>}</span>
<span id="cb10-55"><a href="#cb10-55" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-56"><a href="#cb10-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-57"><a href="#cb10-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Get best configuration</span></span>
<span id="cb10-58"><a href="#cb10-58" aria-hidden="true" tabindex="-1"></a>best_config <span class="op">=</span> analysis.get_best_config(metric<span class="op">=</span><span class="st">"mrr"</span>, mode<span class="op">=</span><span class="st">"max"</span>)</span>
<span id="cb10-59"><a href="#cb10-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Best hyperparameters: </span><span class="sc">{</span>best_config<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This example uses Ray Tune with the ASHA scheduler to efficiently search for optimal hyperparameters, automatically stopping underperforming trials.</p>
</div>
</section>
<section id="regularization-techniques" class="level3" data-number="13.4.5">
<h3 data-number="13.4.5" class="anchored" data-anchor-id="regularization-techniques"><span class="header-section-number">13.4.5</span> Regularization techniques</h3>
<p>Regularization helps prevent overfitting in embedding models:</p>
<div id="def-regularization-techniques" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.14 (Regularization techniques)</strong></span> Common regularization approaches:</p>
<ol type="1">
<li><strong>L2 regularization</strong>: Penalizing large embedding norms</li>
<li><strong>Dropout</strong>: Randomly zeroing embeddings during training</li>
<li><strong>Spectral regularization</strong>: Constraining singular values of relation matrices</li>
<li><strong>Noise injection</strong>: Adding random noise to embeddings</li>
<li><strong>Early stopping</strong>: Monitoring validation performance to avoid overfitting</li>
<li><strong>Adversarial regularization</strong>: Adding adversarial perturbations during training</li>
</ol>
</div>
<div id="exm-regularization" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.14 (Regularization example)</strong></span> Implementing various regularization techniques:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> RegularizedTransE(nn.Module):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_entities, num_relations, embedding_dim):</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.entity_embedding <span class="op">=</span> nn.Embedding(num_entities, embedding_dim)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.relation_embedding <span class="op">=</span> nn.Embedding(num_relations, embedding_dim)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.entity_dropout <span class="op">=</span> nn.Dropout(<span class="fl">0.2</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.relation_dropout <span class="op">=</span> nn.Dropout(<span class="fl">0.2</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, head, relation, tail):</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.entity_dropout(<span class="va">self</span>.entity_embedding(head))</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>        r <span class="op">=</span> <span class="va">self</span>.relation_dropout(<span class="va">self</span>.relation_embedding(relation))</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>        t <span class="op">=</span> <span class="va">self</span>.entity_dropout(<span class="va">self</span>.entity_embedding(tail))</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># L2 normalization</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> F.normalize(h, p<span class="op">=</span><span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>        t <span class="op">=</span> F.normalize(t, p<span class="op">=</span><span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Score calculation</span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> <span class="op">-</span>torch.norm(h <span class="op">+</span> r <span class="op">-</span> t, p<span class="op">=</span><span class="dv">1</span>, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> score</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> regularization_loss(<span class="va">self</span>):</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># L2 regularization</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>        entity_reg <span class="op">=</span> torch.norm(<span class="va">self</span>.entity_embedding.weight, p<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>        relation_reg <span class="op">=</span> torch.norm(<span class="va">self</span>.relation_embedding.weight, p<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> entity_reg <span class="op">+</span> relation_reg</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a><span class="co"># During training</span></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>optimizer.zero_grad()</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> model(head, relation, tail)</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> base_loss(scores) <span class="op">+</span> reg_weight <span class="op">*</span> model.regularization_loss()</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>loss.backward()</span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>optimizer.step()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This implementation combines multiple regularization techniques:</p>
<ol type="1">
<li>Dropout on entity and relation embeddings</li>
<li>L2 normalization of entity embeddings</li>
<li>Explicit L2 regularization loss term</li>
</ol>
</div>
</section>
</section>
<section id="scaling-to-large-knowledge-graphs" class="level2" data-number="13.5">
<h2 data-number="13.5" class="anchored" data-anchor-id="scaling-to-large-knowledge-graphs"><span class="header-section-number">13.5</span> Scaling to large knowledge graphs</h2>
<p>Scaling knowledge graph embeddings to very large graphs requires specialized approaches:</p>
<section id="partitioning-and-parallel-processing" class="level3" data-number="13.5.1">
<h3 data-number="13.5.1" class="anchored" data-anchor-id="partitioning-and-parallel-processing"><span class="header-section-number">13.5.1</span> Partitioning and parallel processing</h3>
<p>Partitioning can enable processing of large graphs:</p>
<div id="def-partitioning-implementation" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.15 (Partitioning implementation)</strong></span> Implementation strategies for partitioning:</p>
<ol type="1">
<li><strong>Graph partitioning algorithms</strong>: METIS, Louvain, or spectral clustering</li>
<li><strong>Partition-aware training</strong>: Training on subgraphs while considering cross-partition edges</li>
<li><strong>Partition synchronization</strong>: Coordinating updates between partitions</li>
<li><strong>Embedding alignment</strong>: Ensuring consistent embeddings across partitions</li>
<li><strong>Load balancing</strong>: Distributing partitions evenly across computational resources</li>
</ol>
</div>
<div id="exm-partition-impl" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.15 (Partitioning implementation example)</strong></span> Implementing partition-based training:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> networkx <span class="im">as</span> nx</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> metis <span class="im">import</span> part_graph</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Construct networkx graph from triples</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> nx.Graph()</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> h, r, t <span class="kw">in</span> triples:</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    G.add_edge(h, t)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Partition the graph into 8 parts</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>_, parts <span class="op">=</span> part_graph(G, <span class="dv">8</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Create partition mapping</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>node_to_partition <span class="op">=</span> {node: partition <span class="cf">for</span> node, partition <span class="kw">in</span> <span class="bu">enumerate</span>(parts)}</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Create partition-specific datasets</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>partition_datasets <span class="op">=</span> [[] <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">8</span>)]</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> h, r, t <span class="kw">in</span> triples:</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>    h_part <span class="op">=</span> node_to_partition[h]</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>    t_part <span class="op">=</span> node_to_partition[t]</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add to both partitions if cross-partition edge</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> h_part <span class="op">==</span> t_part:</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>        partition_datasets[h_part].append((h, r, t))</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>        partition_datasets[h_part].append((h, r, t))</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>        partition_datasets[t_part].append((h, r, t))</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Train models for each partition</span></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>partition_models <span class="op">=</span> []</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> partition_id, partition_data <span class="kw">in</span> <span class="bu">enumerate</span>(partition_datasets):</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> TransE(num_entities, num_relations, embedding_dim)</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Train model on partition_data</span></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ...</span></span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>    partition_models.append(model)</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine embeddings from partition models</span></span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_entity_embedding(entity_id):</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>    partition_id <span class="op">=</span> node_to_partition[entity_id]</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> partition_models[partition_id].entity_embedding(entity_id)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This approach uses METIS for graph partitioning and trains separate models for each partition, handling cross-partition edges by including them in both partitions.</p>
</div>
</section>
<section id="embedding-compression-techniques" class="level3" data-number="13.5.2">
<h3 data-number="13.5.2" class="anchored" data-anchor-id="embedding-compression-techniques"><span class="header-section-number">13.5.2</span> Embedding compression techniques</h3>
<p>Compression can reduce the memory footprint of embeddings:</p>
<div id="def-embedding-compression" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.16 (Embedding compression techniques)</strong></span> Approaches for embedding compression:</p>
<ol type="1">
<li><strong>Quantization</strong>: Reducing precision from 32-bit to 16-bit, 8-bit, or lower</li>
<li><strong>Pruning</strong>: Removing less important dimensions or entities</li>
<li><strong>Tensor decomposition</strong>: Factorizing embedding matrices into smaller components</li>
<li><strong>Knowledge distillation</strong>: Training a smaller model to mimic a larger one</li>
<li><strong>Hashing tricks</strong>: Using hash functions to reduce parameter count</li>
<li><strong>Mixed precision</strong>: Using different precisions for different parts of the model</li>
</ol>
</div>
<div id="exm-compression" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.16 (Embedding compression example)</strong></span> Implementing tensor decomposition for relation matrices:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CompressedRESCAL(nn.Module):</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_entities, num_relations, embedding_dim, rank<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.entity_embedding <span class="op">=</span> nn.Embedding(num_entities, embedding_dim)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Low-rank decomposition of relation matrices</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Instead of storing full d×d matrices (O(r*d²)), store factors (O(r*d*k))</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.relation_factor1 <span class="op">=</span> nn.Embedding(num_relations, embedding_dim <span class="op">*</span> rank)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.relation_factor2 <span class="op">=</span> nn.Embedding(num_relations, rank <span class="op">*</span> embedding_dim)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.embedding_dim <span class="op">=</span> embedding_dim</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rank <span class="op">=</span> rank</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, head, relation, tail):</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.entity_embedding(head)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>        t <span class="op">=</span> <span class="va">self</span>.entity_embedding(tail)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Reshape factors to matrices</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>        r1 <span class="op">=</span> <span class="va">self</span>.relation_factor1(relation).view(<span class="op">-</span><span class="dv">1</span>, <span class="va">self</span>.embedding_dim, <span class="va">self</span>.rank)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>        r2 <span class="op">=</span> <span class="va">self</span>.relation_factor2(relation).view(<span class="op">-</span><span class="dv">1</span>, <span class="va">self</span>.rank, <span class="va">self</span>.embedding_dim)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute R = r1 @ r2 implicitly</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># h @ R @ t = h @ (r1 @ r2) @ t = (h @ r1) @ (r2 @ t)</span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>        h_r1 <span class="op">=</span> torch.bmm(h.unsqueeze(<span class="dv">1</span>), r1).squeeze(<span class="dv">1</span>)  <span class="co"># Batch matrix multiply</span></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>        r2_t <span class="op">=</span> torch.bmm(r2, t.unsqueeze(<span class="dv">2</span>)).squeeze(<span class="dv">2</span>)  <span class="co"># Batch matrix multiply</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute final score</span></span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> torch.<span class="bu">sum</span>(h_r1 <span class="op">*</span> r2_t, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> score</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This implementation uses a low-rank decomposition of relation matrices in RESCAL, reducing the parameter count from O(r<em>d²) to O(r</em>d*k) where k is the rank (typically k &lt;&lt; d).</p>
</div>
</section>
<section id="out-of-core-training" class="level3" data-number="13.5.3">
<h3 data-number="13.5.3" class="anchored" data-anchor-id="out-of-core-training"><span class="header-section-number">13.5.3</span> Out-of-core training</h3>
<p>Out-of-core techniques handle knowledge graphs larger than memory:</p>
<div id="def-out-of-core" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.17 (Out-of-core training)</strong></span> Out-of-core training approaches:</p>
<ol type="1">
<li><strong>Streaming algorithms</strong>: Processing the graph in streams rather than loading it entirely</li>
<li><strong>Disk-based embeddings</strong>: Storing embeddings on disk and loading as needed</li>
<li><strong>Embedding swapping</strong>: Swapping embeddings between CPU and GPU memory</li>
<li><strong>Caching strategies</strong>: Caching frequently used embeddings in faster memory</li>
<li><strong>Minibatch selection</strong>: Selecting minibatches to maximize cache efficiency</li>
<li><strong>On-the-fly embedding generation</strong>: Computing embeddings from compressed representations</li>
</ol>
</div>
<div id="exm-out-of-core" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.17 (Out-of-core training example)</strong></span> Implementing embedding swapping between CPU and GPU:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> OutOfCoreEmbedding:</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_entities, embedding_dim):</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Store embeddings in CPU memory</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.embeddings <span class="op">=</span> torch.randn(num_entities, embedding_dim, device<span class="op">=</span><span class="st">'cpu'</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.embedding_dim <span class="op">=</span> embedding_dim</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cache for GPU embeddings</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cache_size <span class="op">=</span> <span class="dv">100000</span>  <span class="co"># Number of embeddings to cache on GPU</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.gpu_cache <span class="op">=</span> torch.zeros(<span class="va">self</span>.cache_size, embedding_dim, device<span class="op">=</span><span class="st">'cuda'</span>)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cache_indices <span class="op">=</span> torch.full((<span class="va">self</span>.cache_size,), <span class="op">-</span><span class="dv">1</span>, dtype<span class="op">=</span>torch.<span class="bu">long</span>, device<span class="op">=</span><span class="st">'cuda'</span>)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Tracking for LRU cache replacement</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.access_count <span class="op">=</span> torch.zeros(<span class="va">self</span>.cache_size, dtype<span class="op">=</span>torch.<span class="bu">long</span>, device<span class="op">=</span><span class="st">'cuda'</span>)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.current_step <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> lookup(<span class="va">self</span>, indices):</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.current_step <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>        batch_size <span class="op">=</span> indices.size(<span class="dv">0</span>)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> torch.zeros(batch_size, <span class="va">self</span>.embedding_dim, device<span class="op">=</span><span class="st">'cuda'</span>)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check which indices are in cache</span></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>        cache_hits <span class="op">=</span> torch.zeros(batch_size, dtype<span class="op">=</span>torch.<span class="bu">bool</span>, device<span class="op">=</span><span class="st">'cuda'</span>)</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(batch_size):</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>            idx <span class="op">=</span> indices[i].item()</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>            cache_pos <span class="op">=</span> (<span class="va">self</span>.cache_indices <span class="op">==</span> idx).nonzero(as_tuple<span class="op">=</span><span class="va">True</span>)[<span class="dv">0</span>]</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(cache_pos) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>                cache_hits[i] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>                pos <span class="op">=</span> cache_pos[<span class="dv">0</span>].item()</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>                result[i] <span class="op">=</span> <span class="va">self</span>.gpu_cache[pos]</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.access_count[pos] <span class="op">=</span> <span class="va">self</span>.current_step</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Handle cache misses</span></span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>        miss_indices <span class="op">=</span> indices[<span class="op">~</span>cache_hits].cpu()</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(miss_indices) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>            miss_embeddings <span class="op">=</span> <span class="va">self</span>.embeddings[miss_indices].cuda()</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>            result[<span class="op">~</span>cache_hits] <span class="op">=</span> miss_embeddings</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Add to cache, replacing least recently used entries if needed</span></span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i, idx <span class="kw">in</span> <span class="bu">enumerate</span>(miss_indices):</span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a>                idx <span class="op">=</span> idx.item()</span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Find LRU entry to replace</span></span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a>                replace_idx <span class="op">=</span> torch.argmin(<span class="va">self</span>.access_count).item()</span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Update cache</span></span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.gpu_cache[replace_idx] <span class="op">=</span> miss_embeddings[i]</span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.cache_indices[replace_idx] <span class="op">=</span> idx</span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.access_count[replace_idx] <span class="op">=</span> <span class="va">self</span>.current_step</span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> result</span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-52"><a href="#cb14-52" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update(<span class="va">self</span>, indices, gradients):</span>
<span id="cb14-53"><a href="#cb14-53" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply gradients to CPU embeddings</span></span>
<span id="cb14-54"><a href="#cb14-54" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.embeddings[indices.cpu()] <span class="op">-=</span> gradients.cpu()</span>
<span id="cb14-55"><a href="#cb14-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-56"><a href="#cb14-56" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update cache if present</span></span>
<span id="cb14-57"><a href="#cb14-57" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, idx <span class="kw">in</span> <span class="bu">enumerate</span>(indices):</span>
<span id="cb14-58"><a href="#cb14-58" aria-hidden="true" tabindex="-1"></a>            idx <span class="op">=</span> idx.item()</span>
<span id="cb14-59"><a href="#cb14-59" aria-hidden="true" tabindex="-1"></a>            cache_pos <span class="op">=</span> (<span class="va">self</span>.cache_indices <span class="op">==</span> idx).nonzero(as_tuple<span class="op">=</span><span class="va">True</span>)[<span class="dv">0</span>]</span>
<span id="cb14-60"><a href="#cb14-60" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(cache_pos) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb14-61"><a href="#cb14-61" aria-hidden="true" tabindex="-1"></a>                pos <span class="op">=</span> cache_pos[<span class="dv">0</span>].item()</span>
<span id="cb14-62"><a href="#cb14-62" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.gpu_cache[pos] <span class="op">-=</span> gradients[i]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This implementation uses an LRU (Least Recently Used) cache to keep frequently accessed embeddings in GPU memory while storing the full embedding table in CPU memory.</p>
</div>
</section>
<section id="entity-and-relation-filtering" class="level3" data-number="13.5.4">
<h3 data-number="13.5.4" class="anchored" data-anchor-id="entity-and-relation-filtering"><span class="header-section-number">13.5.4</span> Entity and relation filtering</h3>
<p>Filtering techniques can focus computation on the most important entities and relations:</p>
<div id="def-filtering" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.18 (Entity and relation filtering)</strong></span> Filtering approaches include:</p>
<ol type="1">
<li><strong>Frequency-based filtering</strong>: Focusing on frequent entities and relations</li>
<li><strong>Centrality-based filtering</strong>: Prioritizing central nodes in the graph</li>
<li><strong>Task-specific filtering</strong>: Selecting entities and relations relevant to the target task</li>
<li><strong>Hierarchical modeling</strong>: Modeling important entities in detail and others more coarsely</li>
<li><strong>Dynamic entity selection</strong>: Adaptively selecting entities based on the current context</li>
</ol>
</div>
<div id="exm-filtering" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.18 (Entity filtering example)</strong></span> Implementing frequency-based entity filtering:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> collections</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Count entity frequencies</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>entity_counts <span class="op">=</span> collections.Counter()</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> h, r, t <span class="kw">in</span> triples:</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    entity_counts[h] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    entity_counts[t] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Select top-k entities for detailed modeling</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">100000</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>important_entities <span class="op">=</span> <span class="bu">set</span>([entity <span class="cf">for</span> entity, _ <span class="kw">in</span> entity_counts.most_common(k)])</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Create two-tier modeling system</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TwoTierTransE(nn.Module):</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_entities, num_relations, primary_dim<span class="op">=</span><span class="dv">200</span>, secondary_dim<span class="op">=</span><span class="dv">50</span>):</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.important_entities <span class="op">=</span> important_entities</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># High-dimensional embeddings for important entities</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.primary_entity_embedding <span class="op">=</span> nn.Embedding(k, primary_dim)</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Lower-dimensional embeddings for less important entities</span></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.secondary_entity_embedding <span class="op">=</span> nn.Embedding(num_entities <span class="op">-</span> k, secondary_dim)</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Projection for secondary embeddings to match primary dimension</span></span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.secondary_projection <span class="op">=</span> nn.Linear(secondary_dim, primary_dim, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Relation embeddings</span></span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.relation_embedding <span class="op">=</span> nn.Embedding(num_relations, primary_dim)</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Entity ID mappings</span></span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.primary_mapping <span class="op">=</span> {entity: idx <span class="cf">for</span> idx, entity <span class="kw">in</span> <span class="bu">enumerate</span>(important_entities)}</span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.secondary_mapping <span class="op">=</span> {entity: idx <span class="cf">for</span> idx, entity <span class="kw">in</span></span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a>                                 <span class="bu">enumerate</span>(<span class="bu">set</span>(<span class="bu">range</span>(num_entities)) <span class="op">-</span> important_entities)}</span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_entity_embedding(<span class="va">self</span>, entity_ids):</span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a>        result <span class="op">=</span> torch.zeros(<span class="bu">len</span>(entity_ids), <span class="va">self</span>.primary_dim, device<span class="op">=</span>entity_ids.device)</span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Process primary entities</span></span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a>        primary_mask <span class="op">=</span> torch.tensor([e <span class="kw">in</span> <span class="va">self</span>.important_entities <span class="cf">for</span> e <span class="kw">in</span> entity_ids], device<span class="op">=</span>entity_ids.device)</span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> primary_mask.<span class="bu">any</span>():</span>
<span id="cb15-42"><a href="#cb15-42" aria-hidden="true" tabindex="-1"></a>            primary_ids <span class="op">=</span> torch.tensor([<span class="va">self</span>.primary_mapping[e] <span class="cf">for</span> e <span class="kw">in</span> entity_ids[primary_mask]],</span>
<span id="cb15-43"><a href="#cb15-43" aria-hidden="true" tabindex="-1"></a>                                       device<span class="op">=</span>entity_ids.device)</span>
<span id="cb15-44"><a href="#cb15-44" aria-hidden="true" tabindex="-1"></a>            result[primary_mask] <span class="op">=</span> <span class="va">self</span>.primary_entity_embedding(primary_ids)</span>
<span id="cb15-45"><a href="#cb15-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-46"><a href="#cb15-46" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Process secondary entities</span></span>
<span id="cb15-47"><a href="#cb15-47" aria-hidden="true" tabindex="-1"></a>        secondary_mask <span class="op">=</span> <span class="op">~</span>primary_mask</span>
<span id="cb15-48"><a href="#cb15-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> secondary_mask.<span class="bu">any</span>():</span>
<span id="cb15-49"><a href="#cb15-49" aria-hidden="true" tabindex="-1"></a>            secondary_ids <span class="op">=</span> torch.tensor([<span class="va">self</span>.secondary_mapping[e] <span class="cf">for</span> e <span class="kw">in</span> entity_ids[secondary_mask]],</span>
<span id="cb15-50"><a href="#cb15-50" aria-hidden="true" tabindex="-1"></a>                                         device<span class="op">=</span>entity_ids.device)</span>
<span id="cb15-51"><a href="#cb15-51" aria-hidden="true" tabindex="-1"></a>            secondary_emb <span class="op">=</span> <span class="va">self</span>.secondary_entity_embedding(secondary_ids)</span>
<span id="cb15-52"><a href="#cb15-52" aria-hidden="true" tabindex="-1"></a>            result[secondary_mask] <span class="op">=</span> <span class="va">self</span>.secondary_projection(secondary_emb)</span>
<span id="cb15-53"><a href="#cb15-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-54"><a href="#cb15-54" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> result</span>
<span id="cb15-55"><a href="#cb15-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-56"><a href="#cb15-56" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, head, relation, tail):</span>
<span id="cb15-57"><a href="#cb15-57" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> <span class="va">self</span>.get_entity_embedding(head)</span>
<span id="cb15-58"><a href="#cb15-58" aria-hidden="true" tabindex="-1"></a>        r <span class="op">=</span> <span class="va">self</span>.relation_embedding(relation)</span>
<span id="cb15-59"><a href="#cb15-59" aria-hidden="true" tabindex="-1"></a>        t <span class="op">=</span> <span class="va">self</span>.get_entity_embedding(tail)</span>
<span id="cb15-60"><a href="#cb15-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-61"><a href="#cb15-61" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Score calculation</span></span>
<span id="cb15-62"><a href="#cb15-62" aria-hidden="true" tabindex="-1"></a>        score <span class="op">=</span> <span class="op">-</span>torch.norm(h <span class="op">+</span> r <span class="op">-</span> t, p<span class="op">=</span><span class="dv">1</span>, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb15-63"><a href="#cb15-63" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> score</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This implementation uses high-dimensional embeddings for frequent entities and lower-dimensional embeddings (with projection) for less frequent entities, reducing the overall parameter count while maintaining performance on important entities.</p>
</div>
</section>
</section>
<section id="evaluation-and-validation" class="level2" data-number="13.6">
<h2 data-number="13.6" class="anchored" data-anchor-id="evaluation-and-validation"><span class="header-section-number">13.6</span> Evaluation and validation</h2>
<p>Proper evaluation is crucial for knowledge graph embedding systems:</p>
<section id="evaluation-metrics" class="level3" data-number="13.6.1">
<h3 data-number="13.6.1" class="anchored" data-anchor-id="evaluation-metrics"><span class="header-section-number">13.6.1</span> Evaluation metrics</h3>
<div id="def-evaluation-metrics" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.19 (Evaluation metrics implementation)</strong></span> Common evaluation metrics include:</p>
<ol type="1">
<li><strong>Mean Rank (MR)</strong>: Average rank of correct entities</li>
<li><strong>Mean Reciprocal Rank (MRR)</strong>: Average of reciprocal ranks</li>
<li><strong>Hits@k</strong>: Percentage of test cases where correct entity is in top k</li>
<li><strong>Filtered metrics</strong>: Metrics calculated after removing other correct answers</li>
<li><strong>Area Under the ROC Curve (AUC)</strong>: For triple classification tasks</li>
<li><strong>Precision, Recall, F1-score</strong>: For triple classification with threshold</li>
</ol>
</div>
<div id="exm-evaluation" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.19 (Evaluation implementation example)</strong></span> Implementing filtered evaluation metrics:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_model(model, test_triples, all_triples, entity_ids, relation_ids, batch_size<span class="op">=</span><span class="dv">128</span>):</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    ranks <span class="op">=</span> []</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    hits_at_1 <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    hits_at_3 <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    hits_at_10 <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch_start <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(test_triples), batch_size):</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>            batch_end <span class="op">=</span> <span class="bu">min</span>(batch_start <span class="op">+</span> batch_size, <span class="bu">len</span>(test_triples))</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>            batch <span class="op">=</span> test_triples[batch_start:batch_end]</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> h, r, t <span class="kw">in</span> batch:</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Tail prediction</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>                heads <span class="op">=</span> torch.tensor([h] <span class="op">*</span> <span class="bu">len</span>(entity_ids), device<span class="op">=</span>model.device)</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>                relations <span class="op">=</span> torch.tensor([r] <span class="op">*</span> <span class="bu">len</span>(entity_ids), device<span class="op">=</span>model.device)</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>                tails <span class="op">=</span> torch.tensor(entity_ids, device<span class="op">=</span>model.device)</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>                scores <span class="op">=</span> model(heads, relations, tails)</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Filter out existing triples</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> h_tmp, r_tmp, t_tmp <span class="kw">in</span> all_triples:</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> h_tmp <span class="op">==</span> h <span class="kw">and</span> r_tmp <span class="op">==</span> r <span class="kw">and</span> t_tmp <span class="op">!=</span> t:</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>                        <span class="co"># This is another valid tail for (h,r)</span></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>                        idx <span class="op">=</span> entity_ids.index(t_tmp)</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>                        scores[idx] <span class="op">=</span> <span class="bu">float</span>(<span class="st">'-inf'</span>)</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Get rank</span></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>                _, sorted_indices <span class="op">=</span> torch.sort(scores, descending<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>                rank <span class="op">=</span> (sorted_indices <span class="op">==</span> entity_ids.index(t)).nonzero(as_tuple<span class="op">=</span><span class="va">True</span>)[<span class="dv">0</span>].item() <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>                ranks.append(rank)</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Calculate hits</span></span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> rank <span class="op">&lt;=</span> <span class="dv">1</span>:</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>                    hits_at_1 <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> rank <span class="op">&lt;=</span> <span class="dv">3</span>:</span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>                    hits_at_3 <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> rank <span class="op">&lt;=</span> <span class="dv">10</span>:</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>                    hits_at_10 <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Head prediction (similar process)</span></span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a>                <span class="co"># ...</span></span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate metrics</span></span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>    mr <span class="op">=</span> <span class="bu">sum</span>(ranks) <span class="op">/</span> <span class="bu">len</span>(ranks)</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>    mrr <span class="op">=</span> <span class="bu">sum</span>(<span class="fl">1.0</span> <span class="op">/</span> rank <span class="cf">for</span> rank <span class="kw">in</span> ranks) <span class="op">/</span> <span class="bu">len</span>(ranks)</span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>    hits_at_1 <span class="op">=</span> hits_at_1 <span class="op">/</span> <span class="bu">len</span>(ranks)</span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a>    hits_at_3 <span class="op">=</span> hits_at_3 <span class="op">/</span> <span class="bu">len</span>(ranks)</span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a>    hits_at_10 <span class="op">=</span> hits_at_10 <span class="op">/</span> <span class="bu">len</span>(ranks)</span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {</span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a>        <span class="st">'MR'</span>: mr,</span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a>        <span class="st">'MRR'</span>: mrr,</span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Hits@1'</span>: hits_at_1,</span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Hits@3'</span>: hits_at_3,</span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Hits@10'</span>: hits_at_10</span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a>    }</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This implementation handles filtered evaluation, which removes other known correct answers when computing ranks to avoid penalizing the model for predicting valid alternatives.</p>
</div>
</section>
<section id="validation-strategies" class="level3" data-number="13.6.2">
<h3 data-number="13.6.2" class="anchored" data-anchor-id="validation-strategies"><span class="header-section-number">13.6.2</span> Validation strategies</h3>
<p>Proper validation ensures reliable model selection:</p>
<div id="def-validation" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.20 (Validation strategies)</strong></span> Effective validation approaches:</p>
<ol type="1">
<li><strong>Cross-validation</strong>: Evaluating on multiple train/test splits</li>
<li><strong>Time-based validation</strong>: Using chronological splits for temporal data</li>
<li><strong>Entity-based validation</strong>: Holding out specific entities for inductive evaluation</li>
<li><strong>Relation-based validation</strong>: Testing generalization to specific relation types</li>
<li><strong>Adversarial validation</strong>: Testing robustness against adversarial examples</li>
<li><strong>Out-of-distribution validation</strong>: Testing generalization to new domains</li>
</ol>
</div>
<div id="exm-validation" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.20 (Validation strategy example)</strong></span> Implementing time-based validation for temporal knowledge graphs:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datetime <span class="im">import</span> datetime</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load triples with timestamps</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>triples_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'head'</span>: [h <span class="cf">for</span> h, _, _, _ <span class="kw">in</span> temporal_triples],</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'relation'</span>: [r <span class="cf">for</span> _, r, _, _ <span class="kw">in</span> temporal_triples],</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'tail'</span>: [t <span class="cf">for</span> _, _, t, _ <span class="kw">in</span> temporal_triples],</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'timestamp'</span>: [ts <span class="cf">for</span> _, _, _, ts <span class="kw">in</span> temporal_triples]</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort by timestamp</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>triples_df[<span class="st">'date'</span>] <span class="op">=</span> pd.to_datetime(triples_df[<span class="st">'timestamp'</span>])</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>triples_df <span class="op">=</span> triples_df.sort_values(<span class="st">'date'</span>)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Create chronological splits</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>train_cutoff <span class="op">=</span> datetime(<span class="dv">2018</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>val_cutoff <span class="op">=</span> datetime(<span class="dv">2019</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>train_df <span class="op">=</span> triples_df[triples_df[<span class="st">'date'</span>] <span class="op">&lt;</span> train_cutoff]</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>val_df <span class="op">=</span> triples_df[(triples_df[<span class="st">'date'</span>] <span class="op">&gt;=</span> train_cutoff) <span class="op">&amp;</span> (triples_df[<span class="st">'date'</span>] <span class="op">&lt;</span> val_cutoff)]</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>test_df <span class="op">=</span> triples_df[triples_df[<span class="st">'date'</span>] <span class="op">&gt;=</span> val_cutoff]</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Train: </span><span class="sc">{</span><span class="bu">len</span>(train_df)<span class="sc">}</span><span class="ss"> triples from </span><span class="sc">{</span>train_df[<span class="st">'date'</span>]<span class="sc">.</span><span class="bu">min</span>()<span class="sc">}</span><span class="ss"> to </span><span class="sc">{</span>train_df[<span class="st">'date'</span>]<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Validation: </span><span class="sc">{</span><span class="bu">len</span>(val_df)<span class="sc">}</span><span class="ss"> triples from </span><span class="sc">{</span>val_df[<span class="st">'date'</span>]<span class="sc">.</span><span class="bu">min</span>()<span class="sc">}</span><span class="ss"> to </span><span class="sc">{</span>val_df[<span class="st">'date'</span>]<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Test: </span><span class="sc">{</span><span class="bu">len</span>(test_df)<span class="sc">}</span><span class="ss"> triples from </span><span class="sc">{</span>test_df[<span class="st">'date'</span>]<span class="sc">.</span><span class="bu">min</span>()<span class="sc">}</span><span class="ss"> to </span><span class="sc">{</span>test_df[<span class="st">'date'</span>]<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert back to triples</span></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>train_triples <span class="op">=</span> [(row[<span class="st">'head'</span>], row[<span class="st">'relation'</span>], row[<span class="st">'tail'</span>]) <span class="cf">for</span> _, row <span class="kw">in</span> train_df.iterrows()]</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>val_triples <span class="op">=</span> [(row[<span class="st">'head'</span>], row[<span class="st">'relation'</span>], row[<span class="st">'tail'</span>]) <span class="cf">for</span> _, row <span class="kw">in</span> val_df.iterrows()]</span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>test_triples <span class="op">=</span> [(row[<span class="st">'head'</span>], row[<span class="st">'relation'</span>], row[<span class="st">'tail'</span>]) <span class="cf">for</span> _, row <span class="kw">in</span> test_df.iterrows()]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This approach creates chronological train/validation/test splits for temporal knowledge graphs, simulating the real-world scenario where models are trained on historical data and used to predict future relationships.</p>
</div>
</section>
<section id="reproducibility-considerations" class="level3" data-number="13.6.3">
<h3 data-number="13.6.3" class="anchored" data-anchor-id="reproducibility-considerations"><span class="header-section-number">13.6.3</span> Reproducibility considerations</h3>
<p>Ensuring reproducibility is important for reliable evaluation:</p>
<div id="def-reproducibility" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.21 (Reproducibility considerations)</strong></span> Key reproducibility practices:</p>
<ol type="1">
<li><strong>Fixed random seeds</strong>: Setting all random seeds for deterministic behavior</li>
<li><strong>Documented hyperparameters</strong>: Clearly recording all hyperparameter values</li>
<li><strong>Environment specification</strong>: Documenting software versions and hardware</li>
<li><strong>Dataset versioning</strong>: Tracking dataset versions and preprocessing steps</li>
<li><strong>Code versioning</strong>: Using version control for implementation code</li>
<li><strong>Model checkpointing</strong>: Saving models at key points for later verification</li>
</ol>
</div>
<div id="exm-reproducibility" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.21 (Reproducibility example)</strong></span> Setting up a reproducible environment:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> set_seed(seed):</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Set all random seeds for reproducibility."""</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> random</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> torch</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    random.seed(seed)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    np.random.seed(seed)</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    torch.manual_seed(seed)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    torch.cuda.manual_seed_all(seed)</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    torch.backends.cudnn.deterministic <span class="op">=</span> <span class="va">True</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    torch.backends.cudnn.benchmark <span class="op">=</span> <span class="va">False</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> seed</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_environment_info():</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Get information about the current environment."""</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> platform</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> torch</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> sys</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>    info <span class="op">=</span> {</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>        <span class="st">'python_version'</span>: platform.python_version(),</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>        <span class="st">'pytorch_version'</span>: torch.__version__,</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>        <span class="st">'cuda_version'</span>: torch.version.cuda,</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">'cuda_available'</span>: torch.cuda.is_available(),</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>        <span class="st">'gpu_count'</span>: torch.cuda.device_count(),</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>        <span class="st">'gpu_names'</span>: [torch.cuda.get_device_name(i) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(torch.cuda.device_count())],</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>        <span class="st">'system'</span>: platform.system(),</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>        <span class="st">'processor'</span>: platform.processor(),</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>        <span class="st">'packages'</span>: {pkg: pkg_info.version <span class="cf">for</span> pkg, pkg_info <span class="kw">in</span> sys.modules.items()</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>                     <span class="cf">if</span> <span class="bu">hasattr</span>(pkg_info, <span class="st">'__version__'</span>)}</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> info</span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up reproducible environment</span></span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>seed <span class="op">=</span> set_seed(<span class="dv">42</span>)</span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>env_info <span class="op">=</span> get_environment_info()</span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Log environment and configuration</span></span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="st">'experiment_metadata.json'</span>, <span class="st">'w'</span>) <span class="im">as</span> f:</span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>    json.dump({</span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>        <span class="st">'seed'</span>: seed,</span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>        <span class="st">'environment'</span>: env_info,</span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a>        <span class="st">'hyperparameters'</span>: {</span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a>            <span class="st">'embedding_dim'</span>: <span class="dv">200</span>,</span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a>            <span class="st">'batch_size'</span>: <span class="dv">512</span>,</span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a>            <span class="st">'learning_rate'</span>: <span class="fl">0.0005</span>,</span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a>            <span class="st">'margin'</span>: <span class="fl">1.0</span>,</span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a>            <span class="st">'epochs'</span>: <span class="dv">1000</span>,</span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a>            <span class="st">'negative_samples'</span>: <span class="dv">5</span></span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a>    }, f, indent<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This implementation sets up a reproducible environment by fixing random seeds and documenting the software versions, hardware, and hyperparameters.</p>
</div>
</section>
</section>
<section id="deployment-architectures" class="level2" data-number="13.7">
<h2 data-number="13.7" class="anchored" data-anchor-id="deployment-architectures"><span class="header-section-number">13.7</span> Deployment architectures</h2>
<p>Deploying knowledge graph embedding systems requires careful architectural design:</p>
<section id="serving-architectures" class="level3" data-number="13.7.1">
<h3 data-number="13.7.1" class="anchored" data-anchor-id="serving-architectures"><span class="header-section-number">13.7.1</span> Serving architectures</h3>
<div id="def-serving" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.22 (Serving architectures)</strong></span> Common serving architectures include:</p>
<ol type="1">
<li><strong>Batch processing</strong>: Running inference on batches of queries</li>
<li><strong>Real-time serving</strong>: Providing low-latency responses to individual queries</li>
<li><strong>Hybrid approaches</strong>: Combining pre-computed and real-time results</li>
<li><strong>Client-server architecture</strong>: Separating embedding lookup from application logic</li>
<li><strong>Serverless deployment</strong>: Using cloud functions for scalable serving</li>
<li><strong>Edge deployment</strong>: Running inference on edge devices for low-latency applications</li>
</ol>
</div>
<div id="exm-serving" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.22 (Serving architecture example)</strong></span> Implementing a real-time serving API:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastapi <span class="im">import</span> FastAPI, HTTPException</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pydantic <span class="im">import</span> BaseModel</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>app <span class="op">=</span> FastAPI(title<span class="op">=</span><span class="st">"Knowledge Graph Embedding API"</span>)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Load pre-trained model</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> torch.load(<span class="st">'models/transe_model.pt'</span>)</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()  <span class="co"># Set to evaluation mode</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Load entity and relation mappings</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>entity_to_id <span class="op">=</span> torch.load(<span class="st">'models/entity_to_id.pt'</span>)</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>id_to_entity <span class="op">=</span> {v: k <span class="cf">for</span> k, v <span class="kw">in</span> entity_to_id.items()}</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>relation_to_id <span class="op">=</span> torch.load(<span class="st">'models/relation_to_id.pt'</span>)</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>id_to_relation <span class="op">=</span> {v: k <span class="cf">for</span> k, v <span class="kw">in</span> relation_to_id.items()}</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Request models</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LinkPredictionRequest(BaseModel):</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>    head: <span class="bu">str</span> <span class="op">=</span> <span class="va">None</span></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>    relation: <span class="bu">str</span> <span class="op">=</span> <span class="va">None</span></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>    tail: <span class="bu">str</span> <span class="op">=</span> <span class="va">None</span></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>    k: <span class="bu">int</span> <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a><span class="at">@app.post</span>(<span class="st">"/predict_links"</span>)</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a><span class="cf">async</span> <span class="kw">def</span> predict_links(request: LinkPredictionRequest):</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Validate request</span></span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">sum</span>(x <span class="kw">is</span> <span class="va">None</span> <span class="cf">for</span> x <span class="kw">in</span> [request.head, request.relation, request.tail]) <span class="op">!=</span> <span class="dv">1</span>:</span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> HTTPException(status_code<span class="op">=</span><span class="dv">400</span>, detail<span class="op">=</span><span class="st">"Exactly one of head, relation, or tail must be None"</span>)</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Predict missing entity</span></span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> request.head <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Head prediction</span></span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>            r_id <span class="op">=</span> relation_to_id[request.relation]</span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>            t_id <span class="op">=</span> entity_to_id[request.tail]</span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Generate scores for all entities as head</span></span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> torch.no_grad():</span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a>                heads <span class="op">=</span> torch.arange(<span class="bu">len</span>(entity_to_id)).to(model.device)</span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>                relations <span class="op">=</span> torch.full_like(heads, r_id).to(model.device)</span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a>                tails <span class="op">=</span> torch.full_like(heads, t_id).to(model.device)</span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>                scores <span class="op">=</span> model(heads, relations, tails)</span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Get top-k entities</span></span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a>            top_k_scores, top_k_indices <span class="op">=</span> torch.topk(scores, k<span class="op">=</span>request.k)</span>
<span id="cb19-48"><a href="#cb19-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-49"><a href="#cb19-49" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Convert to entity names</span></span>
<span id="cb19-50"><a href="#cb19-50" aria-hidden="true" tabindex="-1"></a>            results <span class="op">=</span> [</span>
<span id="cb19-51"><a href="#cb19-51" aria-hidden="true" tabindex="-1"></a>                {<span class="st">"entity"</span>: id_to_entity[idx.item()], <span class="st">"score"</span>: score.item()}</span>
<span id="cb19-52"><a href="#cb19-52" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> idx, score <span class="kw">in</span> <span class="bu">zip</span>(top_k_indices, top_k_scores)</span>
<span id="cb19-53"><a href="#cb19-53" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb19-54"><a href="#cb19-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-55"><a href="#cb19-55" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> {</span>
<span id="cb19-56"><a href="#cb19-56" aria-hidden="true" tabindex="-1"></a>                <span class="st">"query"</span>: {<span class="st">"relation"</span>: request.relation, <span class="st">"tail"</span>: request.tail},</span>
<span id="cb19-57"><a href="#cb19-57" aria-hidden="true" tabindex="-1"></a>                <span class="st">"predictions"</span>: results</span>
<span id="cb19-58"><a href="#cb19-58" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb19-59"><a href="#cb19-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-60"><a href="#cb19-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> request.relation <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb19-61"><a href="#cb19-61" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Relation prediction</span></span>
<span id="cb19-62"><a href="#cb19-62" aria-hidden="true" tabindex="-1"></a>            <span class="co"># (Similar implementation)</span></span>
<span id="cb19-63"><a href="#cb19-63" aria-hidden="true" tabindex="-1"></a>            <span class="cf">pass</span></span>
<span id="cb19-64"><a href="#cb19-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-65"><a href="#cb19-65" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:  <span class="co"># request.tail is None</span></span>
<span id="cb19-66"><a href="#cb19-66" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Tail prediction</span></span>
<span id="cb19-67"><a href="#cb19-67" aria-hidden="true" tabindex="-1"></a>            <span class="co"># (Similar implementation)</span></span>
<span id="cb19-68"><a href="#cb19-68" aria-hidden="true" tabindex="-1"></a>            <span class="cf">pass</span></span>
<span id="cb19-69"><a href="#cb19-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-70"><a href="#cb19-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">KeyError</span> <span class="im">as</span> e:</span>
<span id="cb19-71"><a href="#cb19-71" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> HTTPException(status_code<span class="op">=</span><span class="dv">404</span>, detail<span class="op">=</span><span class="ss">f"Entity or relation not found: </span><span class="sc">{</span><span class="bu">str</span>(e)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This example implements a FastAPI-based service for real-time link prediction, which can be deployed as a microservice in a containerized environment.</p>
</div>
</section>
<section id="caching-strategies" class="level3" data-number="13.7.2">
<h3 data-number="13.7.2" class="anchored" data-anchor-id="caching-strategies"><span class="header-section-number">13.7.2</span> Caching strategies</h3>
<p>Caching can significantly improve performance:</p>
<div id="def-caching" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.23 (Caching strategies)</strong></span> Effective caching approaches:</p>
<ol type="1">
<li><strong>Entity embedding cache</strong>: Caching frequently accessed entity embeddings</li>
<li><strong>Query result cache</strong>: Caching results of common queries</li>
<li><strong>Hierarchical caching</strong>: Using multiple cache levels with different characteristics</li>
<li><strong>Distributed caching</strong>: Spreading the cache across multiple machines</li>
<li><strong>Predictive caching</strong>: Pre-loading embeddings based on access patterns</li>
<li><strong>Cache invalidation</strong>: Strategies for refreshing the cache when models are updated</li>
</ol>
</div>
<div id="exm-caching" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.23 (Caching implementation example)</strong></span> Implementing a query result cache:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> functools <span class="im">import</span> lru_cache</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> hashlib</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pickle</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> KGEmbeddingService:</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, model, entity_map, relation_map, cache_size<span class="op">=</span><span class="dv">10000</span>):</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.entity_map <span class="op">=</span> entity_map</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.relation_map <span class="op">=</span> relation_map</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.id_to_entity <span class="op">=</span> {v: k <span class="cf">for</span> k, v <span class="kw">in</span> entity_map.items()}</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.id_to_relation <span class="op">=</span> {v: k <span class="cf">for</span> k, v <span class="kw">in</span> relation_map.items()}</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Setup caches</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.entity_embedding_cache <span class="op">=</span> {}</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.setup_query_cache(cache_size)</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> setup_query_cache(<span class="va">self</span>, cache_size):</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Use LRU cache for query results</span></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>        <span class="at">@lru_cache</span>(maxsize<span class="op">=</span>cache_size)</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> cached_query_fn(query_hash):</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Deserialize the query from the hash</span></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>            query_data <span class="op">=</span> <span class="va">self</span>.query_hash_map.get(query_hash)</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="kw">not</span> query_data:</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Execute the actual query</span></span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>            query_type, head, relation, tail, k <span class="op">=</span> pickle.loads(query_data)</span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> query_type <span class="op">==</span> <span class="st">'head'</span>:</span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> <span class="va">self</span>._predict_head(relation, tail, k)</span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> query_type <span class="op">==</span> <span class="st">'relation'</span>:</span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> <span class="va">self</span>._predict_relation(head, tail, k)</span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:  <span class="co"># query_type == 'tail'</span></span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> <span class="va">self</span>._predict_tail(head, relation, k)</span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.query_cache <span class="op">=</span> cached_query_fn</span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.query_hash_map <span class="op">=</span> {}</span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _hash_query(<span class="va">self</span>, query_type, head, relation, tail, k):</span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Create a hash for the query parameters."""</span></span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a>        query_data <span class="op">=</span> pickle.dumps((query_type, head, relation, tail, k))</span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a>        query_hash <span class="op">=</span> hashlib.md5(query_data).hexdigest()</span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.query_hash_map[query_hash] <span class="op">=</span> query_data</span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> query_hash</span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _get_entity_embedding(<span class="va">self</span>, entity_id):</span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Get entity embedding with caching."""</span></span>
<span id="cb20-48"><a href="#cb20-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> entity_id <span class="kw">in</span> <span class="va">self</span>.entity_embedding_cache:</span>
<span id="cb20-49"><a href="#cb20-49" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.entity_embedding_cache[entity_id]</span>
<span id="cb20-50"><a href="#cb20-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-51"><a href="#cb20-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb20-52"><a href="#cb20-52" aria-hidden="true" tabindex="-1"></a>            embedding <span class="op">=</span> <span class="va">self</span>.model.entity_embedding(torch.tensor([entity_id]).to(<span class="va">self</span>.model.device))[<span class="dv">0</span>]</span>
<span id="cb20-53"><a href="#cb20-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-54"><a href="#cb20-54" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Cache the embedding</span></span>
<span id="cb20-55"><a href="#cb20-55" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.entity_embedding_cache[entity_id] <span class="op">=</span> embedding</span>
<span id="cb20-56"><a href="#cb20-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> embedding</span>
<span id="cb20-57"><a href="#cb20-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-58"><a href="#cb20-58" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict_tail(<span class="va">self</span>, head, relation, k<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb20-59"><a href="#cb20-59" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Predict top-k tail entities with caching."""</span></span>
<span id="cb20-60"><a href="#cb20-60" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert names to IDs</span></span>
<span id="cb20-61"><a href="#cb20-61" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb20-62"><a href="#cb20-62" aria-hidden="true" tabindex="-1"></a>            head_id <span class="op">=</span> <span class="va">self</span>.entity_map.get(head)</span>
<span id="cb20-63"><a href="#cb20-63" aria-hidden="true" tabindex="-1"></a>            relation_id <span class="op">=</span> <span class="va">self</span>.relation_map.get(relation)</span>
<span id="cb20-64"><a href="#cb20-64" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> head_id <span class="kw">is</span> <span class="va">None</span> <span class="kw">or</span> relation_id <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb20-65"><a href="#cb20-65" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> {<span class="st">"error"</span>: <span class="st">"Entity or relation not found"</span>}</span>
<span id="cb20-66"><a href="#cb20-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-67"><a href="#cb20-67" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Check cache</span></span>
<span id="cb20-68"><a href="#cb20-68" aria-hidden="true" tabindex="-1"></a>            query_hash <span class="op">=</span> <span class="va">self</span>._hash_query(<span class="st">'tail'</span>, head_id, relation_id, <span class="va">None</span>, k)</span>
<span id="cb20-69"><a href="#cb20-69" aria-hidden="true" tabindex="-1"></a>            result <span class="op">=</span> <span class="va">self</span>.query_cache(query_hash)</span>
<span id="cb20-70"><a href="#cb20-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-71"><a href="#cb20-71" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> result <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb20-72"><a href="#cb20-72" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Cache miss, compute the result</span></span>
<span id="cb20-73"><a href="#cb20-73" aria-hidden="true" tabindex="-1"></a>                result <span class="op">=</span> <span class="va">self</span>._predict_tail(head_id, relation_id, k)</span>
<span id="cb20-74"><a href="#cb20-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-75"><a href="#cb20-75" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> result</span>
<span id="cb20-76"><a href="#cb20-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-77"><a href="#cb20-77" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb20-78"><a href="#cb20-78" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> {<span class="st">"error"</span>: <span class="bu">str</span>(e)}</span>
<span id="cb20-79"><a href="#cb20-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-80"><a href="#cb20-80" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _predict_tail(<span class="va">self</span>, head_id, relation_id, k):</span>
<span id="cb20-81"><a href="#cb20-81" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Internal implementation of tail prediction."""</span></span>
<span id="cb20-82"><a href="#cb20-82" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Implementation details</span></span>
<span id="cb20-83"><a href="#cb20-83" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This implementation uses a combination of LRU caching for query results and a simple dictionary cache for entity embeddings, significantly reducing computation for repeated queries.</p>
</div>
</section>
<section id="monitoring-and-maintenance" class="level3" data-number="13.7.3">
<h3 data-number="13.7.3" class="anchored" data-anchor-id="monitoring-and-maintenance"><span class="header-section-number">13.7.3</span> Monitoring and maintenance</h3>
<p>Ongoing monitoring is essential for production systems:</p>
<div id="def-monitoring" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.24 (Monitoring and maintenance)</strong></span> Key monitoring considerations:</p>
<ol type="1">
<li><strong>Performance tracking</strong>: Monitoring key metrics over time</li>
<li><strong>Data drift detection</strong>: Identifying changes in the input distribution</li>
<li><strong>Model drift detection</strong>: Detecting when model performance degrades</li>
<li><strong>Resource monitoring</strong>: Tracking memory, CPU, and GPU usage</li>
<li><strong>Alerting systems</strong>: Setting up alerts for anomalies or performance issues</li>
<li><strong>Continuous evaluation</strong>: Regularly evaluating against benchmark datasets</li>
<li><strong>Automated retraining</strong>: Setting up pipelines for model refreshing</li>
</ol>
</div>
<div id="exm-monitoring" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.24 (Monitoring implementation example)</strong></span> Setting up basic model monitoring:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> logging</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> datetime</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> prometheus_client <span class="im">import</span> start_http_server, Summary, Counter, Gauge</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Configure logging</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>logging.basicConfig(level<span class="op">=</span>logging.INFO, <span class="bu">format</span><span class="op">=</span><span class="st">'</span><span class="sc">%(asctime)s</span><span class="st"> - </span><span class="sc">%(levelname)s</span><span class="st"> - </span><span class="sc">%(message)s</span><span class="st">'</span>)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>logger <span class="op">=</span> logging.getLogger(<span class="st">"kge_monitoring"</span>)</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up Prometheus metrics</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>QUERY_TIME <span class="op">=</span> Summary(<span class="st">'query_processing_seconds'</span>, <span class="st">'Time spent processing query'</span>)</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>QUERY_COUNT <span class="op">=</span> Counter(<span class="st">'queries_total'</span>, <span class="st">'Total number of queries'</span>, [<span class="st">'query_type'</span>])</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>CACHE_HITS <span class="op">=</span> Counter(<span class="st">'cache_hits_total'</span>, <span class="st">'Total number of cache hits'</span>)</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>CACHE_MISSES <span class="op">=</span> Counter(<span class="st">'cache_misses_total'</span>, <span class="st">'Total number of cache misses'</span>)</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>MODEL_PERFORMANCE <span class="op">=</span> Gauge(<span class="st">'model_mrr'</span>, <span class="st">'Model MRR on evaluation set'</span>)</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Performance history</span></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>performance_history <span class="op">=</span> []</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MonitoredKGEmbeddingService:</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, base_service, evaluation_dataset, evaluation_frequency<span class="op">=</span><span class="dv">24</span><span class="op">*</span><span class="dv">60</span><span class="op">*</span><span class="dv">60</span>):</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.service <span class="op">=</span> base_service</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.evaluation_dataset <span class="op">=</span> evaluation_dataset</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.evaluation_frequency <span class="op">=</span> evaluation_frequency</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.last_evaluation_time <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Start Prometheus metrics server</span></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>        start_http_server(<span class="dv">8000</span>)</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initial evaluation</span></span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.evaluate_model()</span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict_tail(<span class="va">self</span>, head, relation, k<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Track query time</span></span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> QUERY_TIME.time():</span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Increment query counter</span></span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a>            QUERY_COUNT.labels(query_type<span class="op">=</span><span class="st">'tail'</span>).inc()</span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Check if cache hit</span></span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a>            <span class="co"># (Implementation details)</span></span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-44"><a href="#cb21-44" aria-hidden="true" tabindex="-1"></a>            result <span class="op">=</span> <span class="va">self</span>.service.predict_tail(head, relation, k)</span>
<span id="cb21-45"><a href="#cb21-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-46"><a href="#cb21-46" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Check if it's time to re-evaluate</span></span>
<span id="cb21-47"><a href="#cb21-47" aria-hidden="true" tabindex="-1"></a>            current_time <span class="op">=</span> time.time()</span>
<span id="cb21-48"><a href="#cb21-48" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> current_time <span class="op">-</span> <span class="va">self</span>.last_evaluation_time <span class="op">&gt;</span> <span class="va">self</span>.evaluation_frequency:</span>
<span id="cb21-49"><a href="#cb21-49" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.evaluate_model()</span>
<span id="cb21-50"><a href="#cb21-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-51"><a href="#cb21-51" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> result</span>
<span id="cb21-52"><a href="#cb21-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-53"><a href="#cb21-53" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> evaluate_model(<span class="va">self</span>):</span>
<span id="cb21-54"><a href="#cb21-54" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Evaluate model on benchmark dataset and log results."""</span></span>
<span id="cb21-55"><a href="#cb21-55" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb21-56"><a href="#cb21-56" aria-hidden="true" tabindex="-1"></a>            logger.info(<span class="st">"Starting model evaluation"</span>)</span>
<span id="cb21-57"><a href="#cb21-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-58"><a href="#cb21-58" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Evaluate model</span></span>
<span id="cb21-59"><a href="#cb21-59" aria-hidden="true" tabindex="-1"></a>            <span class="co"># (Implementation details)</span></span>
<span id="cb21-60"><a href="#cb21-60" aria-hidden="true" tabindex="-1"></a>            metrics <span class="op">=</span> {<span class="st">'MRR'</span>: <span class="fl">0.75</span>, <span class="st">'Hits@10'</span>: <span class="fl">0.85</span>}  <span class="co"># Example metrics</span></span>
<span id="cb21-61"><a href="#cb21-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-62"><a href="#cb21-62" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Update Prometheus gauge</span></span>
<span id="cb21-63"><a href="#cb21-63" aria-hidden="true" tabindex="-1"></a>            MODEL_PERFORMANCE.<span class="bu">set</span>(metrics[<span class="st">'MRR'</span>])</span>
<span id="cb21-64"><a href="#cb21-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-65"><a href="#cb21-65" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Record metrics with timestamp</span></span>
<span id="cb21-66"><a href="#cb21-66" aria-hidden="true" tabindex="-1"></a>            metrics[<span class="st">'timestamp'</span>] <span class="op">=</span> datetime.datetime.now()</span>
<span id="cb21-67"><a href="#cb21-67" aria-hidden="true" tabindex="-1"></a>            performance_history.append(metrics)</span>
<span id="cb21-68"><a href="#cb21-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-69"><a href="#cb21-69" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Save history to file</span></span>
<span id="cb21-70"><a href="#cb21-70" aria-hidden="true" tabindex="-1"></a>            pd.DataFrame(performance_history).to_csv(<span class="st">'performance_history.csv'</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb21-71"><a href="#cb21-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-72"><a href="#cb21-72" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Generate performance plot</span></span>
<span id="cb21-73"><a href="#cb21-73" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>._generate_performance_plot()</span>
<span id="cb21-74"><a href="#cb21-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-75"><a href="#cb21-75" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Update last evaluation time</span></span>
<span id="cb21-76"><a href="#cb21-76" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.last_evaluation_time <span class="op">=</span> time.time()</span>
<span id="cb21-77"><a href="#cb21-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-78"><a href="#cb21-78" aria-hidden="true" tabindex="-1"></a>            logger.info(<span class="ss">f"Model evaluation complete: MRR=</span><span class="sc">{</span>metrics[<span class="st">'MRR'</span>]<span class="sc">}</span><span class="ss">, Hits@10=</span><span class="sc">{</span>metrics[<span class="st">'Hits@10'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-79"><a href="#cb21-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-80"><a href="#cb21-80" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Check for performance degradation</span></span>
<span id="cb21-81"><a href="#cb21-81" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(performance_history) <span class="op">&gt;=</span> <span class="dv">2</span>:</span>
<span id="cb21-82"><a href="#cb21-82" aria-hidden="true" tabindex="-1"></a>                current_mrr <span class="op">=</span> metrics[<span class="st">'MRR'</span>]</span>
<span id="cb21-83"><a href="#cb21-83" aria-hidden="true" tabindex="-1"></a>                previous_mrr <span class="op">=</span> performance_history[<span class="op">-</span><span class="dv">2</span>][<span class="st">'MRR'</span>]</span>
<span id="cb21-84"><a href="#cb21-84" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> current_mrr <span class="op">&lt;</span> previous_mrr <span class="op">*</span> <span class="fl">0.9</span>:  <span class="co"># 10% degradation</span></span>
<span id="cb21-85"><a href="#cb21-85" aria-hidden="true" tabindex="-1"></a>                    logger.warning(<span class="ss">f"Performance degradation detected! MRR dropped from </span><span class="sc">{</span>previous_mrr<span class="sc">}</span><span class="ss"> to </span><span class="sc">{</span>current_mrr<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-86"><a href="#cb21-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-87"><a href="#cb21-87" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb21-88"><a href="#cb21-88" aria-hidden="true" tabindex="-1"></a>            logger.error(<span class="ss">f"Error during model evaluation: </span><span class="sc">{</span><span class="bu">str</span>(e)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-89"><a href="#cb21-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-90"><a href="#cb21-90" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _generate_performance_plot(<span class="va">self</span>):</span>
<span id="cb21-91"><a href="#cb21-91" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Generate performance trend plot."""</span></span>
<span id="cb21-92"><a href="#cb21-92" aria-hidden="true" tabindex="-1"></a>        df <span class="op">=</span> pd.DataFrame(performance_history)</span>
<span id="cb21-93"><a href="#cb21-93" aria-hidden="true" tabindex="-1"></a>        plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb21-94"><a href="#cb21-94" aria-hidden="true" tabindex="-1"></a>        plt.plot(df[<span class="st">'timestamp'</span>], df[<span class="st">'MRR'</span>], marker<span class="op">=</span><span class="st">'o'</span>, label<span class="op">=</span><span class="st">'MRR'</span>)</span>
<span id="cb21-95"><a href="#cb21-95" aria-hidden="true" tabindex="-1"></a>        plt.plot(df[<span class="st">'timestamp'</span>], df[<span class="st">'Hits@10'</span>], marker<span class="op">=</span><span class="st">'s'</span>, label<span class="op">=</span><span class="st">'Hits@10'</span>)</span>
<span id="cb21-96"><a href="#cb21-96" aria-hidden="true" tabindex="-1"></a>        plt.xlabel(<span class="st">'Time'</span>)</span>
<span id="cb21-97"><a href="#cb21-97" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(<span class="st">'Score'</span>)</span>
<span id="cb21-98"><a href="#cb21-98" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="st">'Model Performance Over Time'</span>)</span>
<span id="cb21-99"><a href="#cb21-99" aria-hidden="true" tabindex="-1"></a>        plt.legend()</span>
<span id="cb21-100"><a href="#cb21-100" aria-hidden="true" tabindex="-1"></a>        plt.grid(<span class="va">True</span>)</span>
<span id="cb21-101"><a href="#cb21-101" aria-hidden="true" tabindex="-1"></a>        plt.tight_layout()</span>
<span id="cb21-102"><a href="#cb21-102" aria-hidden="true" tabindex="-1"></a>        plt.savefig(<span class="st">'performance_trend.png'</span>)</span>
<span id="cb21-103"><a href="#cb21-103" aria-hidden="true" tabindex="-1"></a>        plt.close()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This implementation sets up monitoring using Prometheus metrics, logging, and periodic evaluation to track model performance over time and detect degradation.</p>
</div>
</section>
<section id="incremental-learning" class="level3" data-number="13.7.4">
<h3 data-number="13.7.4" class="anchored" data-anchor-id="incremental-learning"><span class="header-section-number">13.7.4</span> Incremental learning</h3>
<p>Continuous learning from new data is important for keeping models up-to-date:</p>
<div id="def-incremental" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.25 (Incremental learning)</strong></span> Incremental learning approaches:</p>
<ol type="1">
<li><strong>Online learning</strong>: Updating the model with each new observation</li>
<li><strong>Mini-batch updates</strong>: Accumulating updates and applying in small batches</li>
<li><strong>Periodic retraining</strong>: Regularly retraining the model on updated data</li>
<li><strong>Transfer learning</strong>: Initializing new models with previous embeddings</li>
<li><strong>Continual learning</strong>: Techniques to avoid catastrophic forgetting</li>
<li><strong>Active learning</strong>: Selectively incorporating new data based on uncertainty</li>
</ol>
</div>
<div id="exm-incremental" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.25 (Incremental learning example)</strong></span> Implementing continuous learning for a production system:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ContinuousLearningKGEmbeddingSystem:</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, model, optimizer, data_store, update_frequency<span class="op">=</span><span class="dv">1000</span>, batch_size<span class="op">=</span><span class="dv">64</span>):</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.optimizer <span class="op">=</span> optimizer</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.data_store <span class="op">=</span> data_store</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.update_frequency <span class="op">=</span> update_frequency</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.batch_size <span class="op">=</span> batch_size</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Tracking new data</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.new_triples <span class="op">=</span> []</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.last_update_time <span class="op">=</span> time.time()</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Lock for thread safety</span></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.update_lock <span class="op">=</span> threading.Lock()</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> add_new_triple(<span class="va">self</span>, head, relation, tail, confidence<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Add a new triple to the learning queue."""</span></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Convert names to IDs</span></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>            head_id <span class="op">=</span> <span class="va">self</span>.data_store.get_entity_id(head, create_if_missing<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>            relation_id <span class="op">=</span> <span class="va">self</span>.data_store.get_relation_id(relation, create_if_missing<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>            tail_id <span class="op">=</span> <span class="va">self</span>.data_store.get_entity_id(tail, create_if_missing<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> <span class="va">self</span>.update_lock:</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.new_triples.append((head_id, relation_id, tail_id, confidence))</span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Check if it's time to update</span></span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(<span class="va">self</span>.new_triples) <span class="op">&gt;=</span> <span class="va">self</span>.update_frequency:</span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.update_model()</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> {<span class="st">"status"</span>: <span class="st">"success"</span>, <span class="st">"message"</span>: <span class="st">"Triple added to learning queue"</span>}</span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> {<span class="st">"status"</span>: <span class="st">"error"</span>, <span class="st">"message"</span>: <span class="bu">str</span>(e)}</span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> update_model(<span class="va">self</span>):</span>
<span id="cb22-37"><a href="#cb22-37" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Update the model with new triples."""</span></span>
<span id="cb22-38"><a href="#cb22-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> <span class="va">self</span>.update_lock:</span>
<span id="cb22-39"><a href="#cb22-39" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="kw">not</span> <span class="va">self</span>.new_triples:</span>
<span id="cb22-40"><a href="#cb22-40" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span></span>
<span id="cb22-41"><a href="#cb22-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-42"><a href="#cb22-42" aria-hidden="true" tabindex="-1"></a>            logging.info(<span class="ss">f"Updating model with </span><span class="sc">{</span><span class="bu">len</span>(<span class="va">self</span>.new_triples)<span class="sc">}</span><span class="ss"> new triples"</span>)</span>
<span id="cb22-43"><a href="#cb22-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-44"><a href="#cb22-44" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Prepare for training</span></span>
<span id="cb22-45"><a href="#cb22-45" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.model.train()</span>
<span id="cb22-46"><a href="#cb22-46" aria-hidden="true" tabindex="-1"></a>            new_triples <span class="op">=</span> <span class="va">self</span>.new_triples.copy()</span>
<span id="cb22-47"><a href="#cb22-47" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.new_triples <span class="op">=</span> []</span>
<span id="cb22-48"><a href="#cb22-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-49"><a href="#cb22-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Perform update in batches</span></span>
<span id="cb22-50"><a href="#cb22-50" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch_start <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(new_triples), <span class="va">self</span>.batch_size):</span>
<span id="cb22-51"><a href="#cb22-51" aria-hidden="true" tabindex="-1"></a>            batch_end <span class="op">=</span> <span class="bu">min</span>(batch_start <span class="op">+</span> <span class="va">self</span>.batch_size, <span class="bu">len</span>(new_triples))</span>
<span id="cb22-52"><a href="#cb22-52" aria-hidden="true" tabindex="-1"></a>            batch <span class="op">=</span> new_triples[batch_start:batch_end]</span>
<span id="cb22-53"><a href="#cb22-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-54"><a href="#cb22-54" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Prepare batch</span></span>
<span id="cb22-55"><a href="#cb22-55" aria-hidden="true" tabindex="-1"></a>            heads <span class="op">=</span> torch.tensor([t[<span class="dv">0</span>] <span class="cf">for</span> t <span class="kw">in</span> batch], device<span class="op">=</span><span class="va">self</span>.model.device)</span>
<span id="cb22-56"><a href="#cb22-56" aria-hidden="true" tabindex="-1"></a>            relations <span class="op">=</span> torch.tensor([t[<span class="dv">1</span>] <span class="cf">for</span> t <span class="kw">in</span> batch], device<span class="op">=</span><span class="va">self</span>.model.device)</span>
<span id="cb22-57"><a href="#cb22-57" aria-hidden="true" tabindex="-1"></a>            tails <span class="op">=</span> torch.tensor([t[<span class="dv">2</span>] <span class="cf">for</span> t <span class="kw">in</span> batch], device<span class="op">=</span><span class="va">self</span>.model.device)</span>
<span id="cb22-58"><a href="#cb22-58" aria-hidden="true" tabindex="-1"></a>            confidences <span class="op">=</span> torch.tensor([t[<span class="dv">3</span>] <span class="cf">for</span> t <span class="kw">in</span> batch], device<span class="op">=</span><span class="va">self</span>.model.device)</span>
<span id="cb22-59"><a href="#cb22-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-60"><a href="#cb22-60" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Generate negative samples</span></span>
<span id="cb22-61"><a href="#cb22-61" aria-hidden="true" tabindex="-1"></a>            neg_heads, neg_tails <span class="op">=</span> <span class="va">self</span>._generate_negative_samples(heads, relations, tails)</span>
<span id="cb22-62"><a href="#cb22-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-63"><a href="#cb22-63" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Compute positive and negative scores</span></span>
<span id="cb22-64"><a href="#cb22-64" aria-hidden="true" tabindex="-1"></a>            pos_scores <span class="op">=</span> <span class="va">self</span>.model(heads, relations, tails)</span>
<span id="cb22-65"><a href="#cb22-65" aria-hidden="true" tabindex="-1"></a>            neg_scores <span class="op">=</span> <span class="va">self</span>.model(neg_heads, relations, neg_tails)</span>
<span id="cb22-66"><a href="#cb22-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-67"><a href="#cb22-67" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Compute loss with confidence weighting</span></span>
<span id="cb22-68"><a href="#cb22-68" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> <span class="va">self</span>._compute_loss(pos_scores, neg_scores, confidences)</span>
<span id="cb22-69"><a href="#cb22-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-70"><a href="#cb22-70" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Update model</span></span>
<span id="cb22-71"><a href="#cb22-71" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.optimizer.zero_grad()</span>
<span id="cb22-72"><a href="#cb22-72" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb22-73"><a href="#cb22-73" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.optimizer.step()</span>
<span id="cb22-74"><a href="#cb22-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-75"><a href="#cb22-75" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Normalize embeddings if needed</span></span>
<span id="cb22-76"><a href="#cb22-76" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>._normalize_embeddings()</span>
<span id="cb22-77"><a href="#cb22-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-78"><a href="#cb22-78" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update data store with new embeddings</span></span>
<span id="cb22-79"><a href="#cb22-79" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.data_store.update_embeddings(<span class="va">self</span>.model.entity_embedding.weight.detach().cpu(),</span>
<span id="cb22-80"><a href="#cb22-80" aria-hidden="true" tabindex="-1"></a>                                         <span class="va">self</span>.model.relation_embedding.weight.detach().cpu())</span>
<span id="cb22-81"><a href="#cb22-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-82"><a href="#cb22-82" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Set model back to evaluation mode</span></span>
<span id="cb22-83"><a href="#cb22-83" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model.<span class="bu">eval</span>()</span>
<span id="cb22-84"><a href="#cb22-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-85"><a href="#cb22-85" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Record update time</span></span>
<span id="cb22-86"><a href="#cb22-86" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.last_update_time <span class="op">=</span> time.time()</span>
<span id="cb22-87"><a href="#cb22-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-88"><a href="#cb22-88" aria-hidden="true" tabindex="-1"></a>        logging.info(<span class="st">"Model update complete"</span>)</span>
<span id="cb22-89"><a href="#cb22-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-90"><a href="#cb22-90" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _generate_negative_samples(<span class="va">self</span>, heads, relations, tails):</span>
<span id="cb22-91"><a href="#cb22-91" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Generate negative samples for training."""</span></span>
<span id="cb22-92"><a href="#cb22-92" aria-hidden="true" tabindex="-1"></a>        batch_size <span class="op">=</span> heads.size(<span class="dv">0</span>)</span>
<span id="cb22-93"><a href="#cb22-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-94"><a href="#cb22-94" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Corrupt either head or tail</span></span>
<span id="cb22-95"><a href="#cb22-95" aria-hidden="true" tabindex="-1"></a>        corrupt_head <span class="op">=</span> torch.rand(batch_size) <span class="op">&lt;</span> <span class="fl">0.5</span></span>
<span id="cb22-96"><a href="#cb22-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-97"><a href="#cb22-97" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create negative samples</span></span>
<span id="cb22-98"><a href="#cb22-98" aria-hidden="true" tabindex="-1"></a>        neg_heads <span class="op">=</span> heads.clone()</span>
<span id="cb22-99"><a href="#cb22-99" aria-hidden="true" tabindex="-1"></a>        neg_tails <span class="op">=</span> tails.clone()</span>
<span id="cb22-100"><a href="#cb22-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-101"><a href="#cb22-101" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Corrupt heads</span></span>
<span id="cb22-102"><a href="#cb22-102" aria-hidden="true" tabindex="-1"></a>        head_corruptions <span class="op">=</span> torch.randint(<span class="dv">0</span>, <span class="va">self</span>.data_store.num_entities, (batch_size,), device<span class="op">=</span>heads.device)</span>
<span id="cb22-103"><a href="#cb22-103" aria-hidden="true" tabindex="-1"></a>        neg_heads[corrupt_head] <span class="op">=</span> head_corruptions[corrupt_head]</span>
<span id="cb22-104"><a href="#cb22-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-105"><a href="#cb22-105" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Corrupt tails</span></span>
<span id="cb22-106"><a href="#cb22-106" aria-hidden="true" tabindex="-1"></a>        tail_corruptions <span class="op">=</span> torch.randint(<span class="dv">0</span>, <span class="va">self</span>.data_store.num_entities, (batch_size,), device<span class="op">=</span>tails.device)</span>
<span id="cb22-107"><a href="#cb22-107" aria-hidden="true" tabindex="-1"></a>        neg_tails[<span class="op">~</span>corrupt_head] <span class="op">=</span> tail_corruptions[<span class="op">~</span>corrupt_head]</span>
<span id="cb22-108"><a href="#cb22-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-109"><a href="#cb22-109" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> neg_heads, neg_tails</span>
<span id="cb22-110"><a href="#cb22-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-111"><a href="#cb22-111" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _compute_loss(<span class="va">self</span>, pos_scores, neg_scores, confidences):</span>
<span id="cb22-112"><a href="#cb22-112" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Compute margin loss with confidence weighting."""</span></span>
<span id="cb22-113"><a href="#cb22-113" aria-hidden="true" tabindex="-1"></a>        margin <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb22-114"><a href="#cb22-114" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> torch.mean(confidences <span class="op">*</span> torch.relu(margin <span class="op">-</span> pos_scores <span class="op">+</span> neg_scores))</span>
<span id="cb22-115"><a href="#cb22-115" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> loss</span>
<span id="cb22-116"><a href="#cb22-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-117"><a href="#cb22-117" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _normalize_embeddings(<span class="va">self</span>):</span>
<span id="cb22-118"><a href="#cb22-118" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Normalize entity embeddings to unit L2 norm."""</span></span>
<span id="cb22-119"><a href="#cb22-119" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb22-120"><a href="#cb22-120" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.model.entity_embedding.weight.div_(</span>
<span id="cb22-121"><a href="#cb22-121" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.model.entity_embedding.weight.norm(p<span class="op">=</span><span class="dv">2</span>, dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>).clamp_min(<span class="fl">1e-8</span>)</span>
<span id="cb22-122"><a href="#cb22-122" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb22-123"><a href="#cb22-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-124"><a href="#cb22-124" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> schedule_periodic_update(<span class="va">self</span>, interval_seconds<span class="op">=</span><span class="dv">3600</span>):</span>
<span id="cb22-125"><a href="#cb22-125" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Schedule periodic model updates."""</span></span>
<span id="cb22-126"><a href="#cb22-126" aria-hidden="true" tabindex="-1"></a>        <span class="kw">def</span> update_task():</span>
<span id="cb22-127"><a href="#cb22-127" aria-hidden="true" tabindex="-1"></a>            <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb22-128"><a href="#cb22-128" aria-hidden="true" tabindex="-1"></a>                time.sleep(interval_seconds)</span>
<span id="cb22-129"><a href="#cb22-129" aria-hidden="true" tabindex="-1"></a>                current_time <span class="op">=</span> time.time()</span>
<span id="cb22-130"><a href="#cb22-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-131"><a href="#cb22-131" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Check if we have new data and it's been a while since last update</span></span>
<span id="cb22-132"><a href="#cb22-132" aria-hidden="true" tabindex="-1"></a>                <span class="cf">with</span> <span class="va">self</span>.update_lock:</span>
<span id="cb22-133"><a href="#cb22-133" aria-hidden="true" tabindex="-1"></a>                    has_new_data <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.new_triples) <span class="op">&gt;</span> <span class="dv">0</span></span>
<span id="cb22-134"><a href="#cb22-134" aria-hidden="true" tabindex="-1"></a>                    time_since_update <span class="op">=</span> current_time <span class="op">-</span> <span class="va">self</span>.last_update_time</span>
<span id="cb22-135"><a href="#cb22-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-136"><a href="#cb22-136" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> has_new_data <span class="kw">and</span> time_since_update <span class="op">&gt;=</span> interval_seconds:</span>
<span id="cb22-137"><a href="#cb22-137" aria-hidden="true" tabindex="-1"></a>                    logging.info(<span class="ss">f"Performing scheduled update after </span><span class="sc">{</span>time_since_update<span class="sc">:.1f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb22-138"><a href="#cb22-138" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.update_model()</span>
<span id="cb22-139"><a href="#cb22-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-140"><a href="#cb22-140" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Start update thread</span></span>
<span id="cb22-141"><a href="#cb22-141" aria-hidden="true" tabindex="-1"></a>        update_thread <span class="op">=</span> threading.Thread(target<span class="op">=</span>update_task, daemon<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb22-142"><a href="#cb22-142" aria-hidden="true" tabindex="-1"></a>        update_thread.start()</span>
<span id="cb22-143"><a href="#cb22-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-144"><a href="#cb22-144" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> update_thread</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This implementation enables continuous learning by accumulating new triples and periodically updating the model with batches of new data, maintaining entity and relation embeddings over time.</p>
</div>
</section>
</section>
<section id="integration-with-other-systems" class="level2" data-number="13.8">
<h2 data-number="13.8" class="anchored" data-anchor-id="integration-with-other-systems"><span class="header-section-number">13.8</span> Integration with other systems</h2>
<p>Knowledge graph embedding systems often need to integrate with other components:</p>
<section id="integration-with-recommendation-systems" class="level3" data-number="13.8.1">
<h3 data-number="13.8.1" class="anchored" data-anchor-id="integration-with-recommendation-systems"><span class="header-section-number">13.8.1</span> Integration with recommendation systems</h3>
<div id="def-recommendation-integration" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.26 (Recommendation system integration)</strong></span> Integration approaches for recommendation systems:</p>
<ol type="1">
<li><strong>Entity-based recommendations</strong>: Using entity embeddings for similarity-based recommendations</li>
<li><strong>Path-based recommendations</strong>: Using multi-hop paths for explainable recommendations</li>
<li><strong>Hybrid recommendation</strong>: Combining knowledge graph embeddings with collaborative filtering</li>
<li><strong>Cold-start handling</strong>: Using knowledge graph information for new users or items</li>
<li><strong>Context-aware recommendations</strong>: Incorporating context through knowledge graph relations</li>
</ol>
</div>
<div id="exm-recommender" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.26 (Recommendation system integration example)</strong></span> Implementing a knowledge graph-enhanced recommender:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> KGEnhancedRecommender:</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, kg_model, collaborative_model, kg_weight<span class="op">=</span><span class="fl">0.5</span>):</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.kg_model <span class="op">=</span> kg_model</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.collaborative_model <span class="op">=</span> collaborative_model</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.kg_weight <span class="op">=</span> kg_weight</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Mapping between recommendation and KG entities</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.user_to_entity <span class="op">=</span> {}</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.item_to_entity <span class="op">=</span> {}</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.entity_to_item <span class="op">=</span> {}</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> map_user_to_entity(<span class="va">self</span>, user_id, entity_id):</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Map a recommendation user to a KG entity."""</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.user_to_entity[user_id] <span class="op">=</span> entity_id</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> map_item_to_entity(<span class="va">self</span>, item_id, entity_id):</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Map a recommendation item to a KG entity."""</span></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.item_to_entity[item_id] <span class="op">=</span> entity_id</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.entity_to_item[entity_id] <span class="op">=</span> item_id</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_recommendations(<span class="va">self</span>, user_id, n<span class="op">=</span><span class="dv">10</span>, include_kg_explanations<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Get recommendations for a user."""</span></span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Get collaborative filtering recommendations</span></span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>            cf_recommendations <span class="op">=</span> <span class="va">self</span>.collaborative_model.recommend(user_id, n<span class="op">=</span>n)</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a>            <span class="co"># If user not in KG, return CF recommendations only</span></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> user_id <span class="kw">not</span> <span class="kw">in</span> <span class="va">self</span>.user_to_entity:</span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> {<span class="st">"recommendations"</span>: cf_recommendations, <span class="st">"source"</span>: <span class="st">"collaborative_only"</span>}</span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Get KG-based recommendations</span></span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a>            user_entity_id <span class="op">=</span> <span class="va">self</span>.user_to_entity[user_id]</span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Relation that connects users to items they might like</span></span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a>            relation_id <span class="op">=</span> <span class="va">self</span>.kg_model.relation_to_id[<span class="st">"might_like"</span>]</span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Predict potential items</span></span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> torch.no_grad():</span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a>                heads <span class="op">=</span> torch.tensor([user_entity_id], device<span class="op">=</span><span class="va">self</span>.kg_model.device)</span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a>                relations <span class="op">=</span> torch.tensor([relation_id], device<span class="op">=</span><span class="va">self</span>.kg_model.device)</span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Score all entities as potential tails</span></span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a>                all_tails <span class="op">=</span> torch.arange(<span class="va">self</span>.kg_model.num_entities, device<span class="op">=</span><span class="va">self</span>.kg_model.device)</span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a>                scores <span class="op">=</span> <span class="va">self</span>.kg_model(heads.expand_as(all_tails),</span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a>                                     relations.expand_as(all_tails),</span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a>                                     all_tails)</span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Get top entities</span></span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a>                top_scores, top_indices <span class="op">=</span> torch.topk(scores, k<span class="op">=</span>n<span class="op">*</span><span class="dv">2</span>)  <span class="co"># Get more, as some might not be items</span></span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Convert to item IDs</span></span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a>                kg_recommendations <span class="op">=</span> []</span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> entity_id, score <span class="kw">in</span> <span class="bu">zip</span>(top_indices.cpu().numpy(), top_scores.cpu().numpy()):</span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a>                    entity_id <span class="op">=</span> entity_id.item()</span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> entity_id <span class="kw">in</span> <span class="va">self</span>.entity_to_item:</span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a>                        item_id <span class="op">=</span> <span class="va">self</span>.entity_to_item[entity_id]</span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a>                        kg_recommendations.append({<span class="st">"item_id"</span>: item_id, <span class="st">"score"</span>: <span class="bu">float</span>(score)})</span>
<span id="cb23-58"><a href="#cb23-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-59"><a href="#cb23-59" aria-hidden="true" tabindex="-1"></a>                        <span class="co"># Add explanation paths if requested</span></span>
<span id="cb23-60"><a href="#cb23-60" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">if</span> include_kg_explanations:</span>
<span id="cb23-61"><a href="#cb23-61" aria-hidden="true" tabindex="-1"></a>                            explanation_paths <span class="op">=</span> <span class="va">self</span>._find_explanation_paths(user_entity_id, entity_id)</span>
<span id="cb23-62"><a href="#cb23-62" aria-hidden="true" tabindex="-1"></a>                            kg_recommendations[<span class="op">-</span><span class="dv">1</span>][<span class="st">"explanations"</span>] <span class="op">=</span> explanation_paths</span>
<span id="cb23-63"><a href="#cb23-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-64"><a href="#cb23-64" aria-hidden="true" tabindex="-1"></a>                kg_recommendations <span class="op">=</span> kg_recommendations[:n]</span>
<span id="cb23-65"><a href="#cb23-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-66"><a href="#cb23-66" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Combine recommendations</span></span>
<span id="cb23-67"><a href="#cb23-67" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="va">self</span>.kg_weight <span class="op">==</span> <span class="fl">1.0</span>:</span>
<span id="cb23-68"><a href="#cb23-68" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> {<span class="st">"recommendations"</span>: kg_recommendations, <span class="st">"source"</span>: <span class="st">"kg_only"</span>}</span>
<span id="cb23-69"><a href="#cb23-69" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> <span class="va">self</span>.kg_weight <span class="op">==</span> <span class="fl">0.0</span>:</span>
<span id="cb23-70"><a href="#cb23-70" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> {<span class="st">"recommendations"</span>: cf_recommendations, <span class="st">"source"</span>: <span class="st">"collaborative_only"</span>}</span>
<span id="cb23-71"><a href="#cb23-71" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb23-72"><a href="#cb23-72" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Hybrid recommendations with weighted scores</span></span>
<span id="cb23-73"><a href="#cb23-73" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> <span class="va">self</span>._combine_recommendations(cf_recommendations, kg_recommendations)</span>
<span id="cb23-74"><a href="#cb23-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-75"><a href="#cb23-75" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb23-76"><a href="#cb23-76" aria-hidden="true" tabindex="-1"></a>            logging.error(<span class="ss">f"Error generating recommendations: </span><span class="sc">{</span><span class="bu">str</span>(e)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-77"><a href="#cb23-77" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> {<span class="st">"error"</span>: <span class="bu">str</span>(e)}</span>
<span id="cb23-78"><a href="#cb23-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-79"><a href="#cb23-79" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _find_explanation_paths(<span class="va">self</span>, user_entity_id, item_entity_id, max_paths<span class="op">=</span><span class="dv">3</span>, max_length<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb23-80"><a href="#cb23-80" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Find explanation paths between user and item in the knowledge graph."""</span></span>
<span id="cb23-81"><a href="#cb23-81" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Implementation using breadth-first search or pre-computed paths</span></span>
<span id="cb23-82"><a href="#cb23-82" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ...</span></span>
<span id="cb23-83"><a href="#cb23-83" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> [<span class="st">"example_path_1"</span>, <span class="st">"example_path_2"</span>]</span>
<span id="cb23-84"><a href="#cb23-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-85"><a href="#cb23-85" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _combine_recommendations(<span class="va">self</span>, cf_recommendations, kg_recommendations):</span>
<span id="cb23-86"><a href="#cb23-86" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Combine collaborative filtering and KG recommendations."""</span></span>
<span id="cb23-87"><a href="#cb23-87" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create a unified scoring</span></span>
<span id="cb23-88"><a href="#cb23-88" aria-hidden="true" tabindex="-1"></a>        item_scores <span class="op">=</span> {}</span>
<span id="cb23-89"><a href="#cb23-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-90"><a href="#cb23-90" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add CF scores</span></span>
<span id="cb23-91"><a href="#cb23-91" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> rec <span class="kw">in</span> cf_recommendations:</span>
<span id="cb23-92"><a href="#cb23-92" aria-hidden="true" tabindex="-1"></a>            item_scores[rec[<span class="st">"item_id"</span>]] <span class="op">=</span> {<span class="st">"cf_score"</span>: rec[<span class="st">"score"</span>], <span class="st">"kg_score"</span>: <span class="fl">0.0</span>}</span>
<span id="cb23-93"><a href="#cb23-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-94"><a href="#cb23-94" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add KG scores</span></span>
<span id="cb23-95"><a href="#cb23-95" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> rec <span class="kw">in</span> kg_recommendations:</span>
<span id="cb23-96"><a href="#cb23-96" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> rec[<span class="st">"item_id"</span>] <span class="kw">in</span> item_scores:</span>
<span id="cb23-97"><a href="#cb23-97" aria-hidden="true" tabindex="-1"></a>                item_scores[rec[<span class="st">"item_id"</span>]][<span class="st">"kg_score"</span>] <span class="op">=</span> rec[<span class="st">"score"</span>]</span>
<span id="cb23-98"><a href="#cb23-98" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb23-99"><a href="#cb23-99" aria-hidden="true" tabindex="-1"></a>                item_scores[rec[<span class="st">"item_id"</span>]] <span class="op">=</span> {<span class="st">"cf_score"</span>: <span class="fl">0.0</span>, <span class="st">"kg_score"</span>: rec[<span class="st">"score"</span>]}</span>
<span id="cb23-100"><a href="#cb23-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-101"><a href="#cb23-101" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute combined scores</span></span>
<span id="cb23-102"><a href="#cb23-102" aria-hidden="true" tabindex="-1"></a>        combined_recommendations <span class="op">=</span> []</span>
<span id="cb23-103"><a href="#cb23-103" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> item_id, scores <span class="kw">in</span> item_scores.items():</span>
<span id="cb23-104"><a href="#cb23-104" aria-hidden="true" tabindex="-1"></a>            combined_score <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> <span class="va">self</span>.kg_weight) <span class="op">*</span> scores[<span class="st">"cf_score"</span>] <span class="op">+</span> <span class="va">self</span>.kg_weight <span class="op">*</span> scores[<span class="st">"kg_score"</span>]</span>
<span id="cb23-105"><a href="#cb23-105" aria-hidden="true" tabindex="-1"></a>            recommendation <span class="op">=</span> {<span class="st">"item_id"</span>: item_id, <span class="st">"score"</span>: combined_score,</span>
<span id="cb23-106"><a href="#cb23-106" aria-hidden="true" tabindex="-1"></a>                             <span class="st">"cf_score"</span>: scores[<span class="st">"cf_score"</span>], <span class="st">"kg_score"</span>: scores[<span class="st">"kg_score"</span>]}</span>
<span id="cb23-107"><a href="#cb23-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-108"><a href="#cb23-108" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Add explanations if available</span></span>
<span id="cb23-109"><a href="#cb23-109" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> rec <span class="kw">in</span> kg_recommendations:</span>
<span id="cb23-110"><a href="#cb23-110" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> rec[<span class="st">"item_id"</span>] <span class="op">==</span> item_id <span class="kw">and</span> <span class="st">"explanations"</span> <span class="kw">in</span> rec:</span>
<span id="cb23-111"><a href="#cb23-111" aria-hidden="true" tabindex="-1"></a>                    recommendation[<span class="st">"explanations"</span>] <span class="op">=</span> rec[<span class="st">"explanations"</span>]</span>
<span id="cb23-112"><a href="#cb23-112" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">break</span></span>
<span id="cb23-113"><a href="#cb23-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-114"><a href="#cb23-114" aria-hidden="true" tabindex="-1"></a>            combined_recommendations.append(recommendation)</span>
<span id="cb23-115"><a href="#cb23-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-116"><a href="#cb23-116" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Sort by combined score</span></span>
<span id="cb23-117"><a href="#cb23-117" aria-hidden="true" tabindex="-1"></a>        combined_recommendations.sort(key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="st">"score"</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb23-118"><a href="#cb23-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-119"><a href="#cb23-119" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {<span class="st">"recommendations"</span>: combined_recommendations[:<span class="dv">10</span>], <span class="st">"source"</span>: <span class="st">"hybrid"</span>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This implementation integrates a knowledge graph embedding model with a collaborative filtering recommender system, providing hybrid recommendations with explanations derived from knowledge graph paths.</p>
</div>
</section>
<section id="integration-with-search-systems" class="level3" data-number="13.8.2">
<h3 data-number="13.8.2" class="anchored" data-anchor-id="integration-with-search-systems"><span class="header-section-number">13.8.2</span> Integration with search systems</h3>
<div id="def-search-integration" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.27 (Search system integration)</strong></span> Integration approaches for search systems:</p>
<ol type="1">
<li><strong>Entity expansion</strong>: Expanding queries with related entities</li>
<li><strong>Semantic search</strong>: Using embeddings for semantic matching</li>
<li><strong>Query understanding</strong>: Mapping queries to knowledge graph entities and relations</li>
<li><strong>Ranking enhancement</strong>: Using knowledge graph features for result ranking</li>
<li><strong>Question answering</strong>: Supporting complex queries through knowledge graph traversal</li>
</ol>
</div>
<div id="exm-search" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.27 (Search integration example)</strong></span> Implementing entity-based search enhancement:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> KGEnhancedSearch:</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, kg_model, search_engine, entity_recognizer):</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.kg_model <span class="op">=</span> kg_model</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.search_engine <span class="op">=</span> search_engine</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.entity_recognizer <span class="op">=</span> entity_recognizer</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> search(<span class="va">self</span>, query, max_results<span class="op">=</span><span class="dv">10</span>, enhance_with_kg<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Perform enhanced search using knowledge graph."""</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract entities from query</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>        entities <span class="op">=</span> <span class="va">self</span>.entity_recognizer.extract_entities(query)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> enhance_with_kg <span class="kw">or</span> <span class="kw">not</span> entities:</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Fallback to regular search if no entities or enhancement disabled</span></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.search_engine.search(query, max_results)</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get KG entity IDs for recognized entities</span></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>        kg_entities <span class="op">=</span> []</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> entity <span class="kw">in</span> entities:</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>            entity_id <span class="op">=</span> <span class="va">self</span>.kg_model.entity_to_id.get(entity)</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> entity_id <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>                kg_entities.append((entity, entity_id))</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> kg_entities:</span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>            <span class="co"># No recognized entities in KG, fallback to regular search</span></span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.search_engine.search(query, max_results)</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Find related entities in KG</span></span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a>        related_entities <span class="op">=</span> <span class="va">self</span>._find_related_entities(kg_entities)</span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Expand query with related entities</span></span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>        expanded_query <span class="op">=</span> <span class="va">self</span>._expand_query(query, related_entities)</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Perform search with expanded query</span></span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>        search_results <span class="op">=</span> <span class="va">self</span>.search_engine.search(expanded_query, max_results)</span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Re-rank results using KG information</span></span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>        reranked_results <span class="op">=</span> <span class="va">self</span>._rerank_results(search_results, kg_entities, related_entities)</span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a>            <span class="st">"original_query"</span>: query,</span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a>            <span class="st">"expanded_query"</span>: expanded_query,</span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a>            <span class="st">"results"</span>: reranked_results,</span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a>            <span class="st">"kg_entities"</span>: [e[<span class="dv">0</span>] <span class="cf">for</span> e <span class="kw">in</span> kg_entities],</span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a>            <span class="st">"related_entities"</span>: [e[<span class="st">"entity"</span>] <span class="cf">for</span> e <span class="kw">in</span> related_entities]</span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb24-46"><a href="#cb24-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-47"><a href="#cb24-47" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _find_related_entities(<span class="va">self</span>, kg_entities, max_per_entity<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb24-48"><a href="#cb24-48" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Find related entities in the knowledge graph."""</span></span>
<span id="cb24-49"><a href="#cb24-49" aria-hidden="true" tabindex="-1"></a>        related_entities <span class="op">=</span> []</span>
<span id="cb24-50"><a href="#cb24-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-51"><a href="#cb24-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> entity_name, entity_id <span class="kw">in</span> kg_entities:</span>
<span id="cb24-52"><a href="#cb24-52" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Get entity embedding</span></span>
<span id="cb24-53"><a href="#cb24-53" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> torch.no_grad():</span>
<span id="cb24-54"><a href="#cb24-54" aria-hidden="true" tabindex="-1"></a>                entity_emb <span class="op">=</span> <span class="va">self</span>.kg_model.entity_embedding(</span>
<span id="cb24-55"><a href="#cb24-55" aria-hidden="true" tabindex="-1"></a>                    torch.tensor([entity_id], device<span class="op">=</span><span class="va">self</span>.kg_model.device)</span>
<span id="cb24-56"><a href="#cb24-56" aria-hidden="true" tabindex="-1"></a>                )[<span class="dv">0</span>]</span>
<span id="cb24-57"><a href="#cb24-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-58"><a href="#cb24-58" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Compute similarity with all other entities</span></span>
<span id="cb24-59"><a href="#cb24-59" aria-hidden="true" tabindex="-1"></a>            all_emb <span class="op">=</span> <span class="va">self</span>.kg_model.entity_embedding.weight</span>
<span id="cb24-60"><a href="#cb24-60" aria-hidden="true" tabindex="-1"></a>            similarities <span class="op">=</span> torch.nn.functional.cosine_similarity(</span>
<span id="cb24-61"><a href="#cb24-61" aria-hidden="true" tabindex="-1"></a>                entity_emb.unsqueeze(<span class="dv">0</span>), all_emb</span>
<span id="cb24-62"><a href="#cb24-62" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb24-63"><a href="#cb24-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-64"><a href="#cb24-64" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Get top similar entities</span></span>
<span id="cb24-65"><a href="#cb24-65" aria-hidden="true" tabindex="-1"></a>            top_k <span class="op">=</span> <span class="bu">min</span>(max_per_entity, <span class="bu">len</span>(similarities) <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb24-66"><a href="#cb24-66" aria-hidden="true" tabindex="-1"></a>            top_scores, top_indices <span class="op">=</span> torch.topk(similarities, k<span class="op">=</span>top_k <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb24-67"><a href="#cb24-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-68"><a href="#cb24-68" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Skip the entity itself (should be the most similar)</span></span>
<span id="cb24-69"><a href="#cb24-69" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(top_indices)):</span>
<span id="cb24-70"><a href="#cb24-70" aria-hidden="true" tabindex="-1"></a>                idx <span class="op">=</span> top_indices[i].item()</span>
<span id="cb24-71"><a href="#cb24-71" aria-hidden="true" tabindex="-1"></a>                score <span class="op">=</span> top_scores[i].item()</span>
<span id="cb24-72"><a href="#cb24-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-73"><a href="#cb24-73" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Convert ID to entity name</span></span>
<span id="cb24-74"><a href="#cb24-74" aria-hidden="true" tabindex="-1"></a>                related_name <span class="op">=</span> <span class="va">self</span>.kg_model.id_to_entity[idx]</span>
<span id="cb24-75"><a href="#cb24-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-76"><a href="#cb24-76" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Add to list of related entities</span></span>
<span id="cb24-77"><a href="#cb24-77" aria-hidden="true" tabindex="-1"></a>                related_entities.append({</span>
<span id="cb24-78"><a href="#cb24-78" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"entity"</span>: related_name,</span>
<span id="cb24-79"><a href="#cb24-79" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"score"</span>: score,</span>
<span id="cb24-80"><a href="#cb24-80" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"source_entity"</span>: entity_name</span>
<span id="cb24-81"><a href="#cb24-81" aria-hidden="true" tabindex="-1"></a>                })</span>
<span id="cb24-82"><a href="#cb24-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-83"><a href="#cb24-83" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> related_entities</span>
<span id="cb24-84"><a href="#cb24-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-85"><a href="#cb24-85" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _expand_query(<span class="va">self</span>, original_query, related_entities, max_expansions<span class="op">=</span><span class="dv">3</span>):</span>
<span id="cb24-86"><a href="#cb24-86" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Expand search query with related entities."""</span></span>
<span id="cb24-87"><a href="#cb24-87" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Select top related entities for expansion</span></span>
<span id="cb24-88"><a href="#cb24-88" aria-hidden="true" tabindex="-1"></a>        expansion_entities <span class="op">=</span> <span class="bu">sorted</span>(related_entities, key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="st">"score"</span>], reverse<span class="op">=</span><span class="va">True</span>)[:max_expansions]</span>
<span id="cb24-89"><a href="#cb24-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-90"><a href="#cb24-90" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create expanded query</span></span>
<span id="cb24-91"><a href="#cb24-91" aria-hidden="true" tabindex="-1"></a>        expanded_query <span class="op">=</span> original_query <span class="op">+</span> <span class="st">" "</span> <span class="op">+</span> <span class="st">" "</span>.join([e[<span class="st">"entity"</span>] <span class="cf">for</span> e <span class="kw">in</span> expansion_entities])</span>
<span id="cb24-92"><a href="#cb24-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-93"><a href="#cb24-93" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> expanded_query</span>
<span id="cb24-94"><a href="#cb24-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-95"><a href="#cb24-95" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _rerank_results(<span class="va">self</span>, search_results, query_entities, related_entities):</span>
<span id="cb24-96"><a href="#cb24-96" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Re-rank search results using KG information."""</span></span>
<span id="cb24-97"><a href="#cb24-97" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract entities from search results</span></span>
<span id="cb24-98"><a href="#cb24-98" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> result <span class="kw">in</span> search_results:</span>
<span id="cb24-99"><a href="#cb24-99" aria-hidden="true" tabindex="-1"></a>            result_entities <span class="op">=</span> <span class="va">self</span>.entity_recognizer.extract_entities(result[<span class="st">"title"</span>] <span class="op">+</span> <span class="st">" "</span> <span class="op">+</span> result[<span class="st">"snippet"</span>])</span>
<span id="cb24-100"><a href="#cb24-100" aria-hidden="true" tabindex="-1"></a>            result[<span class="st">"entities"</span>] <span class="op">=</span> result_entities</span>
<span id="cb24-101"><a href="#cb24-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-102"><a href="#cb24-102" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Calculate KG relevance score</span></span>
<span id="cb24-103"><a href="#cb24-103" aria-hidden="true" tabindex="-1"></a>            kg_score <span class="op">=</span> <span class="va">self</span>._calculate_kg_relevance(result_entities, query_entities, related_entities)</span>
<span id="cb24-104"><a href="#cb24-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-105"><a href="#cb24-105" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Combine with original score</span></span>
<span id="cb24-106"><a href="#cb24-106" aria-hidden="true" tabindex="-1"></a>            original_score <span class="op">=</span> result[<span class="st">"score"</span>]</span>
<span id="cb24-107"><a href="#cb24-107" aria-hidden="true" tabindex="-1"></a>            result[<span class="st">"combined_score"</span>] <span class="op">=</span> <span class="fl">0.7</span> <span class="op">*</span> original_score <span class="op">+</span> <span class="fl">0.3</span> <span class="op">*</span> kg_score</span>
<span id="cb24-108"><a href="#cb24-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-109"><a href="#cb24-109" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Re-rank based on combined score</span></span>
<span id="cb24-110"><a href="#cb24-110" aria-hidden="true" tabindex="-1"></a>        reranked_results <span class="op">=</span> <span class="bu">sorted</span>(search_results, key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="st">"combined_score"</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb24-111"><a href="#cb24-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-112"><a href="#cb24-112" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> reranked_results</span>
<span id="cb24-113"><a href="#cb24-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-114"><a href="#cb24-114" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _calculate_kg_relevance(<span class="va">self</span>, result_entities, query_entities, related_entities):</span>
<span id="cb24-115"><a href="#cb24-115" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Calculate relevance score based on KG relationships."""</span></span>
<span id="cb24-116"><a href="#cb24-116" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Implementation details</span></span>
<span id="cb24-117"><a href="#cb24-117" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ...</span></span>
<span id="cb24-118"><a href="#cb24-118" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="fl">0.5</span>  <span class="co"># Example score</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This example demonstrates how knowledge graph embeddings can enhance search by expanding queries with related entities and re-ranking results based on knowledge graph relationships.</p>
</div>
</section>
<section id="integration-with-natural-language-processing" class="level3" data-number="13.8.3">
<h3 data-number="13.8.3" class="anchored" data-anchor-id="integration-with-natural-language-processing"><span class="header-section-number">13.8.3</span> Integration with natural language processing</h3>
<div id="def-nlp-integration" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 13.28 (NLP integration)</strong></span> Integration approaches with NLP systems:</p>
<ol type="1">
<li><strong>Entity linking</strong>: Connecting text mentions to knowledge graph entities</li>
<li><strong>Relation extraction</strong>: Identifying relationships between entities in text</li>
<li><strong>Knowledge-enhanced language models</strong>: Incorporating knowledge graph information into language models</li>
<li><strong>Question answering</strong>: Answering natural language questions using knowledge graphs</li>
<li><strong>Text generation</strong>: Generating text grounded in knowledge graph facts</li>
</ol>
</div>
<div id="exm-nlp" class="theorem example">
<p><span class="theorem-title"><strong>Example 13.28 (NLP integration example)</strong></span> Implementing knowledge graph-enhanced question answering:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> KGQuestionAnsweringSystem:</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, kg_model, nlp_model, entity_linker, relation_extractor):</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.kg_model <span class="op">=</span> kg_model</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.nlp_model <span class="op">=</span> nlp_model</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.entity_linker <span class="op">=</span> entity_linker</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.relation_extractor <span class="op">=</span> relation_extractor</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> answer_question(<span class="va">self</span>, question):</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Answer a natural language question using KG."""</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Parse question to identify query type</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>        question_type <span class="op">=</span> <span class="va">self</span>._classify_question_type(question)</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract entities and relations from question</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>        entities <span class="op">=</span> <span class="va">self</span>.entity_linker.extract_entities(question)</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>        relations <span class="op">=</span> <span class="va">self</span>.relation_extractor.extract_relations(question)</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> entities:</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> {</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>                <span class="st">"answer"</span>: <span class="va">None</span>,</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>                <span class="st">"confidence"</span>: <span class="fl">0.0</span>,</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>                <span class="st">"error"</span>: <span class="st">"No entities found in question"</span></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Map to KG entities and relations</span></span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>        kg_entities <span class="op">=</span> [(e, <span class="va">self</span>.kg_model.entity_to_id.get(e)) <span class="cf">for</span> e <span class="kw">in</span> entities]</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a>        kg_entities <span class="op">=</span> [(e, eid) <span class="cf">for</span> e, eid <span class="kw">in</span> kg_entities <span class="cf">if</span> eid <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>]</span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>        kg_relations <span class="op">=</span> [(r, <span class="va">self</span>.kg_model.relation_to_id.get(r)) <span class="cf">for</span> r <span class="kw">in</span> relations]</span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a>        kg_relations <span class="op">=</span> [(r, rid) <span class="cf">for</span> r, rid <span class="kw">in</span> kg_relations <span class="cf">if</span> rid <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>]</span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> kg_entities:</span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> {</span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a>                <span class="st">"answer"</span>: <span class="va">None</span>,</span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a>                <span class="st">"confidence"</span>: <span class="fl">0.0</span>,</span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a>                <span class="st">"error"</span>: <span class="st">"No recognized entities in knowledge graph"</span></span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Generate answer based on question type</span></span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> question_type <span class="op">==</span> <span class="st">"factoid"</span>:</span>
<span id="cb25-40"><a href="#cb25-40" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>._answer_factoid_question(question, kg_entities, kg_relations)</span>
<span id="cb25-41"><a href="#cb25-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> question_type <span class="op">==</span> <span class="st">"list"</span>:</span>
<span id="cb25-42"><a href="#cb25-42" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>._answer_list_question(question, kg_entities, kg_relations)</span>
<span id="cb25-43"><a href="#cb25-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> question_type <span class="op">==</span> <span class="st">"complex"</span>:</span>
<span id="cb25-44"><a href="#cb25-44" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>._answer_complex_question(question, kg_entities, kg_relations)</span>
<span id="cb25-45"><a href="#cb25-45" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb25-46"><a href="#cb25-46" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Fall back to general NLP model</span></span>
<span id="cb25-47"><a href="#cb25-47" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> {</span>
<span id="cb25-48"><a href="#cb25-48" aria-hidden="true" tabindex="-1"></a>                <span class="st">"answer"</span>: <span class="va">self</span>.nlp_model.generate_answer(question),</span>
<span id="cb25-49"><a href="#cb25-49" aria-hidden="true" tabindex="-1"></a>                <span class="st">"confidence"</span>: <span class="fl">0.3</span>,</span>
<span id="cb25-50"><a href="#cb25-50" aria-hidden="true" tabindex="-1"></a>                <span class="st">"source"</span>: <span class="st">"language_model"</span></span>
<span id="cb25-51"><a href="#cb25-51" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb25-52"><a href="#cb25-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-53"><a href="#cb25-53" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _classify_question_type(<span class="va">self</span>, question):</span>
<span id="cb25-54"><a href="#cb25-54" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Classify the question as factoid, list, or complex."""</span></span>
<span id="cb25-55"><a href="#cb25-55" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Implementation using NLP techniques</span></span>
<span id="cb25-56"><a href="#cb25-56" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ...</span></span>
<span id="cb25-57"><a href="#cb25-57" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"factoid"</span></span>
<span id="cb25-58"><a href="#cb25-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-59"><a href="#cb25-59" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _answer_factoid_question(<span class="va">self</span>, question, kg_entities, kg_relations):</span>
<span id="cb25-60"><a href="#cb25-60" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Answer a factoid question using KG."""</span></span>
<span id="cb25-61"><a href="#cb25-61" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Simple case: one entity, one potential relation</span></span>
<span id="cb25-62"><a href="#cb25-62" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(kg_entities) <span class="op">==</span> <span class="dv">1</span> <span class="kw">and</span> <span class="bu">len</span>(kg_relations) <span class="op">&gt;=</span> <span class="dv">1</span>:</span>
<span id="cb25-63"><a href="#cb25-63" aria-hidden="true" tabindex="-1"></a>            entity_name, entity_id <span class="op">=</span> kg_entities[<span class="dv">0</span>]</span>
<span id="cb25-64"><a href="#cb25-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-65"><a href="#cb25-65" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Try each potential relation</span></span>
<span id="cb25-66"><a href="#cb25-66" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> relation_name, relation_id <span class="kw">in</span> kg_relations:</span>
<span id="cb25-67"><a href="#cb25-67" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Query KG for (entity, relation, ?)</span></span>
<span id="cb25-68"><a href="#cb25-68" aria-hidden="true" tabindex="-1"></a>                <span class="cf">with</span> torch.no_grad():</span>
<span id="cb25-69"><a href="#cb25-69" aria-hidden="true" tabindex="-1"></a>                    heads <span class="op">=</span> torch.tensor([entity_id], device<span class="op">=</span><span class="va">self</span>.kg_model.device)</span>
<span id="cb25-70"><a href="#cb25-70" aria-hidden="true" tabindex="-1"></a>                    relations <span class="op">=</span> torch.tensor([relation_id], device<span class="op">=</span><span class="va">self</span>.kg_model.device)</span>
<span id="cb25-71"><a href="#cb25-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-72"><a href="#cb25-72" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># Score all entities as potential tails</span></span>
<span id="cb25-73"><a href="#cb25-73" aria-hidden="true" tabindex="-1"></a>                    all_tails <span class="op">=</span> torch.arange(<span class="va">self</span>.kg_model.num_entities, device<span class="op">=</span><span class="va">self</span>.kg_model.device)</span>
<span id="cb25-74"><a href="#cb25-74" aria-hidden="true" tabindex="-1"></a>                    scores <span class="op">=</span> <span class="va">self</span>.kg_model(heads.expand_as(all_tails),</span>
<span id="cb25-75"><a href="#cb25-75" aria-hidden="true" tabindex="-1"></a>                                         relations.expand_as(all_tails),</span>
<span id="cb25-76"><a href="#cb25-76" aria-hidden="true" tabindex="-1"></a>                                         all_tails)</span>
<span id="cb25-77"><a href="#cb25-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-78"><a href="#cb25-78" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># Get top answers</span></span>
<span id="cb25-79"><a href="#cb25-79" aria-hidden="true" tabindex="-1"></a>                    top_scores, top_indices <span class="op">=</span> torch.topk(scores, k<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb25-80"><a href="#cb25-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-81"><a href="#cb25-81" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># Convert to entity names</span></span>
<span id="cb25-82"><a href="#cb25-82" aria-hidden="true" tabindex="-1"></a>                    answers <span class="op">=</span> []</span>
<span id="cb25-83"><a href="#cb25-83" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">for</span> idx, score <span class="kw">in</span> <span class="bu">zip</span>(top_indices.cpu().numpy(), top_scores.cpu().numpy()):</span>
<span id="cb25-84"><a href="#cb25-84" aria-hidden="true" tabindex="-1"></a>                        idx <span class="op">=</span> idx.item()</span>
<span id="cb25-85"><a href="#cb25-85" aria-hidden="true" tabindex="-1"></a>                        answer_name <span class="op">=</span> <span class="va">self</span>.kg_model.id_to_entity[idx]</span>
<span id="cb25-86"><a href="#cb25-86" aria-hidden="true" tabindex="-1"></a>                        answers.append({<span class="st">"entity"</span>: answer_name, <span class="st">"score"</span>: <span class="bu">float</span>(score)})</span>
<span id="cb25-87"><a href="#cb25-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-88"><a href="#cb25-88" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> answers <span class="kw">and</span> answers[<span class="dv">0</span>][<span class="st">"score"</span>] <span class="op">&gt;</span> <span class="fl">0.5</span>:</span>
<span id="cb25-89"><a href="#cb25-89" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">return</span> {</span>
<span id="cb25-90"><a href="#cb25-90" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"answer"</span>: answers[<span class="dv">0</span>][<span class="st">"entity"</span>],</span>
<span id="cb25-91"><a href="#cb25-91" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"confidence"</span>: answers[<span class="dv">0</span>][<span class="st">"score"</span>],</span>
<span id="cb25-92"><a href="#cb25-92" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"alternative_answers"</span>: answers[<span class="dv">1</span>:],</span>
<span id="cb25-93"><a href="#cb25-93" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"source"</span>: <span class="st">"knowledge_graph"</span></span>
<span id="cb25-94"><a href="#cb25-94" aria-hidden="true" tabindex="-1"></a>                        }</span>
<span id="cb25-95"><a href="#cb25-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-96"><a href="#cb25-96" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If no good answer found, try more complex reasoning or fall back to NLP</span></span>
<span id="cb25-97"><a href="#cb25-97" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb25-98"><a href="#cb25-98" aria-hidden="true" tabindex="-1"></a>            <span class="st">"answer"</span>: <span class="va">self</span>.nlp_model.generate_answer(question),</span>
<span id="cb25-99"><a href="#cb25-99" aria-hidden="true" tabindex="-1"></a>            <span class="st">"confidence"</span>: <span class="fl">0.3</span>,</span>
<span id="cb25-100"><a href="#cb25-100" aria-hidden="true" tabindex="-1"></a>            <span class="st">"source"</span>: <span class="st">"language_model"</span></span>
<span id="cb25-101"><a href="#cb25-101" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb25-102"><a href="#cb25-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-103"><a href="#cb25-103" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _answer_list_question(<span class="va">self</span>, question, kg_entities, kg_relations):</span>
<span id="cb25-104"><a href="#cb25-104" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Answer a list question using KG."""</span></span>
<span id="cb25-105"><a href="#cb25-105" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Implementation details for list questions</span></span>
<span id="cb25-106"><a href="#cb25-106" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ...</span></span>
<span id="cb25-107"><a href="#cb25-107" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {<span class="st">"answer"</span>: <span class="st">"list answer"</span>}</span>
<span id="cb25-108"><a href="#cb25-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-109"><a href="#cb25-109" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _answer_complex_question(<span class="va">self</span>, question, kg_entities, kg_relations):</span>
<span id="cb25-110"><a href="#cb25-110" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Answer a complex question using multi-hop reasoning on KG."""</span></span>
<span id="cb25-111"><a href="#cb25-111" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Implementation details for complex questions</span></span>
<span id="cb25-112"><a href="#cb25-112" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ...</span></span>
<span id="cb25-113"><a href="#cb25-113" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {<span class="st">"answer"</span>: <span class="st">"complex answer"</span>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This example demonstrates integrating knowledge graph embeddings with NLP components for question answering, handling different question types and combining knowledge graph inference with language model capabilities.</p>
</div>
</section>
</section>
<section id="summary" class="level2" data-number="13.9">
<h2 data-number="13.9" class="anchored" data-anchor-id="summary"><span class="header-section-number">13.9</span> Summary</h2>
<p>In this chapter, we’ve explored the practical aspects of implementing knowledge graph embedding systems, covering the entire pipeline from data preparation to deployment and integration. We’ve discussed:</p>
<ol type="1">
<li><strong>Data preparation and preprocessing</strong>: Handling various knowledge graph formats, cleaning data, and preparing for embedding</li>
<li><strong>Software frameworks and tools</strong>: Using existing libraries and developing custom implementations for knowledge graph embeddings</li>
<li><strong>Training and optimization</strong>: Leveraging hardware acceleration, distributed training, and memory optimization techniques</li>
<li><strong>Scaling to large knowledge graphs</strong>: Applying partitioning, compression, and out-of-core techniques for large-scale knowledge graphs</li>
<li><strong>Evaluation and validation</strong>: Implementing proper evaluation metrics and ensuring reproducible results</li>
<li><strong>Deployment architectures</strong>: Designing systems for serving knowledge graph embeddings</li>
<li><strong>Integration with other systems</strong>: Combining knowledge graph embeddings with recommendation, search, and NLP systems</li>
</ol>
<p>Implementing effective knowledge graph embedding systems requires balancing theoretical understanding with practical engineering considerations. The approaches discussed in this chapter provide a foundation for building real-world systems that can leverage the power of knowledge graph embeddings for various applications.</p>
<p>By applying the techniques covered in this chapter, you can develop knowledge graph embedding systems that scale to millions of entities and billions of relations, deliver predictions with low latency, and integrate seamlessly with other components of your AI infrastructure.</p>
</section>
<section id="further-reading" class="level2" data-number="13.10">
<h2 data-number="13.10" class="anchored" data-anchor-id="further-reading"><span class="header-section-number">13.10</span> Further reading</h2>
<section id="software-frameworks-and-implementation" class="level3" data-number="13.10.1">
<h3 data-number="13.10.1" class="anchored" data-anchor-id="software-frameworks-and-implementation"><span class="header-section-number">13.10.1</span> Software frameworks and implementation</h3>
<ul>
<li>Ali, M., Berrendorf, M., Hoyt, C. T., Vermue, L., Sharifzadeh, S., Tresp, V., &amp; Lehmann, J. (2021). PyKEEN 1.0: A Python Library for Training and Evaluating Knowledge Graph Embeddings. Journal of Machine Learning Research, 22(82), 1-6.</li>
<li>Han, X., Cao, S., Lv, X., Lin, Y., Liu, Z., Sun, M., &amp; Li, J. (2018). OpenKE: An Open Toolkit for Knowledge Embedding. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations (pp.&nbsp;139-144).</li>
<li>Zheng, D., Song, X., Ma, C., Tan, Z., Ye, Z., Dong, J., Xiong, H., Zhang, Z., &amp; Karypis, G. (2020). DGL-KE: Training Knowledge Graph Embeddings at Scale. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval (pp.&nbsp;739-748).</li>
</ul>
</section>
<section id="scaling-and-optimization" class="level3" data-number="13.10.2">
<h3 data-number="13.10.2" class="anchored" data-anchor-id="scaling-and-optimization"><span class="header-section-number">13.10.2</span> Scaling and optimization</h3>
<ul>
<li>Lerer, A., Wu, L., Shen, J., Lacroix, T., Wehrstedt, L., Bose, A., &amp; Peysakhovich, A. (2019). PyTorch-BigGraph: A Large-scale Graph Embedding System. In Proceedings of the 2nd Conference on Systems and Machine Learning (SysML).</li>
<li>Zhu, Z., Wang, X., Bai, J., Zhang, Z., Wang, W., &amp; Wang, J. (2020). GraphVite: A High-Performance CPU-GPU Hybrid System for Node Embedding. In The World Wide Web Conference (pp.&nbsp;2494-2504).</li>
<li>Kochsiek, A., &amp; Gemulla, R. (2022). Parallel Training of Knowledge Graph Embedding Models: A Comparison of Techniques. Proceedings of the VLDB Endowment, 15(8), 1628-1641.</li>
</ul>
</section>
<section id="deployment-and-integration" class="level3" data-number="13.10.3">
<h3 data-number="13.10.3" class="anchored" data-anchor-id="deployment-and-integration"><span class="header-section-number">13.10.3</span> Deployment and integration</h3>
<ul>
<li>Pan, Z., Wang, P., Liu, W., Zhu, Y., &amp; Yang, X. (2021). BlazeKG: A System for Real-time Knowledge Graph Embedding. In Proceedings of the 47th International Conference on Very Large Data Bases (VLDB).</li>
<li>Dietz, L., Xiong, C., Dalton, J., &amp; Meij, E. (2020). Special Issue on Knowledge Graphs and Semantics in Text Analysis and Retrieval. Information Retrieval Journal, 23, 103-106.</li>
<li>Tay, Y., Dehghani, M., Bahri, D., &amp; Metzler, D. (2022). Efficient Methods for Natural Language Processing: A Survey. IEEE Transactions on Neural Networks and Learning Systems.</li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation column-body">
  <div class="nav-page nav-page-previous">
      <a href="../content/applications.html" class="pagination-link" aria-label="Practical Applications and Case Studies">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Practical Applications and Case Studies</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../content/frontier.html" class="pagination-link" aria-label="Advanced Topics and Research Frontiers">
        <span class="nav-page-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Advanced Topics and Research Frontiers</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p><a href="https://tuedsci.github.io/">© Tue Nguyen</a></p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>